source_action,Comment_URL,Comment_HTML_URL,Review_Start_Line,Review_End_Line,Original_Commit_id,Merge_Commit_id,Diff_path,New_path,Body,Diff_hunk,Change_Until_Merged,Whether it contain issues or suggestions (Not Contain: 0; Contain: 1),List of issues or suggestions,Addressed Status Classification (Not Addressed: 0; Partly Addressed: 1; Fully Addressed: 2),Detail
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/lightspeedwp/tour-operator/pulls/comments/1881466950,https://github.com/lightspeedwp/tour-operator/pull/457#discussion_r1881466950,352,372,3fe9116bb9f46687a47f4f21799dc177f084d2eb,70abbf3757db6f520f4e9250a937a5aafa1fe4b5,assets/css/style.css,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

There is a minor issue with the CSS property `left` being declared twice for `.facilities-list li::before`. The second declaration will override the first one. If this is not intentional, you should remove the redundant declaration.
```diff
.facilities-list li::before{
    content: '';
    position: absolute;
    left: 0;
    top: 50%;
    transform: translateY(-50%); /* Center the icon vertically */
    width: 20px; /* Adjust the size of the tick icon */
    height: 20px;
    background-image: url('../img/tick.svg'); /* Replace with the path to your tick.svg */
    background-size: contain;
    background-repeat: no-repeat;
-371:     left:-28px
+371:     /* left:-28px */ // Commented out as it seems to be a duplicate
}
```


<!-- This is an auto-generated comment by OSS CodeRabbit -->","+.facilities-list li::marker{display:none;}
+.facilities-list{padding-left:0!important;}
+
+.facilities-list li {
+  margin-left: 10px;
+  list-style: none; /* Remove default list marker */
+  position: relative; /* Position for pseudo-element */}
+
+.facilities-list li::before{
+    content: '';
+    position: absolute;
+    left: 0;
+    top: 50%;
+    transform: translateY(-50%); /* Center the icon vertically */
+    width: 20px; /* Adjust the size of the tick icon */
+    height: 20px;
+    background-image: url('../img/tick.svg'); /* Replace with the path to your tick.svg */
+    background-size: contain;
+    background-repeat: no-repeat;
+    left:-28px
+}","--- 

+++ 

@@ -157,18 +157,146 @@

   margin-right: 0px;
 }
 
+/* Additional information specific styles */
+/* Fast Facts Wrapper */
+.fast-facts-wrapper > .wp-block-group .wp-block-group:first-child {
+  display: flex;
+  align-items: flex-start; /* Align content in this group to the top */
+  gap: 5px; /* Space between icon and text */
+  flex-shrink: 0; /* Prevent group from shrinking */
+}
+
+/* Style the image icon */
+.fast-facts-wrapper > .wp-block-group .wp-block-image img {
+  width: 20px; /* Fixed width */
+  height: 20px; /* Fixed height */
+  display: inline-block;
+  -o-object-fit: contain;
+     object-fit: contain; /* Ensure image doesn't stretch or distort */
+}
+
+/* Styling for the label (e.g., ""Special Interests:"") */
+.fast-facts-wrapper > .wp-block-group .wp-block-group:first-child p {
+  margin: 0;
+  white-space: nowrap; /* Prevent wrapping for label */
+  vertical-align: middle; /* Align text with the middle of the icon */
+  line-height: 1.2; /* Improve readability */
+  display: inline-block; /* Keep text inline */
+}
+
+/* Styling for the flowing text */
+.fast-facts-wrapper > .wp-block-group .wp-block-group:last-child {
+  display: flex;
+  flex-wrap: nowrap; /* Keep the text flowing inline */
+  white-space: normal; /* Allow wrapping for text if it overflows */
+  overflow-wrap: break-word; /* Ensure long words wrap correctly */
+  word-break: break-word; /* Break long words when needed */
+  flex: 1; /* Allow the container to use available space */
+  align-items: flex-start; /* Ensure text starts at the top */
+}
+
+/* Specific styling for the text content */
+.fast-facts-wrapper > .wp-block-group .wp-block-group:last-child p {
+  white-space: normal; /* Allow wrapping for long text */
+  overflow-wrap: break-word; /* Break words when needed */
+  word-break: break-word; /* Break words on legacy browsers */
+  line-height: 1.4; /* Improve readability */
+  text-transform: capitalize; /* Capitalize text */
+  padding: 0; /* Ensure no unnecessary padding */
+  margin: 0; /* Remove extra margins */
+  display: inline; /* Ensure the text flows inline with the label */
+}
+
+/* Facilities List */
+.facilities-list li::marker {
+  display: none;
+}
+
+.facilities-list {
+  padding-left: 0 !important;
+}
+
+.facilities-list li {
+  margin-left: 10px;
+  list-style: none; /* Remove default list marker */
+  position: relative; /* Position for pseudo-element */
+}
+
+.facilities-list li::before {
+  content: """";
+  position: absolute;
+  left: 0;
+  top: 50%;
+  transform: translateY(-50%); /* Center the icon vertically */
+  width: 20px; /* Adjust the size of the tick icon */
+  height: 20px;
+  background-image: url(""../../img/tick.svg""); /* Replace with the path to your tick.svg */
+  background-size: contain;
+  background-repeat: no-repeat;
+  left: -28px;
+}
+
+/* Additional Info */
+.additional-info .wp-block-group.content .read-more-btn,
+.additional-info .wp-block-group.content .read-less-btn {
+  color: #0073aa;
+  cursor: pointer;
+  font-weight: bold;
+}
+
+.additional-info .wp-block-group.content .read-more-btn:hover {
+  text-decoration: underline;
+}
+
+.additional-info .wp-block-group.content .read-less-btn {
+  display: none;
+}
+
+.wp-block-query.lsx-to-slider {
+  gap: var(--wp--preset--spacing--small) var(--wp--preset--spacing--small);
+  position: relative;
+}
+.wp-block-query.lsx-to-slider .slick-arrow {
+  cursor: pointer;
+  border-color: #000 !important;
+  height: 30px;
+  width: 30px;
+}
+.wp-block-query.lsx-to-slider .slick-arrow:before {
+  border-color: #000 !important;
+  height: 30px;
+  width: 30px;
+}
+.wp-block-query.lsx-to-slider .slick-arrow.slick-prev:before {
+  background: url(""../img/left-arrow-dark.svg"") no-repeat center center;
+  width: 20px;
+  left: 3px;
+  height: 20px;
+}
+.wp-block-query.lsx-to-slider .slick-arrow.slick-next:before {
+  background: url(""../img/right-arrow-dark.svg"") no-repeat center center;
+  width: 20px;
+  left: 3px;
+  height: 20px;
+}
+.wp-block-query.lsx-to-slider .slick-slide {
+  padding: 15px !important;
+}
+
 .slick-lightbox-close {
   right: 52px;
   top: 35px;
 }
-.slick-lightbox-close:before{font-size:40px;}
+.slick-lightbox-close:before {
+  font-size: 40px;
+}
 
 .lsx-to-slider .slick-arrow,
 .slick-lightbox-inner .slick-arrow {
   background: transparent;
   border-radius: 50%;
-  position:absolute;
-  top:50%;
+  position: absolute;
+  top: 50%;
   border-style: solid;
   border-color: #fff;
   border-width: 2px;
@@ -183,8 +311,6 @@

   z-index: 3;
   color: white;
 }
-.slick-prev svg, .slick-next svg{color: white;}
-
 .lsx-to-slider .slick-arrow:before,
 .slick-lightbox-inner .slick-arrow:before {
   display: block;
@@ -200,48 +326,32 @@

   -webkit-font-smoothing: antialiased;
   -moz-osx-font-smoothing: grayscale;
 }
+
+.slick-prev svg,
+.slick-next svg {
+  color: white;
+}
+
 .lsx-to-slider .slick-arrow.slick-disabled,
 .slick-lightbox-inner .slick-arrow.slick-disabled {
   cursor: not-allowed;
 }
 .lsx-to-slider .slick-arrow.slick-prev:before,
 .slick-lightbox-inner .slick-arrow.slick-prev:before {
-  content: ''; /* Remove font icon */
-    background: url('../img/left-arrow-new.svg') no-repeat center center;
-    width: 40px;
-    height: 40px;
-    display: inline-block;
-    left: 10px;
+  content: """"; /* Remove font icon */
+  width: 40px;
+  height: 40px;
+  display: inline-block;
+  left: 10px;
 }
 .lsx-to-slider .slick-arrow.slick-next:before,
 .slick-lightbox-inner .slick-arrow.slick-next:before {
-  content: ''; /* Remove font icon */
-    background: url('../img/right-arrow.svg') no-repeat center center;
-    width: 40px;
-    height: 40px;
-    display: inline-block;
-    left: 12px;
-}
-.wp-block-query.lsx-to-slider{position:relative;}
-.wp-block-query.lsx-to-slider .slick-arrow:before,
-.wp-block-query .slick-lightbox-inner .slick-arrow:before{ border-color: #000!important;
-height:30px; width:30px;}
-
-.wp-block-query.lsx-to-slider .slick-arrow,
-.slick-lightbox-inner .slick-arrow {cursor: pointer;
-  border-color: #000!important;height:30px; width:30px;}
-
-.wp-block-query.lsx-to-slider .slick-arrow.slick-prev:before,
-.wp-block-query .slick-lightbox-inner .slick-arrow.slick-prev:before{background: url('../img/left-arrow-dark.svg') no-repeat center center;
-  width: 20px;left: 3px;
-  height: 20px;}
-
-.wp-block-query.lsx-to-slider .slick-arrow.slick-next:before,
-.wp-block-query .slick-lightbox-inner .slick-arrow.slick-next:before{background: url('../img/right-arrow-dark.svg') no-repeat center center;
-  width: 20px;left: 3px;
-  height: 20px;}
-
-  .wp-block-query.lsx-to-slider .slick-slide{padding:15px!important;}
+  content: """"; /* Remove font icon */
+  width: 40px;
+  height: 40px;
+  display: inline-block;
+  left: 12px;
+}
 
 .lsx-to-slider .slick-dots:not(.dropdown-menu) {
   align-items: center;
@@ -272,10 +382,12 @@

 .lsx-to-slider .slick-arrow.slick-next {
   right: -4rem;
 }
-
 .lsx-to-slider.slider-disabled {
   overflow: hidden;
 }
+.lsx-to-slider .slick-slide .lazy-hidden {
+  max-height: 154px;
+}
 
 .slick-lightbox-inner .slick-arrow {
   opacity: 0.75;
@@ -288,7 +400,6 @@

   display: inline-block;
 }
 
-.lsx-to-slider .slick-slide .lazy-hidden,
 .lsx-post-carousel-items .slick-slide .lazy-hidden {
   max-height: 154px;
 }
@@ -297,131 +408,9 @@

 .lsx-units-wrapper .hidden {
   display: none;
 }
-.wp-block-query.lsx-to-slider{gap: var(--wp--preset--spacing--small) var(--wp--preset--spacing--small);}
-
+
+.lsx-itinerary-wrapper .hidden,
+.lsx-units-wrapper .hidden {
+  display: none;
+}
 /*# sourceMappingURL=style.css.map */
-
-/* Inner group for icon and label */
-.fast-facts-wrapper > .wp-block-group .wp-block-group:first-child {
-  display: flex;
-  align-items: flex-start; /* Align content in this group to the top */
-  gap: 5px; /* Space between icon and text */
-  flex-shrink: 0; /* Prevent group from shrinking */
-}
-
-/* Style the image icon */
-.fast-facts-wrapper > .wp-block-group .wp-block-image img {
-  width: 20px; /* Fixed width */
-  height: 20px; /* Fixed height */
-  display: inline-block;
-  object-fit: contain; /* Ensure image doesn't stretch or distort */
-}
-
-/* Styling for the label (e.g., ""Special Interests:"") */
-.fast-facts-wrapper > .wp-block-group .wp-block-group:first-child p {
-  margin: 0;
-  white-space: nowrap; /* Prevent wrapping for label */
-  vertical-align: middle; /* Align text with the middle of the icon */
-  line-height: 1.2; /* Improve readability */
-  display: inline-block; /* Keep text inline */
-}
-
-/* Styling for the flowing text */
-.fast-facts-wrapper > .wp-block-group .wp-block-group:last-child {
-  display: flex;
-  flex-wrap: nowrap; /* Keep the text flowing inline */
-  white-space: normal; /* Allow wrapping for text if it overflows */
-  overflow-wrap: break-word; /* Ensure long words wrap correctly */
-  word-break: break-word; /* Break long words when needed */
-  flex: 1; /* Allow the container to use available space */
-  align-items: flex-start; /* Ensure text starts at the top */
-}
-
-/* Specific styling for the text content */
-.fast-facts-wrapper > .wp-block-group .wp-block-group:last-child p {
-  white-space: normal; /* Allow wrapping for long text */
-  overflow-wrap: break-word; /* Break words when needed */
-  word-break: break-word; /* Break words on legacy browsers */
-  line-height: 1.4; /* Improve readability */
-  text-transform: capitalize; /* Capitalize text */
-  padding: 0; /* Ensure no unnecessary padding */
-  margin: 0; /* Remove extra margins */
-  display: inline; /* Ensure the text flows inline with the label */
-}
-
-.facilities-list li::marker{display:none;}
-.facilities-list{padding-left:0!important;}
-
-.facilities-list li {
-  margin-left: 10px;
-  list-style: none; /* Remove default list marker */
-  position: relative; /* Position for pseudo-element */}
-
-.facilities-list li::before{
-    content: '';
-    position: absolute;
-    left: 0;
-    top: 50%;
-    transform: translateY(-50%); /* Center the icon vertically */
-    width: 20px; /* Adjust the size of the tick icon */
-    height: 20px;
-    background-image: url('../img/tick.svg'); /* Replace with the path to your tick.svg */
-    background-size: contain;
-    background-repeat: no-repeat;
-    left:-28px
-}
-
-.additional-info .wp-block-group.content .read-more-btn,.additional-info .wp-block-group.content .read-less-btn{
-  color: #0073aa;
-  cursor: pointer;
-  font-weight: bold;
-}
-
-.additional-info .wp-block-group.content .read-more-btn:hover {
-  text-decoration: underline;
-}
-
-.additional-info .wp-block-group.content .read-less-btn{display:none;}
-
-@media (min-width: 800px) {
-.single-tour-operator .toggle-button {display:none;}
-}
-
-/* Optional: Responsive adjustments for smaller screens */
-@media (max-width: 768px) {
-
-  /* Styling for the toggle button */
-.single-tour-operator .toggle-button {
-  display: inline-flex;
-  align-items: center;
-  padding: 5px;
-  background: none;
-  border: none;
-  cursor: pointer;
-  font-size: 14px;
-  color: var(--wp--preset--color--contrast);
-}
-
-/* Styling for the SVG icons */
-.single-tour-operator .toggle-icon {
-  width: 16px;
-  height: 16px;
-  fill: var(--wp--preset--color--contrast);
-  margin-left: 5px;
-}
-
-/* Collapsed state for the second wp-block-group */
-.single-tour-operator section.wp-block-group .wp-block-group.collapsed {
-  display: none; /* Hide the content */
-}
-
-
-  .fast-facts-wrapper > .wp-block-group {
-    flex-wrap: wrap; /* Allow wrapping for better readability */
-    gap: 5px;
-  }
-
-  .fast-facts-wrapper > .wp-block-group .wp-block-group.is-layout-flex:last-child {
-    flex-wrap: wrap; /* Allow text to wrap on smaller screens */
-  }
-}",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/saiqulhaq/dynamic_links/pulls/comments/1468725827,https://github.com/saiqulhaq/dynamic_links/pull/19#discussion_r1468725827,4,39,a71f93658310e321b930a78926b4ab31f66de4f4,67675ef2633001974317dae9fc570ecf17a48936,lib/dynamic_links/configuration.rb,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The new configuration class seems to be well structured and the defaults are set in a clear manner. However, it's important to ensure that the `RedisConfig.new` object created as the default for `DEFAULT_REDIS_COUNTER_CONFIG` is properly initialized with sensible defaults. If not, this could lead to unexpected behavior or errors when trying to use Redis functionalities without explicit configuration.

Also, consider adding error handling or validation for the configuration parameters. For instance, if an invalid value is provided for `shortening_strategy`, `db_infra_strategy`, or `async_processing`, the system should either throw an error or revert to the default value. This will prevent potential issues caused by misconfiguration.

```diff
+    VALID_SHORTENING_STRATEGIES = [:MD5, :SHA1, :SHA256].freeze
+    VALID_DB_INFRA_STRATEGIES = [:standard, :sharding].freeze

     def initialize
       @shortening_strategy = DEFAULT_SHORTENING_STRATEGY
       @enable_rest_api = DEFAULT_ENABLE_REST_API
       @db_infra_strategy = DEFAULT_DB_INFRA_STRATEGY
       @async_processing = DEFAULT_ASYNC_PROCESSING

+      validate_configurations
+
       # config for RedisCounterStrategy
       @redis_counter_config = DEFAULT_REDIS_COUNTER_CONFIG
       @cache_store = DEFAULT_CACHE_STORE
     end

+    private
+
+    def validate_configurations
+      unless VALID_SHORTENING_STRATEGIES.include?(@shortening_strategy)
+        raise ""Invalid shortening strategy. Valid strategies are #{VALID_SHORTENING_STRATEGIES.join(', ')}""
+      end
+
+      unless VALID_DB_INFRA_STRATEGIES.include?(@db_infra_strategy)
+        raise ""Invalid DB infrastructure strategy. Valid strategies are #{VALID_DB_INFRA_STRATEGIES.join(', ')}""
+      end
+
+      unless [true, false].include?(@async_processing)
+        raise ""Invalid async processing value. It should be either true or false.""
+      end
+    end
```
This will ensure that the configuration is valid at the time of initialization and prevent potential issues down the line.


<!-- This is an auto-generated comment by OSS CodeRabbit -->","   class Configuration
-    attr_accessor :shortening_strategy, :redis_config,
-                  :redis_pool_size, :redis_pool_timeout,
-                  :enable_rest_api
+    attr_accessor :shortening_strategy, :enable_rest_api, :db_infra_strategy,
+                  :async_processing, :redis_counter_config, :cache_store
+
+    DEFAULT_SHORTENING_STRATEGY = :MD5
+    DEFAULT_ENABLE_REST_API = true
+    DEFAULT_DB_INFRA_STRATEGY = :standard
+    DEFAULT_ASYNC_PROCESSING = false
+    DEFAULT_REDIS_COUNTER_CONFIG = RedisConfig.new
+    # use any class that extends ActiveSupport::Cache::Store, default is MemoryStore
+    DEFAULT_CACHE_STORE = ActiveSupport::Cache::MemoryStore.new
 
+    # Usage:
+    #     DynamicLinks.configure do |config|
+    #       config.shortening_strategy = :MD5 # or other strategy name, see StrategyFactory for available strategies
+    #       config.enable_rest_api = true # or false. when false, the API requests will be rejected
+    #       config.db_infra_strategy = :standard # or :sharding. if sharding is used, then xxx
+    #       config.async_processing = false # or true. if true, the shortening process will be done asynchronously using ActiveJob
+    #       config.redis_counter_config = RedisConfig.new # see RedisConfig documentation for more details
+    #       # if you use Redis
+    #       config.cache_store = ActiveSupport::Cache::RedisStore.new('redis://localhost:6379/0/cache')
+    #       # if you use Memcached
+    #       config.cache_store = ActiveSupport::Cache::MemCacheStore.new('localhost:11211')
+    #     end
+    #
+    # @return [Configuration]
     def initialize
-      @shortening_strategy = :MD5  # Default strategy
-      @redis_config = {}  # Default to an empty hash, can be overridden in configuration
-      @redis_pool_size = 5  # Default pool size
-      @redis_pool_timeout = 5  # Default timeout in seconds
-      @enable_rest_api = true  # Enable REST API by default
+      @shortening_strategy = DEFAULT_SHORTENING_STRATEGY
+      @enable_rest_api = DEFAULT_ENABLE_REST_API
+      @db_infra_strategy = DEFAULT_DB_INFRA_STRATEGY
+      @async_processing = DEFAULT_ASYNC_PROCESSING
+
+      # config for RedisCounterStrategy
+      @redis_counter_config = DEFAULT_REDIS_COUNTER_CONFIG
+      @cache_store = DEFAULT_CACHE_STORE
     end","--- 

+++ 

@@ -1,11 +1,12 @@

 module DynamicLinks
   # @author Saiqul Haq <saiqulhaq@gmail.com>
-
   class Configuration
-    attr_accessor :shortening_strategy, :enable_rest_api, :db_infra_strategy,
+    attr_reader :shortening_strategy, :enable_rest_api, :db_infra_strategy,
                   :async_processing, :redis_counter_config, :cache_store
 
-    DEFAULT_SHORTENING_STRATEGY = :MD5
+    VALID_DB_INFRA_STRATEGIES = [:standard, :sharding].freeze
+
+    DEFAULT_SHORTENING_STRATEGY = :md5
     DEFAULT_ENABLE_REST_API = true
     DEFAULT_DB_INFRA_STRATEGY = :standard
     DEFAULT_ASYNC_PROCESSING = false
@@ -32,10 +33,39 @@

       @enable_rest_api = DEFAULT_ENABLE_REST_API
       @db_infra_strategy = DEFAULT_DB_INFRA_STRATEGY
       @async_processing = DEFAULT_ASYNC_PROCESSING
-
       # config for RedisCounterStrategy
       @redis_counter_config = DEFAULT_REDIS_COUNTER_CONFIG
       @cache_store = DEFAULT_CACHE_STORE
     end
+
+    def shortening_strategy=(strategy)
+      raise ArgumentError, ""Invalid shortening strategy"" unless StrategyFactory::VALID_SHORTENING_STRATEGIES.include?(strategy)
+      @shortening_strategy = strategy
+    end
+
+    def enable_rest_api=(value)
+      raise ArgumentError, ""enable_rest_api must be a boolean"" unless [true, false].include?(value)
+      @enable_rest_api = value
+    end
+
+    def db_infra_strategy=(strategy)
+      raise ArgumentError, ""Invalid DB infra strategy"" unless VALID_DB_INFRA_STRATEGIES.include?(strategy)
+      @db_infra_strategy = strategy
+    end
+
+    def async_processing=(value)
+      raise ArgumentError, ""async_processing must be a boolean"" unless [true, false].include?(value)
+      @async_processing = value
+    end
+
+    def redis_counter_config=(config)
+      raise ArgumentError, ""redis_counter_config must be an instance of RedisConfig"" unless config.is_a?(RedisConfig)
+      @redis_counter_config = config
+    end
+
+    def cache_store=(store)
+      raise ArgumentError, ""cache_store must be an instance of ActiveSupport::Cache::Store"" unless store.is_a?(ActiveSupport::Cache::Store)
+      @cache_store = store
+    end
   end
 end",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/lightspeedwp/tour-operator/pulls/comments/1871095860,https://github.com/lightspeedwp/tour-operator/pull/452#discussion_r1871095860,142,144,24d69edae1e756b7c2fc923c981506bc70c61571,513fc33840f7ff5f995e0cbf585f3484152fd0e3,assets/js/blocks/general.js,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The width property of the image is set as a string '20px' instead of an integer. This could potentially cause issues if the code expects an integer value for the width. Also, it's better to avoid hardcoding URLs in your code. Consider using a configuration file or environment variable to store these values.
```diff
-   width: '20px',
+   width: 20,
-   url: 'https://tour-operator.lsx.design/wp-content/uploads/2024/06/image-1.png',
+   url: config.IMAGE_URL || process.env.IMAGE_URL,
```



<!-- This is an auto-generated comment by OSS CodeRabbit -->","+						width: '20px',
 						sizeSlug: 'large',
-						url: 'http://localhost:8883/wp-content/themes/lsx-tour-operator/assets/images/Typetype-icon.png',
+						url: 'https://tour-operator.lsx.design/wp-content/uploads/2024/06/image-1.png',","--- 

+++ 

@@ -1,3 +1,5 @@

+// metadata.bindings not handle correctly
+
 wp.domReady(() => {
 	// Gallery Block
 	wp.blocks.registerBlockVariation(""core/gallery"", {",,,,
aidar-freeed(merged)/ai-codereviewer,https://api.github.com/repos/aidar-freeed/ai-codereviewer/pulls/comments/1174425508,https://github.com/aidar-freeed/ai-codereviewer/pull/10#discussion_r1174425508,,213,97bdebd58573233576537253b7e2c3870acda9b1,07b4e53660f659896135241f708e9811a19cb8e6,src/main.ts,nan,Consider using `core.info()` instead of `console.log()` for better integration with GitHub Actions.,"+    const pushEvent = JSON.parse(
+      readFileSync(process.env.GITHUB_EVENT_PATH || """", ""utf8"")
+    );
+    console.log(""Push event:"");","--- 

+++ 

@@ -196,24 +196,19 @@

 async function main() {
   const prDetails = await getPRDetails();
   let diff: string | null;
-  console.log(""Running the action..."");
-  console.log(""Event name:"", process.env.GITHUB_EVENT_NAME);
-  if (process.env.GITHUB_EVENT_NAME === ""pull_request"") {
-    console.log(""Pull request event"");
+  const eventData = JSON.parse(
+    readFileSync(process.env.GITHUB_EVENT_PATH ?? """", ""utf8"")
+  );
+
+  if (eventData.action === ""opened"") {
     diff = await getDiff(
       prDetails.owner,
       prDetails.repo,
       prDetails.pull_number
     );
-  } else if (process.env.GITHUB_EVENT_NAME === ""push"") {
-    console.log(""Push event"");
-    const pushEvent = JSON.parse(
-      readFileSync(process.env.GITHUB_EVENT_PATH || """", ""utf8"")
-    );
-    console.log(""Push event:"");
-    console.log(pushEvent);
-    const newBaseSha = pushEvent.before;
-    const newHeadSha = pushEvent.after;
+  } else if (eventData.action === ""synchronize"") {
+    const newBaseSha = eventData.before;
+    const newHeadSha = eventData.after;
 
     const response = await octokit.repos.compareCommits({
       owner: prDetails.owner,
@@ -227,8 +222,6 @@

           .request({ url: response.data.diff_url })
           .then((res) => res.data)
       : null;
-    console.log(""Diff:"");
-    console.log(diff);
   } else {
     console.log(""Unsupported event:"", process.env.GITHUB_EVENT_NAME);
     return;",,,,
aidar-freeed(merged)/ai-codereviewer,https://api.github.com/repos/mrako/week-number/pulls/comments/1236833555,https://github.com/mrako/week-number/pull/29#discussion_r1236833555,,16,08089113741645198a42138ba3811f0943703b21,15488b2b5b414d3f41e183afbb1114cd17966f10,src/index.js,nan,"Instead of checking for `date`, you can use a ternary operator inside the JSX to conditionally render the week number or a default value.","+    setDate(isNaN(date) ? new Date() : new Date(date));
+  }, []);
+
+  if (date) {","--- 

+++ 

@@ -8,9 +8,9 @@

 
   useEffect(() => {
     const searchParams = new URLSearchParams(window.location.search);
-    const date = Date.parse(searchParams.get('date'));
+    const dateParam = Date.parse(searchParams.get('date'));
 
-    setDate(isNaN(date) ? new Date() : new Date(date));
+    setDate(isNaN(dateParam) ? new Date() : new Date(dateParam));
   }, []);
 
   if (date) {",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1532263182,https://github.com/SainsburyWellcomeCentre/aeon_mecha/pull/342#discussion_r1532263182,41,57,e85986b37a1d636d60ee8c61ee08b11d241fd713,739bcbe762004157988bae2a831ff4d2e951dcd0,aeon/io/streams.py,aeon/schema/streams.py,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

In the `compositeStream` function, you're catching a `TypeError` and issuing a warning, but then continuing execution. This could lead to unexpected behavior if the error isn't handled properly later on. Consider either re-raising the exception after issuing the warning, or handling the error in a way that allows the function to continue executing safely.



<!-- This is an auto-generated comment by OSS CodeRabbit -->","+def compositeStream(pattern, *args):
+    """"""Merges multiple data streams into a single composite stream.""""""
+    composite = {}
+    if args:
+        for stream in args:
+            try:
+                composite.update(stream(pattern))
+            except TypeError:
+                warn(
+                    f""Stream groups with no constructors are deprecated. {stream}"",
+                    category=DeprecationWarning,
+                )
+                if inspect.isclass(stream):
+                    for method in vars(stream).values():
+                        if isinstance(method, staticmethod):
+                            composite.update(method.__func__(pattern))
+    return composite","--- 

+++ 

@@ -21,40 +21,23 @@

     """"""Represents a logical group of multiple data streams.
 
     Attributes:
-        name (str): Name of the logical group used to find raw files.
+        path (str): Path to the folder where stream chunks are located.
+        args (Any): Data streams or data stream groups to be included in this stream group.
     """"""
 
-    def __init__(self, name, *args):
-        self.name = name
+    def __init__(self, path, *args):
+        self.path = path
         self._args = args
+        self._nested = (
+            member
+            for member in vars(self.__class__).values()
+            if inspect.isclass(member) and issubclass(member, (Stream, StreamGroup))
+        )
 
     def __iter__(self):
-        for member in chain(vars(self.__class__).values(), self._args):
-            if inspect.isclass(member):
-                for stream in iter(member(self.name)):
-                    yield stream
-            elif isinstance(member, staticmethod):
-                for stream in iter(member.__func__(self.name)):
-                    yield stream
-
-
-def compositeStream(pattern, *args):
-    """"""Merges multiple data streams into a single composite stream.""""""
-    composite = {}
-    if args:
-        for stream in args:
-            try:
-                composite.update(stream(pattern))
-            except TypeError:
-                warn(
-                    f""Stream groups with no constructors are deprecated. {stream}"",
-                    category=DeprecationWarning,
-                )
-                if inspect.isclass(stream):
-                    for method in vars(stream).values():
-                        if isinstance(method, staticmethod):
-                            composite.update(method.__func__(pattern))
-    return composite
+        for factory in chain(self._nested, self._args):
+            for stream in iter(factory(self.path)):
+                yield stream
 
 
 class Device:
@@ -67,17 +50,35 @@

     Attributes:
         name (str): Name of the device.
         args (Any): Data streams collected from the device.
-        pattern (str, optional): Pattern used to find raw chunk files,
-            usually in the format `<Device>_<DataStream>`.
+        path (str, optional): Path to the folder where stream chunks are located.
     """"""
 
-    def __init__(self, name, *args, pattern=None):
+    def __init__(self, name, *args, path=None):
+        if name is None:
+            raise ValueError(""name cannot be None."")
+
         self.name = name
-        self.provider = compositeStream(name if pattern is None else pattern, *args)
+        self._streams = Device._createStreams(name if path is None else path, args)
+
+    @staticmethod
+    def _createStreams(path, args):
+        streams = {}
+        for factory in args:
+            if inspect.isclass(factory) and not hasattr(factory.__init__, ""__code__""):
+                warn(
+                    f""Stream group classes with default constructors are deprecated. {factory}"",
+                    category=DeprecationWarning,
+                )
+                for method in vars(factory).values():
+                    if isinstance(method, staticmethod):
+                        streams.update(method.__func__(path))
+            else:
+                streams.update(factory(path))
+        return streams
 
     def __iter__(self):
-        if len(self.provider) == 1:
-            singleton = self.provider.get(self.name, None)
+        if len(self._streams) == 1:
+            singleton = self._streams.get(self.name, None)
             if singleton:
                 return iter((self.name, singleton))
-        return iter((self.name, self.provider))
+        return iter((self.name, self._streams))",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1307905830,https://github.com/SainsburyWellcomeCentre/aeon_mecha/pull/228#discussion_r1307905830,41,58,ee354120784672bba17150612396476ebf2ca0b4,f1ab685e3701d9a830524ec16350cbd6f56cca32,.pre-commit-config.yaml,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The setup for pytest-py has been commented out. While it's understandable that running tests can be expensive in terms of time and resources, it's generally a good idea to run tests as part of the commit process to catch potential issues early. However, since this is commented out and not removed, it can be easily enabled when needed.


<!-- This is an auto-generated comment by OSS CodeRabbit -->","+  # Pytest is expensive, so we show its set-up but leave it commented out.
+  # - repo: local
+  #   hooks:
+  #     - id: pytest-py
+  #       name: pytest-py
+  #       entry: pytest
+  #       language: system
+  #       pass_filenames: false
+  #       args:
+  #         - ""-v""
+  #         - ""-n""
+  #         - ""auto""","--- 

+++ 

@@ -1,7 +1,8 @@

+# For info on running pre-commit manually, see `pre-commit run --help`
+
 default_language_version:
   python: python3.11
 
-#default_stages: [commit, push]
 files: ""^(docker|aeon\/dj_pipeline)\/.*$""
 repos:
   - repo: meta
@@ -11,19 +12,24 @@

   - repo: https://github.com/pre-commit/pre-commit-hooks
     rev: v4.4.0
     hooks:
+      - id: check-json
       - id: check-yaml
+      - id: check-toml
+      - id: check-xml
+      - id: check-merge-conflict
       - id: detect-private-key
       - id: end-of-file-fixer
         exclude: LICENSE
       - id: no-commit-to-branch
+      - id: mixed-line-ending
+      - id: trailing-whitespace
+        args: [--markdown-linebreak-ext=md]
 
   - repo: https://github.com/psf/black
     rev: 23.7.0
     hooks:
       - id: black
-        args:
-          - ""--config""
-          - ""./pyproject.toml""
+        args: [--check, --config, ./pyproject.toml]
   
   - repo: https://github.com/astral-sh/ruff-pre-commit
     rev: v0.0.286",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1307905843,https://github.com/SainsburyWellcomeCentre/aeon_mecha/pull/228#discussion_r1307905843,51,62,ee354120784672bba17150612396476ebf2ca0b4,f1ab685e3701d9a830524ec16350cbd6f56cca32,.github/workflows/build_env_run_tests.yml,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The steps for this job include checking out the repo, setting up a conda environment, and updating the conda environment with dev requirements. Using conda for managing environments and dependencies is a good practice, especially for projects that require specific versions of packages.



<!-- This is an auto-generated comment by OSS CodeRabbit -->","+        uses: actions/checkout@v2
+      - name: set up conda env
+        uses: conda-incubator/setup-miniconda@v2
+        with:
+          use-mamba: true
+          miniforge-variant: Mambaforge
+          python-version: ${{ matrix.python-version }}
+          environment-file: ./env_config/env.yml
+          activate-environment: aeon
+      - name: Update conda env with dev reqs
+        run: mamba env update -f ./env_config/env_dev.yml
+","--- 

+++ 

@@ -7,6 +7,7 @@

     branches: [ main ]
     types: [opened, reopened, synchronize]
   workflow_dispatch:  # allows running manually from Github's 'Actions' tab
+
 jobs:
   build_env_pip_pyproject:  # checks only for building env using pip and pyproject.toml
     name: Build env using pip and pyproject.toml
@@ -15,9 +16,6 @@

       matrix:
         os: [ubuntu-latest, windows-latest, macos-latest]
         python-version: [3.11]
-        #include:  # test other python versions only on ubuntu
-          #- os: ubuntu-latest
-          #  python-version: [3.9, 3.10]
       fail-fast: false
     defaults:
       run:
@@ -34,7 +32,8 @@

           python -m venv .venv
           source .venv/bin/activate
           pip install -e .[dev]
-          python -c ""import aeon""
+          pip list
+          .venv/bin/python -c ""import aeon""
   
   build_env_run_tests:  # checks for building env using mamba and runs codebase checks and tests
     name: Build env and run tests on ${{ matrix.os }}
@@ -63,22 +62,22 @@

 
       # Only run codebase checks and tests for ubuntu.
       - name: ruff
-        if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'
+        if: matrix.os == 'ubuntu-latest'
         run: python -m ruff check --config ./pyproject.toml .
       - name: pyright
-        if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'
+        if: matrix.os == 'ubuntu-latest'
         run: python -m pyright --level error --project ./pyproject.toml . 
       - name: pytest
-        if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'
+        if: matrix.os == 'ubuntu-latest'
         run: python -m pytest tests/
 
       - name: generate test coverage report
-        if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'
+        if: matrix.os == 'ubuntu-latest'
         run: |
           python -m pytest --cov=aeon ./tests/ --cov-report=xml:./tests/test_coverage/test_coverage_report.xml
           #python -m pytest --cov=aeon ./tests/ --cov-report=html:./tests/test_coverage/test_coverage_report_html
       - name: upload test coverage report to codecov
-        if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'
+        if: matrix.os == 'ubuntu-latest'
         uses: codecov/codecov-action@v2
         with:
           token: ${{ secrets.CODECOV_TOKEN }}",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1314035455,https://github.com/SainsburyWellcomeCentre/aeon_mecha/pull/244#discussion_r1314035455,,60,7445a0a16a18971b741524f685cf3e7b185c3339,bdb3dcd2a4f3a2cd9e79aa1579236d1facbb1ea5,aeon/schema/social.py,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The return type hint of the `get_bodyparts` function has been changed from `Union[None, List[str]]` to `None | list[str]`. This is a new syntax introduced in Python 3.10 and is equivalent to the old one. However, it will cause a `SyntaxError` if the codebase is intended to support Python versions older than 3.10.

```diff
- def get_bodyparts(self, file: Path) -> Union[None, List[str]]:
+ def get_bodyparts(self, file: Path) -> None | list[str]:
```



<!-- This is an auto-generated comment by OSS CodeRabbit -->","         return new_data.sort_index()
 
-    def get_bodyparts(self, file: Path) -> Union[None, List[str]]:
+    def get_bodyparts(self, file: Path) -> None | list[str]:","--- 

+++ 

@@ -3,6 +3,7 @@

 import json
 from pathlib import Path
 
+import numpy as np
 import pandas as pd
 
 import aeon.io.reader as _reader
@@ -22,17 +23,25 @@

     """"""
 
     def __init__(self, pattern: str, extension: str = ""bin""):
+        """"""Pose reader constructor.""""""
         # `pattern` for this reader should typically be '<hpcnode>_<jobid>*'
         super().__init__(pattern, columns=None, extension=extension)
 
     def read(
-        self, file: Path, ceph_proc_dir: Path = Path(""/ceph/aeon/aeon/data/processed"")
+        self, file: Path, ceph_proc_dir: str | Path = ""/ceph/aeon/aeon/data/processed""
     ) -> pd.DataFrame:
         """"""Reads data from the Harp-binarized tracking file.""""""
         # Get config file from `file`, then bodyparts from config file.
         model_dir = Path(file.stem.replace(""_"", ""/"")).parent
+<<<<<<< HEAD
         config_file_dir = ceph_proc_dir / model_dir
+        if not config_file_dir.exists():
+            raise FileNotFoundError(f""Cannot find model dir {config_file_dir}"")
+=======
+        # `ceph_proc_dir` typically
+        config_file_dir = Path(ceph_proc_dir) / model_dir
         assert config_file_dir.exists(), f""Cannot find model dir {config_file_dir}""
+>>>>>>> b9a1e3f... Blackened and ruffed
         config_file = get_config_file(config_file_dir)
         parts = self.get_bodyparts(config_file)
 
@@ -43,47 +52,71 @@

         self.columns = columns
         data = super().read(file)
 
+<<<<<<< HEAD
+        # Drop any repeat parts.
+        unique_parts, unique_idxs = np.unique(parts, return_index=True)
+        repeat_idxs = np.setdiff1d(np.arange(len(parts)), unique_idxs)
+        if repeat_idxs:  # drop x, y, and likelihood cols for repeat parts (skip first 5 cols)
+            init_rep_part_col_idx = (repeat_idxs - 1) * 3 + 5
+            rep_part_col_idxs = np.concatenate([np.arange(i, i + 3) for i in init_rep_part_col_idx])
+            keep_part_col_idxs = np.setdiff1d(np.arange(len(data.columns)), rep_part_col_idxs)
+            data = data.iloc[:, keep_part_col_idxs]
+            parts = unique_parts
+
+=======
+>>>>>>> b9a1e3f... Blackened and ruffed
         # Set new columns, and reformat `data`.
         n_parts = len(parts)
-        part_data_list = [None] * n_parts
+        part_data_list = [pd.DataFrame()] * n_parts
         new_columns = [""class"", ""class_likelihood"", ""part"", ""x"", ""y"", ""part_likelihood""]
         new_data = pd.DataFrame(columns=new_columns)
         for i, part in enumerate(parts):
             part_columns = [""class"", ""class_likelihood"", f""{part}_x"", f""{part}_y"", f""{part}_likelihood""]
-            part_data = data[part_columns]
+            part_data = pd.DataFrame(data[part_columns])
             part_data.insert(2, ""part"", part)
             part_data.columns = new_columns
             part_data_list[i] = part_data
         new_data = pd.concat(part_data_list)
         return new_data.sort_index()
 
-    def get_bodyparts(self, file: Path) -> None | list[str]:
+    def get_bodyparts(self, file: Path) -> list[str]:
         """"""Returns a list of bodyparts from a model's config file.""""""
-        parts = None
+        parts = []
         with open(file) as f:
             config = json.load(f)
         if file.stem == ""confmap_config"":  # SLEAP
             try:
                 heads = config[""model""][""heads""]
-                parts = util.find_nested_key(heads, ""part_names"")
+                parts = [util.find_nested_key(heads, ""anchor_part"")]
+                parts += util.find_nested_key(heads, ""part_names"")
             except KeyError as err:
-                raise KeyError(f""Cannot find bodyparts in {file}."") from err
+                if not parts:
+                    raise KeyError(f""Cannot find bodyparts in {file}."") from err
         return parts
 
 
 def get_config_file(
     config_file_dir: Path,
-    config_file_names: list[str] = None,
-):
+    config_file_names: None | list[str] = None,
+) -> Path:
     """"""Returns the config file from a model's config directory.""""""
     if config_file_names is None:
-        config_file_names = [""confmap_config.json""]
+        config_file_names = [""confmap_config.json""]  # SLEAP (add for other trackers to this list)
+<<<<<<< HEAD
     config_file = None
+=======
+    config_file = Path()
+>>>>>>> b9a1e3f... Blackened and ruffed
     for f in config_file_names:
         if (config_file_dir / f).exists():
             config_file = config_file_dir / f
             break
-    assert config_file is not None, f""Cannot find config file in {config_file_dir}""
+<<<<<<< HEAD
+    if config_file is None:
+         raise FileNotFoundError(f""Cannot find config file in {config_file_dir}"")
+=======
+    assert config_file.is_file(), f""Cannot find config file in {config_file_dir}""
+>>>>>>> b9a1e3f... Blackened and ruffed
     return config_file
 
 ",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1532263181,https://github.com/SainsburyWellcomeCentre/aeon_mecha/pull/342#discussion_r1532263181,32,38,e85986b37a1d636d60ee8c61ee08b11d241fd713,739bcbe762004157988bae2a831ff4d2e951dcd0,aeon/io/streams.py,aeon/schema/streams.py,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

This block of code is quite complex and could benefit from some additional comments explaining its purpose. Specifically, it's not immediately clear why we're checking if `member` is a class or a static method, and what the implications are for each case.



<!-- This is an auto-generated comment by OSS CodeRabbit -->","+        for member in chain(vars(self.__class__).values(), self._args):
+            if inspect.isclass(member):
+                for stream in iter(member(self.name)):
+                    yield stream
+            elif isinstance(member, staticmethod):
+                for stream in iter(member.__func__(self.name)):
+                    yield stream","--- 

+++ 

@@ -21,40 +21,23 @@

     """"""Represents a logical group of multiple data streams.
 
     Attributes:
-        name (str): Name of the logical group used to find raw files.
+        path (str): Path to the folder where stream chunks are located.
+        args (Any): Data streams or data stream groups to be included in this stream group.
     """"""
 
-    def __init__(self, name, *args):
-        self.name = name
+    def __init__(self, path, *args):
+        self.path = path
         self._args = args
+        self._nested = (
+            member
+            for member in vars(self.__class__).values()
+            if inspect.isclass(member) and issubclass(member, (Stream, StreamGroup))
+        )
 
     def __iter__(self):
-        for member in chain(vars(self.__class__).values(), self._args):
-            if inspect.isclass(member):
-                for stream in iter(member(self.name)):
-                    yield stream
-            elif isinstance(member, staticmethod):
-                for stream in iter(member.__func__(self.name)):
-                    yield stream
-
-
-def compositeStream(pattern, *args):
-    """"""Merges multiple data streams into a single composite stream.""""""
-    composite = {}
-    if args:
-        for stream in args:
-            try:
-                composite.update(stream(pattern))
-            except TypeError:
-                warn(
-                    f""Stream groups with no constructors are deprecated. {stream}"",
-                    category=DeprecationWarning,
-                )
-                if inspect.isclass(stream):
-                    for method in vars(stream).values():
-                        if isinstance(method, staticmethod):
-                            composite.update(method.__func__(pattern))
-    return composite
+        for factory in chain(self._nested, self._args):
+            for stream in iter(factory(self.path)):
+                yield stream
 
 
 class Device:
@@ -67,17 +50,35 @@

     Attributes:
         name (str): Name of the device.
         args (Any): Data streams collected from the device.
-        pattern (str, optional): Pattern used to find raw chunk files,
-            usually in the format `<Device>_<DataStream>`.
+        path (str, optional): Path to the folder where stream chunks are located.
     """"""
 
-    def __init__(self, name, *args, pattern=None):
+    def __init__(self, name, *args, path=None):
+        if name is None:
+            raise ValueError(""name cannot be None."")
+
         self.name = name
-        self.provider = compositeStream(name if pattern is None else pattern, *args)
+        self._streams = Device._createStreams(name if path is None else path, args)
+
+    @staticmethod
+    def _createStreams(path, args):
+        streams = {}
+        for factory in args:
+            if inspect.isclass(factory) and not hasattr(factory.__init__, ""__code__""):
+                warn(
+                    f""Stream group classes with default constructors are deprecated. {factory}"",
+                    category=DeprecationWarning,
+                )
+                for method in vars(factory).values():
+                    if isinstance(method, staticmethod):
+                        streams.update(method.__func__(path))
+            else:
+                streams.update(factory(path))
+        return streams
 
     def __iter__(self):
-        if len(self.provider) == 1:
-            singleton = self.provider.get(self.name, None)
+        if len(self._streams) == 1:
+            singleton = self._streams.get(self.name, None)
             if singleton:
                 return iter((self.name, singleton))
-        return iter((self.name, self.provider))
+        return iter((self.name, self._streams))",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/lightspeedwp/tour-operator/pulls/comments/1878249776,https://github.com/lightspeedwp/tour-operator/pull/455#discussion_r1878249776,396,413,95095de04514f36f341a2879f4267d91eae6455e,e93103c36c9a44258b90468ad59f62d80d6c5d70,assets/js/src/custom.js,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

This block of code is responsible for toggling the visibility of sections and changing the icon accordingly. However, it directly manipulates the style of the elements which can lead to issues with CSS specificity and maintainability. It would be better to use CSS classes to control the display of the icons.
```diff
- 					if (toggleTarget.classList.contains('collapsed')) {
- 						iconDown.style.display = 'none';
- 						iconUp.style.display = 'inline';
- 					} else {
- 						iconDown.style.display = 'inline';
- 						iconUp.style.display = 'none';
- 					}
+ 					if (toggleTarget.classList.contains('collapsed')) {
+ 						iconDown.classList.add('hidden');
+ 						iconUp.classList.remove('hidden');
+ 					} else {
+ 						iconDown.classList.remove('hidden');
+ 						iconUp.classList.add('hidden');
+ 					}
```
In your CSS, you can then define these classes as follows:
```css
.hidden {
    display: none;
}

:not(.hidden) {
    display: inline;
}
```



<!-- This is an auto-generated comment by OSS CodeRabbit -->","+				// Insert the button after the heading
+				heading.insertAdjacentElement('afterend', toggleButton);
+	
+				// Add click event listener to toggle visibility of the second wp-block-group
+				toggleButton.addEventListener('click', function () {
+					toggleTarget.classList.toggle('collapsed'); // Add or remove the collapsed class
+	
+					// Toggle the display of the up/down icons
+					const iconDown = toggleButton.querySelector('.icon-down');
+					const iconUp = toggleButton.querySelector('.icon-up');
+	
+					if (toggleTarget.classList.contains('collapsed')) {
+						iconDown.style.display = 'none';
+						iconUp.style.display = 'inline';
+					} else {
+						iconDown.style.display = 'inline';
+						iconUp.style.display = 'none';
+					}","--- 

+++ 

@@ -198,106 +198,50 @@

 	 */
 	lsx_to.build_slider = function( window_width ) {
 		$( '.lsx-to-slider .wp-block-post-template:not(.slider-disabled)' ).each( function() {
-			var $this = $( this ),
-				interval = $this.data( 'interval' ),
-				currentSettings = $this.data( 'slick' ),
-				autoplay = false,
-				autoplay_speed = 0;
+			var $this = $( this );
 
 			lsx_to.pre_build_slider( $this );
 
-			if ( 'undefined' !== typeof interval && 'boolean' !== typeof interval ) {
-				interval = parseInt( interval );
-
-				if ( ! isNaN( interval ) ) {
-					autoplay = true;
-					autoplay_speed = interval;
-				}
-			}
-
-
-			let tabletSlidesToShow   = lsx_to_params.slickSlider.tablet.slidesToShow;
-			let tabletSlidesToScroll = lsx_to_params.slickSlider.tablet.slidesToScroll;
-
-			if ( 'undefined' !== typeof currentSettings && 'boolean' !== typeof currentSettings ) {
-
-				// Tablet Settings.
-				if ( 'undefined' !== typeof currentSettings.tablet ) {
-					if ( 'undefined' !== typeof currentSettings.tablet.slidesToShow ) {
-						tabletSlidesToShow = currentSettings.tablet.slidesToShow;
-					}
-					if ( 'undefined' !== typeof currentSettings.tablet.slidesToShow ) {
-						tabletSlidesToScroll = currentSettings.tablet.slidesToScroll;
-					}
-				}
-			}
-
 			if ( 1 < $this.children.length ) {
-				console.log($this);
 
 				$this.slick( {
-					draggable: lsx_to_params.slickSlider.desktop.draggable,
-					infinite: lsx_to_params.slickSlider.desktop.infinite,
-					swipe: lsx_to_params.slickSlider.desktop.swipe,
-					cssEase: lsx_to_params.slickSlider.desktop.cssEase,
-					dots: lsx_to_params.slickSlider.desktop.dots,
-					slidesToShow: lsx_to_params.slickSlider.desktop.slidesToShow,
-					slidesToScroll: lsx_to_params.slickSlider.desktop.slidesToScroll,
-					autoplay: autoplay,
-					autoplaySpeed: autoplay_speed,
-					appendArrows: $this.parent(),
-					appendDots: $this.parent(),
+					draggable: false,
+					infinite: true,
+					swipe: false,
+					dots: false,
+					slidesToShow: 3,
+					slidesToScroll: 1,
+					autoplay: false,
+					autoplaySpeed: 0,
+					//appendArrows: $this.parent(),
+					//appendDots: $this.parent(),
 					responsive: [
 						{
-							breakpoint: lsx_to_params.slickSlider.tablet.breakpoint,
+							breakpoint: 1028,
 							settings: {
-								slidesToShow:   tabletSlidesToShow,
-								slidesToScroll: tabletSlidesToScroll,
-								draggable: lsx_to_params.slickSlider.tablet.draggable,
-								arrows: lsx_to_params.slickSlider.tablet.arrows,
-								swipe: lsx_to_params.slickSlider.tablet.swipe,
+								slidesToShow:   2,
+								slidesToScroll: 1,
+								draggable: true,
+								arrows: false,
+								swipe: true,
+								dots: true,
 							}
 						},
 						{
-							breakpoint: lsx_to_params.slickSlider.mobile.breakpoint,
+							breakpoint: 782,
 							settings: {
-								slidesToShow:   lsx_to_params.slickSlider.mobile.slidesToShow,
-								slidesToScroll: lsx_to_params.slickSlider.mobile.slidesToScroll,
-								draggable:      lsx_to_params.slickSlider.mobile.draggable,
-								arrows:         lsx_to_params.slickSlider.mobile.arrows,
-								swipe:          lsx_to_params.slickSlider.mobile.swipe
+								slidesToShow:   1,
+								slidesToScroll: 1,
+								draggable: true,
+								arrows: false,
+								swipe: true,
+								dots: true,
 							}
 						}
 					]
 				} );
 			}
 		} );
-
-		if ( window_width < 768 ) {
-			$( '.gallery' ).not('.slick-initialized').slick( {
-				slide: 'dl',
-				arrows: false,
-				draggable: true,
-				infinite: true,
-				swipe: true,
-				cssEase: 'ease-out',
-				dots: true,
-				autoplay: false,
-				responsive: [
-					{
-						breakpoint: 99999,
-						settings: 'unslick'
-					},
-					{
-						breakpoint: 768,
-						setting: {
-							slidesToShow: 1,
-							slidesToScroll: 1
-						}
-					}
-				]
-			} );
-		}
 	};
 
 	/**
@@ -369,9 +313,50 @@

 	} );
 
 	document.addEventListener('DOMContentLoaded', function () {
+		const paragraphs = document.querySelectorAll('.additional-info .wp-block-group.content p');
+	
+		paragraphs.forEach(function (p) {
+			const text = p.innerText.trim();
+	
+			if (text.split(' ').length > 30) {  // Check if paragraph exceeds 30 words
+				const fullText = p.innerText.trim();
+				const truncatedText = fullText.split(' ').slice(0, 30).join(' ') + '...';
+				p.innerHTML = `<span class=""truncated-text"">${truncatedText}</span><span class=""full-text"" style=""display: none;"">${fullText}</span>`;
+	
+				// Create Read More button
+				const readMoreBtn = document.createElement('span');
+				readMoreBtn.textContent = ' Read More';
+				readMoreBtn.classList.add('read-more-btn');
+				p.appendChild(readMoreBtn);
+	
+				// Create Read Less button
+				const readLessBtn = document.createElement('span');
+				readLessBtn.textContent = ' Read Less';
+				readLessBtn.classList.add('read-less-btn');
+				p.appendChild(readLessBtn);
+	
+				// Add functionality to toggle text
+				readMoreBtn.addEventListener('click', function () {
+					p.querySelector('.truncated-text').style.display = 'none';
+					p.querySelector('.full-text').style.display = 'inline';
+					readMoreBtn.style.display = 'none';
+					readLessBtn.style.display = 'inline';
+				});
+	
+				readLessBtn.addEventListener('click', function () {
+					p.querySelector('.truncated-text').style.display = 'inline';
+					p.querySelector('.full-text').style.display = 'none';
+					readMoreBtn.style.display = 'inline';
+					readLessBtn.style.display = 'none';
+				});
+			}
+		});
+	});	
+
+	document.addEventListener('DOMContentLoaded', function () {
 		// Select all sections within `.single-tour-operator`
 		const sections = document.querySelectorAll('.single-tour-operator section.wp-block-group');
-	
+
 		sections.forEach(section => {
 			// Locate the first <h2> within the section
 			const heading = section.querySelector('h2');
@@ -415,5 +400,5 @@

 			}
 		});
 	});
-	
+
 } )( jQuery, window, document );",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/lightspeedwp/tour-operator/pulls/comments/1893912143,https://github.com/lightspeedwp/tour-operator/pull/463#discussion_r1893912143,,25,c5479a61c7b8e9d8fa90c7ff6ca98ce116223f36,e8eacd5dd2d29bfe380c7a4bf508da6d9622fc14,templates/single-accommodation.html,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The width of the first column in the columns block has been reduced from 70% to 65%. This will give more space to the second column, but it may also make the content in the first column appear more condensed.
```diff
- <div class=""wp-block-columns alignwide""><!-- wp:column {""width"":""70%""} -->
+ <div class=""wp-block-columns alignwide""><!-- wp:column {""width"":""65%""} -->
```



<!-- This is an auto-generated comment by OSS CodeRabbit -->","-<div class=""wp-block-column"" style=""flex-basis:70%""><!-- wp:post-content {""align"":""wide"",""layout"":{""type"":""default""}} /-->
+<!-- wp:group {""tagName"":""main"",""metadata"":{""name"":""Description \u0026 Fast Facts""},""align"":""wide"",""style"":{""spacing"":{""padding"":{""top"":""var:preset|spacing|medium"",""bottom"":""var:preset|spacing|medium"",""left"":""var:preset|spacing|x-small"",""right"":""var:preset|spacing|x-small""},""margin"":{""top"":""0"",""bottom"":""0""}}},""backgroundColor"":""base"",""layout"":{""type"":""constrained""}} -->
+<main class=""wp-block-group alignwide has-base-background-color has-background"" style=""margin-top:0;margin-bottom:0;padding-top:var(--wp--preset--spacing--medium);padding-right:var(--wp--preset--spacing--x-small);padding-bottom:var(--wp--preset--spacing--medium);padding-left:var(--wp--preset--spacing--x-small)""><!-- wp:columns {""align"":""wide"",""style"":{""spacing"":{""blockGap"":{""top"":""var:preset|spacing|small"",""left"":""var:preset|spacing|medium""}}}} -->
+<div class=""wp-block-columns alignwide""><!-- wp:column {""width"":""65%""} -->","--- 

+++ 

@@ -69,7 +69,7 @@

 <div class=""wp-block-group fast-facts-wrapper""><!-- wp:group {""metadata"":{""name"":""Rating""},""className"":""lsx-rating-wrapper"",""style"":{""spacing"":{""padding"":{""top"":""0"",""bottom"":""0""},""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap""}} -->
 <div class=""wp-block-group lsx-rating-wrapper"" style=""padding-top:0;padding-bottom:0""><!-- wp:group {""style"":{""spacing"":{""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap"",""verticalAlignment"":""top""}} -->
 <div class=""wp-block-group""><!-- wp:image {""width"":""20px"",""sizeSlug"":""large""} -->
-<figure class=""wp-block-image size-large is-resized""><img src=""https://tourpress.pro/wp-content/uploads/2024/09/rating-icon-TO-black-20px-1.png"" alt="""" style=""width:20px""/></figure>
+<figure class=""wp-block-image size-large is-resized""><img src=""/wp-content/plugins/tour-operator/assets/img/rating-icon-TO-black-20px-1.png"" alt="""" style=""width:20px""/></figure>
 <!-- /wp:image -->
 
 <!-- wp:paragraph {""style"":{""spacing"":{""padding"":{""top"":""2px"",""bottom"":""2px""}}}} -->
@@ -101,7 +101,7 @@

 <!-- wp:group {""metadata"":{""name"":""Number if Rooms""},""className"":""lsx-number-of-rooms-wrapper"",""style"":{""spacing"":{""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap""}} -->
 <div class=""wp-block-group lsx-number-of-rooms-wrapper""><!-- wp:group {""style"":{""spacing"":{""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap"",""verticalAlignment"":""top""}} -->
 <div class=""wp-block-group""><!-- wp:image {""width"":""20px"",""sizeSlug"":""large""} -->
-<figure class=""wp-block-image size-large is-resized""><img src=""https://tourpress.pro/wp-content/uploads/2024/09/TO-accommodation-rooms-icon-black-52px.png"" alt="""" style=""width:20px""/></figure>
+<figure class=""wp-block-image size-large is-resized""><img src=""/wp-content/plugins/tour-operator/assets/img/TO-accommodation-rooms-icon-black-52px.png"" alt="""" style=""width:20px""/></figure>
 <!-- /wp:image -->
 
 <!-- wp:paragraph {""style"":{""spacing"":{""padding"":{""top"":""2px"",""bottom"":""2px""}}}} -->
@@ -119,7 +119,7 @@

 <!-- wp:group {""metadata"":{""name"":""Single Supplement""},""className"":""lsx-single-supplement-wrapper"",""style"":{""spacing"":{""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap""}} -->
 <div class=""wp-block-group lsx-single-supplement-wrapper""><!-- wp:group {""style"":{""spacing"":{""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap"",""verticalAlignment"":""top""}} -->
 <div class=""wp-block-group""><!-- wp:image {""id"":122733,""width"":""20px"",""sizeSlug"":""large"",""linkDestination"":""none""} -->
-<figure class=""wp-block-image size-large is-resized""><img src=""https://tourpress.pro/wp-content/uploads/2024/11/single-supplement-icon-black-52px-1.svg"" alt="""" class=""wp-image-122733"" style=""width:20px""/></figure>
+<figure class=""wp-block-image size-large is-resized""><img src=""/wp-content/plugins/tour-operator/assets/img/single-supplement-icon-black-52px-1.svg"" alt="""" class=""wp-image-122733"" style=""width:20px""/></figure>
 <!-- /wp:image -->
 
 <!-- wp:paragraph {""style"":{""spacing"":{""padding"":{""top"":""2px"",""bottom"":""2px""}}},""fontSize"":""x-small""} -->
@@ -137,7 +137,7 @@

 <!-- wp:group {""metadata"":{""name"":""Check In Time""},""className"":""lsx-checkin-time-wrapper"",""style"":{""spacing"":{""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap""}} -->
 <div class=""wp-block-group lsx-checkin-time-wrapper""><!-- wp:group {""style"":{""spacing"":{""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap"",""verticalAlignment"":""top""}} -->
 <div class=""wp-block-group""><!-- wp:image {""id"":122720,""width"":""20px"",""sizeSlug"":""large"",""linkDestination"":""none"",""className"":""wp-image-122720""} -->
-<figure class=""wp-block-image size-large is-resized wp-image-122720""><img src=""https://tourpress.pro/wp-content/uploads/2024/11/check-in-check-out-time-icon-black-52px-1.svg"" alt="""" class=""wp-image-122720"" style=""width:20px""/></figure>
+<figure class=""wp-block-image size-large is-resized wp-image-122720""><img src=""/wp-content/plugins/tour-operator/assets/img/check-in-check-out-time-icon-black-52px-1.svg"" alt="""" class=""wp-image-122720"" style=""width:20px""/></figure>
 <!-- /wp:image -->
 
 <!-- wp:paragraph {""style"":{""spacing"":{""padding"":{""top"":""2px"",""bottom"":""2px""}}}} -->
@@ -155,7 +155,7 @@

 <!-- wp:group {""metadata"":{""name"":""Check Out Time""},""className"":""lsx-checkout-time-wrapper"",""style"":{""spacing"":{""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap""}} -->
 <div class=""wp-block-group lsx-checkout-time-wrapper""><!-- wp:group {""style"":{""spacing"":{""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap"",""verticalAlignment"":""top""}} -->
 <div class=""wp-block-group""><!-- wp:image {""id"":122720,""width"":""20px"",""sizeSlug"":""large"",""linkDestination"":""none"",""className"":""wp-image-122720""} -->
-<figure class=""wp-block-image size-large is-resized wp-image-122720""><img src=""https://tourpress.pro/wp-content/uploads/2024/11/check-in-check-out-time-icon-black-52px-1.svg"" alt="""" class=""wp-image-122720"" style=""width:20px""/></figure>
+<figure class=""wp-block-image size-large is-resized wp-image-122720""><img src=""/wp-content/plugins/tour-operator/assets/img/check-in-check-out-time-icon-black-52px-1.svg"" alt="""" class=""wp-image-122720"" style=""width:20px""/></figure>
 <!-- /wp:image -->
 
 <!-- wp:paragraph {""style"":{""spacing"":{""padding"":{""top"":""2px"",""bottom"":""2px""}}}} -->
@@ -173,7 +173,7 @@

 <!-- wp:group {""metadata"":{""name"":""Minimum Child Age""},""className"":""lsx-minimum-child-age-wrapper"",""style"":{""spacing"":{""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap""}} -->
 <div class=""wp-block-group lsx-minimum-child-age-wrapper""><!-- wp:group {""style"":{""spacing"":{""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap"",""verticalAlignment"":""top""}} -->
 <div class=""wp-block-group""><!-- wp:image {""id"":122719,""width"":""20px"",""sizeSlug"":""large"",""linkDestination"":""none"",""className"":""wp-image-122719""} -->
-<figure class=""wp-block-image size-large is-resized wp-image-122719""><img src=""https://tourpress.pro/wp-content/uploads/2024/11/minimum-child-age-icon-black-52px-1.svg"" alt="""" class=""wp-image-122719"" style=""width:20px""/></figure>
+<figure class=""wp-block-image size-large is-resized wp-image-122719""><img src=""/wp-content/plugins/tour-operator/assets/img/minimum-child-age-icon-black-52px-1.svg"" alt="""" class=""wp-image-122719"" style=""width:20px""/></figure>
 <!-- /wp:image -->
 
 <!-- wp:paragraph {""style"":{""spacing"":{""padding"":{""top"":""2px"",""bottom"":""2px""}}}} -->
@@ -191,7 +191,7 @@

 <!-- wp:group {""metadata"":{""name"":""Destination to Accommodation""},""className"":""lsx-destination-to-accommodation-wrapper"",""style"":{""spacing"":{""padding"":{""top"":""0"",""bottom"":""0""},""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap""}} -->
 <div class=""wp-block-group lsx-destination-to-accommodation-wrapper"" style=""padding-top:0;padding-bottom:0""><!-- wp:group {""style"":{""spacing"":{""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap"",""verticalAlignment"":""top""}} -->
 <div class=""wp-block-group""><!-- wp:image {""width"":""20px"",""sizeSlug"":""large""} -->
-<figure class=""wp-block-image size-large is-resized""><img src=""https://tourpress.pro/wp-content/uploads/2024/09/Typelocation-icon.png"" alt="""" style=""width:20px""/></figure>
+<figure class=""wp-block-image size-large is-resized""><img src=""/wp-content/plugins/tour-operator/assets/img/Typelocation-icon.png"" alt="""" style=""width:20px""/></figure>
 <!-- /wp:image -->
 
 <!-- wp:paragraph {""style"":{""spacing"":{""padding"":{""top"":""2px"",""bottom"":""2px""}}}} -->
@@ -209,7 +209,7 @@

 <!-- wp:group {""metadata"":{""name"":""Spoken Languages""},""className"":""lsx-spoken-languages-wrapper"",""style"":{""spacing"":{""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap""}} -->
 <div class=""wp-block-group lsx-spoken-languages-wrapper""><!-- wp:group {""style"":{""spacing"":{""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap"",""verticalAlignment"":""top""}} -->
 <div class=""wp-block-group""><!-- wp:image {""width"":""20px"",""sizeSlug"":""large""} -->
-<figure class=""wp-block-image size-large is-resized""><img src=""https://tourpress.pro/wp-content/uploads/2024/09/spoken-languages-TO-icon-black-20px-1.png"" alt="""" style=""width:20px""/></figure>
+<figure class=""wp-block-image size-large is-resized""><img src=""/wp-content/plugins/tour-operator/assets/img/spoken-languages-TO-icon-black-20px-1.png"" alt="""" style=""width:20px""/></figure>
 <!-- /wp:image -->
 
 <!-- wp:paragraph {""style"":{""spacing"":{""padding"":{""top"":""2px"",""bottom"":""2px""}}}} -->
@@ -227,7 +227,7 @@

 <!-- wp:group {""metadata"":{""name"":""Travel Styles""},""className"":""lsx-travel-style-wrapper"",""style"":{""spacing"":{""blockGap"":""5px""},""layout"":{""type"":""constrained""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap""}} -->
 <div class=""wp-block-group lsx-travel-style-wrapper""><!-- wp:group {""style"":{""spacing"":{""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap"",""verticalAlignment"":""top""}} -->
 <div class=""wp-block-group""><!-- wp:image {""width"":""20px"",""sizeSlug"":""large""} -->
-<figure class=""wp-block-image size-large is-resized""><img src=""https://tourpress.pro/wp-content/uploads/2024/06/image-1.png"" alt="""" style=""width:20px""/></figure>
+<figure class=""wp-block-image size-large is-resized""><img src=""/wp-content/plugins/tour-operator/assets/img/image-1.png"" alt="""" style=""width:20px""/></figure>
 <!-- /wp:image -->
 
 <!-- wp:paragraph {""style"":{""spacing"":{""padding"":{""top"":""2px"",""bottom"":""2px""}}},""fontSize"":""x-small""} -->
@@ -243,7 +243,7 @@

 <!-- wp:group {""metadata"":{""name"":""Accommodation Type""},""className"":""lsx-accommodation-type-wrapper"",""style"":{""spacing"":{""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap""}} -->
 <div class=""wp-block-group lsx-accommodation-type-wrapper""><!-- wp:group {""style"":{""spacing"":{""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap"",""verticalAlignment"":""top""}} -->
 <div class=""wp-block-group""><!-- wp:image {""width"":""20px"",""sizeSlug"":""large""} -->
-<figure class=""wp-block-image size-large is-resized""><img src=""https://tourpress.pro/wp-content/uploads/2024/09/accommodation-type-TO-icon-black-20px-2.png"" alt="""" style=""width:20px""/></figure>
+<figure class=""wp-block-image size-large is-resized""><img src=""/wp-content/plugins/tour-operator/assets/img/accommodation-type-TO-icon-black-20px-2.png"" alt="""" style=""width:20px""/></figure>
 <!-- /wp:image -->
 
 <!-- wp:paragraph {""style"":{""spacing"":{""padding"":{""top"":""2px"",""bottom"":""2px""}}}} -->
@@ -259,7 +259,7 @@

 <!-- wp:group {""className"":""lsx-suggested-visitor-types-wrapper"",""style"":{""spacing"":{""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap""}} -->
 <div class=""wp-block-group lsx-suggested-visitor-types-wrapper""><!-- wp:group {""style"":{""spacing"":{""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap"",""verticalAlignment"":""top""}} -->
 <div class=""wp-block-group""><!-- wp:image {""width"":""20px"",""sizeSlug"":""large""} -->
-<figure class=""wp-block-image size-large is-resized""><img src=""https://tourpress.pro/wp-content/uploads/2024/09/friendly-TO-icon-black-20px-1.png"" alt="""" style=""width:20px""/></figure>
+<figure class=""wp-block-image size-large is-resized""><img src=""/wp-content/plugins/tour-operator/assets/img/friendly-TO-icon-black-20px-1.png"" alt="""" style=""width:20px""/></figure>
 <!-- /wp:image -->
 
 <!-- wp:paragraph {""style"":{""spacing"":{""padding"":{""top"":""2px"",""bottom"":""2px""}}}} -->
@@ -277,7 +277,7 @@

 <!-- wp:group {""metadata"":{""name"":""Special Interests""},""className"":""lsx-special-interests-wrapper"",""style"":{""spacing"":{""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap""}} -->
 <div class=""wp-block-group lsx-special-interests-wrapper""><!-- wp:group {""style"":{""spacing"":{""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap"",""verticalAlignment"":""top""}} -->
 <div class=""wp-block-group""><!-- wp:image {""id"":122726,""width"":""20px"",""sizeSlug"":""large"",""linkDestination"":""none""} -->
-<figure class=""wp-block-image size-large is-resized""><img src=""https://tourpress.pro/wp-content/uploads/2024/11/special-interests-icon-black-52px-1.svg"" alt="""" class=""wp-image-122726"" style=""width:20px""/></figure>
+<figure class=""wp-block-image size-large is-resized""><img src=""/wp-content/plugins/tour-operator/assets/img/special-interests-icon-black-52px-1.svg"" alt="""" class=""wp-image-122726"" style=""width:20px""/></figure>
 <!-- /wp:image -->
 
 <!-- wp:paragraph {""style"":{""spacing"":{""padding"":{""top"":""2px"",""bottom"":""2px""}}}} -->
@@ -325,7 +325,7 @@

 <div class=""wp-block-group alignwide has-base-background-color has-background"" style=""border-radius:8px""><!-- wp:columns {""align"":""wide"",""style"":{""spacing"":{""blockGap"":{""left"":""10px""}}}} -->
 <div class=""wp-block-columns alignwide""><!-- wp:column {""width"":""30%""} -->
 <div class=""wp-block-column"" style=""flex-basis:30%""><!-- wp:image {""id"":43376,""aspectRatio"":""4/3"",""scale"":""cover"",""sizeSlug"":""large"",""linkDestination"":""none"",""className"":""unit-image is-style-default"",""style"":{""border"":{""radius"":{""topLeft"":""8px"",""bottomLeft"":""8px""}}}} -->
-<figure class=""wp-block-image size-large has-custom-border unit-image is-style-default""><img src=""https://tourpress.pro/wp-content/uploads/2024/09/dark-grey-image-placeholder-990x1024.png"" alt="""" class=""wp-image-43376"" style=""border-top-left-radius:8px;border-bottom-left-radius:8px;aspect-ratio:4/3;object-fit:cover""/></figure>
+<figure class=""wp-block-image size-large has-custom-border unit-image is-style-default""><img src=""/wp-content/plugins/tour-operator/assets/img/dark-grey-image-placeholder-990x1024.png"" alt="""" class=""wp-image-43376"" style=""border-top-left-radius:8px;border-bottom-left-radius:8px;aspect-ratio:4/3;object-fit:cover""/></figure>
 <!-- /wp:image --></div>
 <!-- /wp:column -->
 
@@ -354,7 +354,7 @@

 <!-- wp:group {""className"":""unit-type-wrapper"",""style"":{""spacing"":{""margin"":{""top"":""0"",""bottom"":""0""},""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap""}} -->
 <div class=""wp-block-group unit-type-wrapper"" style=""margin-top:0;margin-bottom:0""><!-- wp:group {""style"":{""spacing"":{""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap"",""verticalAlignment"":""top""}} -->
 <div class=""wp-block-group""><!-- wp:image {""width"":""20px"",""sizeSlug"":""large""} -->
-<figure class=""wp-block-image size-large is-resized""><img src=""https://tourpress.pro/wp-content/uploads/2024/09/accommodation-type-TO-icon-black-20px-2.png"" alt="""" style=""width:20px""/></figure>
+<figure class=""wp-block-image size-large is-resized""><img src=""/wp-content/plugins/tour-operator/assets/img/accommodation-type-TO-icon-black-20px-2.png"" alt="""" style=""width:20px""/></figure>
 <!-- /wp:image -->
 
 <!-- wp:paragraph {""style"":{""spacing"":{""padding"":{""top"":""2px"",""bottom"":""2px""}}}} -->
@@ -370,7 +370,7 @@

 <!-- wp:group {""className"":""unit-price-wrapper"",""style"":{""spacing"":{""margin"":{""top"":""0"",""bottom"":""0""},""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap""}} -->
 <div class=""wp-block-group unit-price-wrapper"" style=""margin-top:0;margin-bottom:0""><!-- wp:group {""style"":{""spacing"":{""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap"",""verticalAlignment"":""top""}} -->
 <div class=""wp-block-group""><!-- wp:image {""width"":""20px"",""sizeSlug"":""large"",""metadata"":{""bindings"":{""__default"":{""source"":""core/pattern-overrides""}},""name"":""From Price Icon""}} -->
-<figure class=""wp-block-image size-large is-resized""><img src=""https://tourpress.pro/wp-content/uploads/2024/09/from-price-TO-icon-black-20px-1.png"" alt="""" style=""width:20px""/></figure>
+<figure class=""wp-block-image size-large is-resized""><img src=""/wp-content/plugins/tour-operator/assets/img/from-price-TO-icon-black-20px-1.png"" alt="""" style=""width:20px""/></figure>
 <!-- /wp:image -->
 
 <!-- wp:paragraph {""style"":{""spacing"":{""padding"":{""top"":""2px"",""bottom"":""2px""}}}} -->
@@ -542,7 +542,7 @@

 <div class=""wp-block-query alignwide""><!-- wp:post-template {""style"":{""spacing"":{""blockGap"":""var:preset|spacing|small""}},""layout"":{""type"":""grid"",""columnCount"":2}} -->
 <!-- wp:group {""style"":{""spacing"":{""blockGap"":""var:preset|spacing|x-small""}},""layout"":{""type"":""constrained""}} -->
 <div class=""wp-block-group""><!-- wp:image {""sizeSlug"":""large"",""align"":""center""} -->
-<figure class=""wp-block-image aligncenter size-large""><img src=""https://tourpress.pro/wp-content/uploads/2024/09/review-testominal-quote-mark-TO-tertiary-32px.png"" alt=""""/></figure>
+<figure class=""wp-block-image aligncenter size-large""><img src=""/wp-content/plugins/tour-operator/assets/img/review-testominal-quote-mark-TO-tertiary-32px.png"" alt=""""/></figure>
 <!-- /wp:image -->
 
 <!-- wp:post-excerpt {""textAlign"":""center"",""showMoreOnNewLine"":false,""excerptLength"":40} /-->",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/comments/1807477939,https://github.com/parkpow/deep-license-plate-recognition/pull/219#discussion_r1807477939,5,36,42f0016b41535fdb9769e9948fe0139596842150,7645a7ff134a797c1d8f5a6fa166a00bcf62b8fe,snapshot-middleware/src/utils.js,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The retry logic in `fetchWithRetry` could be improved by adding exponential backoff to avoid overwhelming the server with requests. Here's a suggested change:

```diff
- const delay = 2000;
+ const delay = Math.pow(2, 3 - tries) * 1000; // Exponential backoff
```

This change will increase the delay between retries exponentially, which is a common practice for handling rate limits and server errors more gracefully.


<!-- This is an auto-generated comment by OSS CodeRabbit -->","+export const fetchWithRetry = (url, init, tries = 3) =>
+	fetch(url, init)
+		.then(async (response) => {
+			if (response.ok) {
+				return response;
+			} else {
+				// 1. throw a new exception
+				if (response.status === 429)
+					throw new Error429(""Rate Limited"", response);
+				if (response.status >= 500 && response.status <= 599)
+					throw new Error5xx(`Server Error - ${response.status}`, response);
+
+				console.error(await response.text());
+				// 2. reject instead of throw, preferred
+				const errorMessage = `Unexpected Response: ${response.status}`;
+				return Promise.reject(new Error(errorMessage));
+			}
+		})
+		.catch((error) => {
+			// Retry network error or 5xx errors
+			if (
+				(error instanceof Error429 || error instanceof Error5xx) &&
+				tries > 0
+			) {
+				console.error(`Retry Response status: ${error.message}`);
+				// if the rate limit is reached or exceeded,
+				const delay = 2000;
+				return wait(delay).then(() => fetchWithRetry(url, init, tries - 1));
+			} else {
+				throw error;
+			}
+		});","--- 

+++ 

@@ -2,35 +2,36 @@

 
 const wait = (delay) => new Promise((resolve) => setTimeout(resolve, delay));
 
-export const fetchWithRetry = (url, init, tries = 3) =>
-	fetch(url, init)
-		.then(async (response) => {
-			if (response.ok) {
-				return response;
-			} else {
-				// 1. throw a new exception
-				if (response.status === 429)
-					throw new Error429(""Rate Limited"", response);
-				if (response.status >= 500 && response.status <= 599)
-					throw new Error5xx(`Server Error - ${response.status}`, response);
+export function fetchWithRetry(url, init, tries = 3) {
+  return fetch(url, init)
+    .then(async (response) => {
+      if (response.ok) {
+        return response;
+      } else {
+        // 1. throw a new exception
+        if (response.status === 429)
+          throw new Error429(""Rate Limited"", response);
+        if (response.status >= 500 && response.status <= 599)
+          throw new Error5xx(`Server Error - ${response.status}`, response);
 
-				console.error(await response.text());
-				// 2. reject instead of throw, preferred
-				const errorMessage = `Unexpected Response: ${response.status}`;
-				return Promise.reject(new Error(errorMessage));
-			}
-		})
-		.catch((error) => {
-			// Retry network error or 5xx errors
-			if (
-				(error instanceof Error429 || error instanceof Error5xx) &&
-				tries > 0
-			) {
-				console.error(`Retry Response status: ${error.message}`);
-				// if the rate limit is reached or exceeded,
-				const delay = 2000;
-				return wait(delay).then(() => fetchWithRetry(url, init, tries - 1));
-			} else {
-				throw error;
-			}
-		});
+        console.error(await response.text());
+        // 2. reject instead of throw, preferred
+        const errorMessage = `Unexpected Response: ${response.status}`;
+        return Promise.reject(new Error(errorMessage));
+      }
+    })
+    .catch((error) => {
+      // Retry network error or 5xx errors
+      if (
+        (error instanceof Error429 || error instanceof Error5xx) &&
+        tries > 0
+      ) {
+        console.log(`Retrying request: ${tries}`);
+        // if the rate limit is reached or exceeded,
+        const delay = 2000;
+        return wait(delay).then(() => fetchWithRetry(url, init, tries - 1));
+      } else {
+        throw error;
+      }
+    });
+}",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/lightspeedwp/tour-operator/pulls/comments/1893912122,https://github.com/lightspeedwp/tour-operator/pull/463#discussion_r1893912122,,2,c5479a61c7b8e9d8fa90c7ff6ca98ce116223f36,e8eacd5dd2d29bfe380c7a4bf508da6d9622fc14,templates/single-region.html,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The theme reference ""lsx-tour-operator"" has been removed from the header template part. This could potentially cause issues if there are styles or scripts specifically tied to this theme in your WordPress setup. If the removal is intentional and you've ensured that no dependencies are broken, then it's fine. Otherwise, you might want to reconsider this change.
```diff
- <!-- wp:template-part {""slug"":""header-2-0"",""theme"":""lsx-tour-operator""} /-->
+ <!-- wp:template-part {""slug"":""header"",""area"":""header""} /-->
```


<!-- This is an auto-generated comment by OSS CodeRabbit -->","@@ -1,5 +1,5 @@
 <!-- wp:group {""style"":{""position"":{""type"":""sticky"",""top"":""0px""}},""layout"":{""type"":""default""}} -->
-<div class=""wp-block-group""><!-- wp:template-part {""slug"":""header-2-0"",""theme"":""lsx-tour-operator""} /--></div>
+<div class=""wp-block-group""><!-- wp:template-part {""slug"":""header"",""area"":""header""} /--></div>","--- 

+++ 

@@ -42,7 +42,7 @@

 <div class=""wp-block-group""><!-- wp:group {""metadata"":{""name"":""Country""},""className"":""facts-country-query-wrapper"",""style"":{""spacing"":{""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap""}} -->
 <div class=""wp-block-group facts-country-query-wrapper""><!-- wp:group {""style"":{""spacing"":{""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap"",""verticalAlignment"":""top""}} -->
 <div class=""wp-block-group""><!-- wp:image {""width"":""20px"",""sizeSlug"":""large""} -->
-<figure class=""wp-block-image size-large is-resized""><img src=""https://tour-operator.lightspeedwp.dev/wp-content/uploads/2024/09/destinations-icon-black-20px.png"" alt="""" style=""width:20px""/></figure>
+<figure class=""wp-block-image size-large is-resized""><img src=""/wp-content/plugins/tour-operator/assets/img/destinations-icon-black-20px.png"" alt="""" style=""width:20px""/></figure>
 <!-- /wp:image -->
 
 <!-- wp:paragraph {""style"":{""spacing"":{""padding"":{""top"":""0"",""bottom"":""0""}}},""fontSize"":""x-small""} -->
@@ -60,7 +60,7 @@

 <!-- wp:group {""metadata"":{""name"":""Travel Styles""},""className"":""lsx-travel-style-wrapper"",""style"":{""spacing"":{""blockGap"":""5px""},""layout"":{""type"":""constrained""}},""layout"":{""type"":""constrained""}} -->
 <div class=""wp-block-group lsx-travel-style-wrapper""><!-- wp:group {""style"":{""spacing"":{""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap"",""verticalAlignment"":""top""}} -->
 <div class=""wp-block-group""><!-- wp:image {""id"":61710,""width"":""20px"",""sizeSlug"":""full"",""linkDestination"":""none"",""className"":""is-resized""} -->
-<figure class=""wp-block-image size-full is-resized""><img src=""https://tour-operator.lightspeedwp.dev/wp-content/uploads/2024/06/image-1.png"" alt="""" class=""wp-image-61710"" style=""width:20px""/></figure>
+<figure class=""wp-block-image size-full is-resized""><img src=""/wp-content/plugins/tour-operator/assets/img/image-1.png"" alt="""" class=""wp-image-61710"" style=""width:20px""/></figure>
 <!-- /wp:image -->
 
 <!-- wp:paragraph {""style"":{""spacing"":{""padding"":{""top"":""2px"",""bottom"":""2px""}}},""fontSize"":""x-small""} -->
@@ -76,7 +76,7 @@

 <!-- wp:group {""metadata"":{""name"":""Best Time to Visit""},""className"":""lsx-best-time-to-visit-wrapper"",""style"":{""spacing"":{""blockGap"":""5px""},""layout"":{""type"":""constrained""}},""layout"":{""type"":""constrained""}} -->
 <div class=""wp-block-group lsx-best-time-to-visit-wrapper""><!-- wp:group {""style"":{""spacing"":{""blockGap"":""5px""}},""layout"":{""type"":""flex"",""flexWrap"":""nowrap"",""verticalAlignment"":""top""}} -->
 <div class=""wp-block-group""><!-- wp:image {""id"":61709,""width"":""20px"",""sizeSlug"":""full"",""linkDestination"":""none"",""className"":""is-resized""} -->
-<figure class=""wp-block-image size-full is-resized""><img src=""https://tour-operator.lightspeedwp.dev/wp-content/uploads/2024/06/image.png"" alt="""" class=""wp-image-61709"" style=""width:20px""/></figure>
+<figure class=""wp-block-image size-full is-resized""><img src=""/wp-content/plugins/tour-operator/assets/img/image.png"" alt="""" class=""wp-image-61709"" style=""width:20px""/></figure>
 <!-- /wp:image -->
 
 <!-- wp:paragraph {""style"":{""spacing"":{""padding"":{""top"":""2px"",""bottom"":""2px""}}},""fontSize"":""x-small""} -->
@@ -200,7 +200,7 @@

 <div class=""wp-block-query alignwide""><!-- wp:post-template {""style"":{""spacing"":{""blockGap"":""var:preset|spacing|small""}},""layout"":{""type"":""grid"",""columnCount"":2}} -->
 <!-- wp:group {""style"":{""spacing"":{""blockGap"":""var:preset|spacing|x-small""}},""layout"":{""type"":""constrained""}} -->
 <div class=""wp-block-group""><!-- wp:image {""sizeSlug"":""large"",""align"":""center""} -->
-<figure class=""wp-block-image aligncenter size-large""><img src=""https://tour-operator.lightspeedwp.dev/wp-content/uploads/2024/09/review-testominal-quote-mark-TO-tertiary-32px.png"" alt=""""/></figure>
+<figure class=""wp-block-image aligncenter size-large""><img src=""/wp-content/plugins/tour-operator/assets/img/review-testominal-quote-mark-TO-tertiary-32px.png"" alt=""""/></figure>
 <!-- /wp:image -->
 
 <!-- wp:post-excerpt {""textAlign"":""center"",""showMoreOnNewLine"":false,""excerptLength"":40} /-->",,,,
aidar-freeed(merged)/ai-codereviewer,https://api.github.com/repos/aidar-freeed/ai-codereviewer/pulls/comments/1174425511,https://github.com/aidar-freeed/ai-codereviewer/pull/10#discussion_r1174425511,,266,97bdebd58573233576537253b7e2c3870acda9b1,07b4e53660f659896135241f708e9811a19cb8e6,src/main.ts,nan,Consider using a more descriptive function name instead of `main` to better indicate the purpose of the function.,"-})().catch((error) => {
+}
+
+main().catch((error) => {","--- 

+++ 

@@ -196,24 +196,19 @@

 async function main() {
   const prDetails = await getPRDetails();
   let diff: string | null;
-  console.log(""Running the action..."");
-  console.log(""Event name:"", process.env.GITHUB_EVENT_NAME);
-  if (process.env.GITHUB_EVENT_NAME === ""pull_request"") {
-    console.log(""Pull request event"");
+  const eventData = JSON.parse(
+    readFileSync(process.env.GITHUB_EVENT_PATH ?? """", ""utf8"")
+  );
+
+  if (eventData.action === ""opened"") {
     diff = await getDiff(
       prDetails.owner,
       prDetails.repo,
       prDetails.pull_number
     );
-  } else if (process.env.GITHUB_EVENT_NAME === ""push"") {
-    console.log(""Push event"");
-    const pushEvent = JSON.parse(
-      readFileSync(process.env.GITHUB_EVENT_PATH || """", ""utf8"")
-    );
-    console.log(""Push event:"");
-    console.log(pushEvent);
-    const newBaseSha = pushEvent.before;
-    const newHeadSha = pushEvent.after;
+  } else if (eventData.action === ""synchronize"") {
+    const newBaseSha = eventData.before;
+    const newHeadSha = eventData.after;
 
     const response = await octokit.repos.compareCommits({
       owner: prDetails.owner,
@@ -227,8 +222,6 @@

           .request({ url: response.data.diff_url })
           .then((res) => res.data)
       : null;
-    console.log(""Diff:"");
-    console.log(diff);
   } else {
     console.log(""Unsupported event:"", process.env.GITHUB_EVENT_NAME);
     return;",,,,
aidar-freeed(merged)/ai-codereviewer,https://api.github.com/repos/mt-krainski/yet-another-flight-scanner/pulls/comments/1694359392,https://github.com/mt-krainski/yet-another-flight-scanner/pull/3#discussion_r1694359392,,13,87652e0cba73d01cac5adf4bd562bcbc11b5fbe2,086369f50abefac5fe84f6551540c2cf3531ffa3,.github/workflows/ci.yml,nan,The change from `issues: write` to `pull-requests: write` should be reviewed for its implications on the workflow. Ensure that the permissions align with the intended functionality of the CI process.," 
 permissions:
   contents: write
+  pull-requests: write","--- 

+++ 

@@ -7,10 +7,6 @@

   pull_request:
     branches:
       - main
-
-permissions:
-  contents: write
-  pull-requests: write
 
 jobs:
   test-yafs:
@@ -70,6 +66,8 @@

     needs: [test-yafs]
     runs-on: ubuntu-latest
     if: ${{ github.event_name == 'pull_request'}}
+    permissions:
+      pull-requests: write
     steps:
       - name: Check out repository
         uses: actions/checkout@v4
@@ -86,6 +84,8 @@

     needs: [test-yafs]
     runs-on: ubuntu-latest
     if: ${{ github.actor == 'dependabot[bot]' && github.event_name == 'pull_request'}}
+    permissions:
+      contents: write
     steps:
       - name: Dependabot metadata
         id: metadata",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/brisen-app/brisen-client/pulls/comments/1536659561,https://github.com/brisen-app/brisen-client/pull/3#discussion_r1536659561,36,43,a2f6c10a61c8310250c76a17d8514b7f4063d2cc,ccad80f2210c4994adca60df93cc4043733bbfe1,.github/workflows/preview.yml,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

This commented-out section for adding a comment to the PR with the QR code seems like a useful feature. If there's no specific reason for it being commented out, consider uncommenting it to provide this functionality.

```diff
-       # TODO: Add a comment to the PR with the QR code
-       # - name: Add Comment To PR
-       #   uses: mshick/add-pr-comment@v1
-       #   with:
-       #     message: |
-       #       ## Application
-       #       ![Expo QR](https://api.qrserver.com/v1/create-qr-code/?size=250x250&data=exp://exp.host/${{ env.EXPO_PROJECT }}?release-channel=pr${{ github.event.number }})
-       #       Published to https://exp.host/${{ env.EXPO_PROJECT }}?
+       - name: Add Comment To PR
+         uses: mshick/add-pr-comment@v1
+         with:
+           message: |
+             ## Application
+             ![Expo QR](https://api.qrserver.com/v1/create-qr-code/?size=250x250&data=exp://exp.host/${{ env.EXPO_PROJECT }}?release-channel=pr${{ github.event.number }})
+             Published to https://exp.host/${{ env.EXPO_PROJECT }}?
```



<!-- This is an auto-generated comment by OSS CodeRabbit -->","+      # TODO: Add a comment to the PR with the QR code
+      # - name: Add Comment To PR
+      #   uses: mshick/add-pr-comment@v1
+      #   with:
+      #     message: |
+      #       ## Application
+      #       ![Expo QR](https://api.qrserver.com/v1/create-qr-code/?size=250x250&data=exp://exp.host/${{ env.EXPO_PROJECT }}?release-channel=pr${{ github.event.number }})
+      #       Published to https://exp.host/${{ env.EXPO_PROJECT }}?","--- 

+++ 

@@ -3,9 +3,13 @@

 on:
   pull_request:
 
+concurrency:
+  group: ${{ github.workflow }}-${{ github.ref }}
+  cancel-in-progress: true
+
 jobs:
   update-preview:
-    name: 🚀 Create Expo Preview
+    name: 🔨 Create
     runs-on: ubuntu-latest
     env:
       GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
@@ -16,13 +20,12 @@

 
       - name: 🏗 Setup Node
         uses: actions/setup-node@v3
-        with:
-          node-version: ${{ vars.NODE_VERSION }}
 
       - name: 🏗 Setup EAS
         uses: expo/expo-github-action@v8
         with:
           eas-version: latest
+          packager: npm
           token: ${{ secrets.EXPO_TOKEN }}
 
       - name: 📦 Install dependencies
@@ -32,12 +35,3 @@

         uses: expo/expo-github-action/preview@v8
         with:
           command: eas update --auto --branch ${{ github.event.pull_request.head.ref }}
-
-      # TODO: Add a comment to the PR with the QR code
-      # - name: Add Comment To PR
-      #   uses: mshick/add-pr-comment@v1
-      #   with:
-      #     message: |
-      #       ## Application
-      #       ![Expo QR](https://api.qrserver.com/v1/create-qr-code/?size=250x250&data=exp://exp.host/${{ env.EXPO_PROJECT }}?release-channel=pr${{ github.event.number }})
-      #       Published to https://exp.host/${{ env.EXPO_PROJECT }}?",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/saiqulhaq/dynamic_links/pulls/comments/1443729345,https://github.com/saiqulhaq/dynamic_links/pull/19#discussion_r1443729345,93,104,f54cf91138e8e8a62befa00fb657e55f33852cfb,67675ef2633001974317dae9fc570ecf17a48936,lib/dynamic_links.rb,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The `process_url_synchronously` method has a TODO comment on line 96 about handling issues when failing to save a record. It's important to handle this case to prevent data inconsistency. Consider adding error handling or logging to ensure that any issues are caught and addressed.

```diff
  # TODO Handle issue when failed to save record
  def self.process_url_synchronously(url, short_url, client, strategy)
    if strategy.always_growing?
      begin
        ShortenedUrl.create!(client: client, url: url, short_url: short_url)
      rescue => e
        Rails.logger.error(""Failed to create ShortenedUrl: #{e.message}"")
      end
    else
      begin
        ShortenedUrl.create_or_update(client, short_url, url)
      rescue => e
        Rails.logger.error(""Failed to create or update ShortenedUrl: #{e.message}"")
      end
    end
    URI::Generic.build({scheme: client.scheme, host: client.hostname, path: ""/#{short_url}""}).to_s
  end
```


<!-- This is an auto-generated comment by OSS CodeRabbit -->","+
+  private
+
+  # TODO Handle issue when failed to save record
+  def self.process_url_synchronously(url, short_url, client, strategy)
+    if strategy.always_growing?
+      ShortenedUrl.create!(client: client, url: url, short_url: short_url)
+    else
+      ShortenedUrl.create_or_update(client, short_url, url)
+    end
+    URI::Generic.build({scheme: client.scheme, host: client.hostname, path: ""/#{short_url}""}).to_s
+  end","--- 

+++ 

@@ -21,14 +21,12 @@

 
 require ""dynamic_links/version""
 require ""dynamic_links/engine""
+require ""dynamic_links/logger""
 require ""dynamic_links/error_classes""
+require ""dynamic_links/redis_config""
 require ""dynamic_links/configuration""
-require ""dynamic_links/redis_config""
 require ""dynamic_links/validator""
 require ""dynamic_links/strategy_factory""
-require 'dynamic_links/cache_store/base_cache_store'
-require 'dynamic_links/cache_store/redis_cache_store'
-require 'dynamic_links/cache_store/memcached_cache_store'
 require ""dynamic_links/shortening_strategies/base_strategy""
 require ""dynamic_links/shortening_strategies/sha256_strategy""
 require ""dynamic_links/shortening_strategies/md5_strategy""
@@ -36,6 +34,8 @@

 require ""dynamic_links/shortening_strategies/nano_id_strategy""
 require ""dynamic_links/shortening_strategies/redis_counter_strategy""
 require ""dynamic_links/shortening_strategies/mock_strategy""
+require ""dynamic_links/async/locker""
+require ""dynamic_links/shortener""
 
 module DynamicLinks
   class << self
@@ -53,32 +53,13 @@

   def self.shorten_url(url, client, async: DynamicLinks.configuration.async_processing)
     raise InvalidURIError, 'Invalid URL' unless Validator.valid_url?(url)
 
-    strategy_key = DynamicLinks.configuration.shortening_strategy
-    strategy = StrategyFactory.get_strategy(strategy_key)
-    short_url = strategy.shorten(url)
-
+    shortener = Shortener.new
     if async
-      lock_key = ""lock:shorten_url:#{short_url}""
-      cache_store = DynamicLinks.configuration.cache_store
-
-      if cache_store.read(lock_key)
-        # Return the short url if it is already in the cache
-        return URI::Generic.build({scheme: client.scheme, host: client.hostname, path: ""/#{short_url}""}).to_s
-      end
-
-      # Set a lock and store data in cache
-      cache_store.write(lock_key, 'locked', { expires_in: 10.minutes })
-      cache_key = ""shorten_url:#{client.id}:#{short_url}""
-      cache_store.write(cache_key, { url: url, short_url: short_url })
-
-      ShortenUrlJob.perform_later(client, url, short_url, lock_key)
-      URI::Generic.build({scheme: client.scheme, host: client.hostname, path: ""/#{short_url}""}).to_s
+      shortener.shorten_async(client, url)
     else
-      # Synchronous processing
-      process_url_synchronously(url, short_url, client, strategy)
+      shortener.shorten(client, url)
     end
   end
-
 
   # mimic Firebase Dynamic Links API
   def self.generate_short_url(original_url, client)
@@ -90,16 +71,4 @@

       warning: []
     }
   end
-
-  private
-
-  # TODO Handle issue when failed to save record
-  def self.process_url_synchronously(url, short_url, client, strategy)
-    if strategy.always_growing?
-      ShortenedUrl.create!(client: client, url: url, short_url: short_url)
-    else
-      ShortenedUrl.create_or_update(client, short_url, url)
-    end
-    URI::Generic.build({scheme: client.scheme, host: client.hostname, path: ""/#{short_url}""}).to_s
-  end
 end",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/Dev-FE-1/Toy_Project_II_team4/pulls/comments/1706229007,https://github.com/Dev-FE-1/Toy_Project_II_team4/pull/108#discussion_r1706229007,18,19,71021125c31073b3b703df2332fe2dcbbbfd89e0,9d9bb5d43e6180ef74fdc7f47cf776701a5003ce,src/pages/salaryList/NoticeCard.tsx,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The `salaryList` is derived from the fetched data using the provided `userId`. If no data is found for the given `userId`, an empty array is returned. This is a good practice as it prevents potential errors when trying to access properties on `undefined`. The sorting of the `salaryList` is done in place which might lead to unexpected behavior if the original data is needed elsewhere in its initial order.

```diff
+   const salaryList = data?.salaryDetails[userId] || []
+   salaryList.sort((a,b) => b.id-a.id)
```



<!-- This is an auto-generated comment by OSS CodeRabbit -->","+  const salaryList = data?.salaryDetails[userId] || []
+  salaryList.sort((a,b) => b.id-a.id) ","--- 

+++ 

@@ -1,22 +1,18 @@

 import * as Styled from './NoticeCard.style';
 import Btn from '../../components/button/Button';
-import useSalaryDetails from './useSalaryDetails';
+import { SalaryDataItem } from './api/fetchSalaryInfo';
 import { useNavigate } from ""react-router-dom"";
 import dayjs from ""dayjs"";
 
 type noticeData = {
-  userId:string;
+  salaryList? : Array<SalaryDataItem> 
   button?: boolean;
   label?: React.ReactNode;
 };
 
 
-export default function NoticeCard({ userId, button = false, label}: noticeData) {
-  const navigate = useNavigate()
-  const {data} = useSalaryDetails()
-
-  const salaryList = data?.salaryDetails[userId] || []
-  salaryList.sort((a,b) => b.id-a.id) 
+export default function NoticeCard({ salaryList=[], button = false, label}: noticeData) {
+  const navigate = useNavigate() 
 
   const handleApplicationBtn = (id:number) => {
     if(salaryList.find((item) => item.id === id)){",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/saiqulhaq/dynamic_links/pulls/comments/1443682782,https://github.com/saiqulhaq/dynamic_links/pull/19#discussion_r1443682782,53,78,53664e479de24bcabfbf1c4fdd12423bafb5865e,67675ef2633001974317dae9fc570ecf17a48936,test/dynamic_links_test.rb,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

This test helper method `simulate_shorten_url` seems to be doing a lot of things - configuring the DynamicLinks module, setting up mocks, stubbing methods, and even making assertions. This violates the Single Responsibility Principle (SRP) and makes the method harder to understand and maintain. Consider breaking it down into smaller, more focused methods.
For example, you could have one method for configuration, another for setting up mocks, and another for making assertions. This would make your tests cleaner and easier to read and maintain.


<!-- This is an auto-generated comment by OSS CodeRabbit -->","+  def simulate_shorten_url(strategy, async, cache_store_config = { type: nil, redis_config: {}, memcached_config: {} })
+    DynamicLinks.configure do |config|
+      config.shortening_strategy = strategy
+      config.async_processing = async
+      config.cache_store_config = cache_store_config
+    end
+
+    strategy_mock = Minitest::Mock.new
+    expected_short_path = 'shortened_url'
+    full_short_url = ""#{@client.scheme}://#{@client.hostname}/#{expected_short_path}""
+    strategy_mock.expect :shorten, expected_short_path, ['https://example.com']
+    strategy_mock.expect :always_growing?, false if !async
+
+    cache_store_mock = Minitest::Mock.new
+    cache_key = ""shorten_url:#{@client.id}:#{expected_short_path}""
+    cache_store_mock.expect :write, nil, [cache_key, { url: 'https://example.com', short_url: expected_short_path }]
+
+    DynamicLinks::ShorteningStrategies::MockStrategy.stub :new, strategy_mock do
+      DynamicLinks.configuration.stub :cache_store, cache_store_mock do
+        assert_equal full_short_url, DynamicLinks.shorten_url('https://example.com', @client)
+      end
+    end
+
+    strategy_mock.verify
+    cache_store_mock.verify if async
+  end","--- 

+++ 

@@ -2,78 +2,7 @@

 require ""minitest/mock""
 
 class DynamicLinksTest < ActiveSupport::TestCase
-  def setup
-    @original_strategy = DynamicLinks.configuration.shortening_strategy
-    @original_async = DynamicLinks.configuration.async_processing
-    @original_cache_store_config = DynamicLinks.configuration.cache_store_config
-    @client = dynamic_links_clients(:one)
-  end
-
-  # Reset the configuration after each test
-  def teardown
-    DynamicLinks.configuration.shortening_strategy = @original_strategy
-    DynamicLinks.configuration.async_processing = @original_async
-    DynamicLinks.configuration.cache_store_config = @original_cache_store_config
-  end
-
   test ""it has a version number"" do
     assert DynamicLinks::VERSION
   end
-
-  test ""shorten_url invokes the correct strategy and shortens URL synchronously"" do
-    simulate_shorten_url(:mock, false)
-  end
-
-  test ""shorten_url invokes the correct strategy and shortens URL asynchronously"" do
-    simulate_shorten_url(:mock, true, {
-      type: :redis, redis_config: {}
-    })
-  end
-
-  test ""generate_short_url returns the correct structure"" do
-    DynamicLinks.configure do |config|
-      config.shortening_strategy = :mock
-    end
-
-    expected_short_path = 'shortened_url'
-    full_short_url = ""#{@client.scheme}://#{@client.hostname}/#{expected_short_path}""
-    expected_response = {
-      shortLink: full_short_url,
-      previewLink: ""#{full_short_url}?preview=true"",
-      warning: []
-    }
-
-    DynamicLinks.stub :shorten_url, full_short_url do
-      assert_equal expected_response, DynamicLinks.generate_short_url('https://example.com', @client)
-    end
-  end
-
-  private
-
-  def simulate_shorten_url(strategy, async, cache_store_config = { type: nil, redis_config: {}, memcached_config: {} })
-    DynamicLinks.configure do |config|
-      config.shortening_strategy = strategy
-      config.async_processing = async
-      config.cache_store_config = cache_store_config
-    end
-
-    strategy_mock = Minitest::Mock.new
-    expected_short_path = 'shortened_url'
-    full_short_url = ""#{@client.scheme}://#{@client.hostname}/#{expected_short_path}""
-    strategy_mock.expect :shorten, expected_short_path, ['https://example.com']
-    strategy_mock.expect :always_growing?, false if !async
-
-    cache_store_mock = Minitest::Mock.new
-    cache_key = ""shorten_url:#{@client.id}:#{expected_short_path}""
-    cache_store_mock.expect :write, nil, [cache_key, { url: 'https://example.com', short_url: expected_short_path }]
-
-    DynamicLinks::ShorteningStrategies::MockStrategy.stub :new, strategy_mock do
-      DynamicLinks.configuration.stub :cache_store, cache_store_mock do
-        assert_equal full_short_url, DynamicLinks.shorten_url('https://example.com', @client)
-      end
-    end
-
-    strategy_mock.verify
-    cache_store_mock.verify if async
-  end
 end",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/Dev-FE-1/Toy_Project_II_team4/pulls/comments/1706228994,https://github.com/Dev-FE-1/Toy_Project_II_team4/pull/108#discussion_r1706228994,,38,71021125c31073b3b703df2332fe2dcbbbfd89e0,9d9bb5d43e6180ef74fdc7f47cf776701a5003ce,src/pages/salaryList/SalaryListPage.tsx,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

Passing `userId` as a prop to `NoticeCard` is a good move as it makes the component more reusable and less dependent on the parent component's data structure.
```diff
- <NoticeCard date={finalDate} day={finalDay}/>
+ <NoticeCard userId={userId}/>
```


<!-- This is an auto-generated comment by OSS CodeRabbit -->","     <Styled.Salary>
       <Heading title=""급여정산""/>
-      <NoticeCard date={finalDate} day={finalDay}/>
+      <NoticeCard userId={userId}/>","--- 

+++ 

@@ -22,10 +22,10 @@

   if (error) {return <div>Error: {error.message}</div>}
 
   const salaryList = data?.salaryDetails[userId] || [] 
-  salaryList.sort((a,b) => b.id-a.id)
+  const sortedSalaryList = [...salaryList].sort((a,b) => b.id-a.id)
 
   const handleApplicationBtn = (id:number) => {
-    if(salaryList.find((item) => item.id === id)){
+    if(sortedSalaryList.find((item) => item.id === id)){
       navigate(`/salary-detail/${id}`)
     }else{
           console.error('급여 명세서가 없습니다.')
@@ -35,7 +35,7 @@

   return(
     <Styled.Salary>
       <Heading title=""급여정산""/>
-      <NoticeCard userId={userId}/>
+      <NoticeCard salaryList={sortedSalaryList}/>
         <Styled.YearSelect>
         <SelectBox 
           labelId=""SalaryYear"" 
@@ -44,7 +44,7 @@

           menuItems={years}
         />
       </Styled.YearSelect>
-        {salaryList.map((el)=>
+        {sortedSalaryList.map((el)=>
           (<Styled.ListCardBox key={el.id} $state={el.state} 
             onClick={()=>{handleApplicationBtn(el.id)}}>
             <Styled.List $state={el.state}>",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/saiqulhaq/dynamic_links/pulls/comments/1443727281,https://github.com/saiqulhaq/dynamic_links/pull/19#discussion_r1443727281,13,15,f989cc012d0e70089de3d7d90d5feb8b09191209,67675ef2633001974317dae9fc570ecf17a48936,test/dynamic_links_test.rb,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The `before_all` method is not a standard Rails test lifecycle method. It seems like you want to clear the cache store before each test run. You should use `setup` or `before_each` instead.
```diff
-  def before_all
+  def setup
     DynamicLinks.configuration.cache_store.clear
   end
```



<!-- This is an auto-generated comment by OSS CodeRabbit -->","+  def before_all
+    DynamicLinks.configuration.cache_store.clear
+  end","--- 

+++ 

@@ -2,103 +2,7 @@

 require ""minitest/mock""
 
 class DynamicLinksTest < ActiveSupport::TestCase
-  def setup
-    @original_strategy = DynamicLinks.configuration.shortening_strategy
-    @original_async = DynamicLinks.configuration.async_processing
-    @original_cache_store_config = DynamicLinks.configuration.cache_store_config
-    @client = dynamic_links_clients(:one)
-  end
-
-  # clear cache store every run
-  def before_all
-    DynamicLinks.configuration.cache_store.clear
-  end
-
-  # Reset the configuration after each test
-  def teardown
-    DynamicLinks.configuration.shortening_strategy = @original_strategy
-    DynamicLinks.configuration.async_processing = @original_async
-    DynamicLinks.configuration.cache_store_config = @original_cache_store_config
-  end
-
   test ""it has a version number"" do
     assert DynamicLinks::VERSION
   end
-
-  test ""shorten_url invokes the correct strategy and shortens URL synchronously"" do
-    simulate_shorten_url(:mock, false)
-  end
-
-  test ""shorten_url invokes the correct strategy and shortens URL asynchronously with condition lock key is empty"" do
-    simulate_shorten_url(:mock, true, {
-      type: :redis, redis_config: { host: 'redis', port: 6379 }
-    }, false)
-  end
-
-  test ""shorten_url invokes the correct strategy and shortens URL asynchronously with condition lock key is not empty"" do
-    simulate_shorten_url(:mock, true, {
-      type: :redis, redis_config: { host: 'redis', port: 6379 }
-    }, true)
-  end
-
-  test ""generate_short_url returns the correct structure"" do
-    DynamicLinks.configure do |config|
-      config.shortening_strategy = :mock
-    end
-
-    expected_short_path = 'shortened_url'
-    full_short_url = ""#{@client.scheme}://#{@client.hostname}/#{expected_short_path}""
-    expected_response = {
-      shortLink: full_short_url,
-      previewLink: ""#{full_short_url}?preview=true"",
-      warning: []
-    }
-
-    DynamicLinks.stub :shorten_url, full_short_url do
-      assert_equal expected_response, DynamicLinks.generate_short_url('https://example.com', @client)
-    end
-  end
-
-  private
-
-  def simulate_shorten_url(strategy,
-                           async,
-                           cache_store_config = DynamicLinks::Configuration::DEFAULT_CACHE_STORE_CONFIG,
-                           lock_key_exists = false)
-    DynamicLinks.configure do |config|
-      config.shortening_strategy = strategy
-      config.async_processing = async
-      config.cache_store_config = cache_store_config
-    end
-
-    strategy_mock = Minitest::Mock.new
-    expected_short_path = 'shortened_url'
-    full_short_url = ""#{@client.scheme}://#{@client.hostname}/#{expected_short_path}""
-    strategy_mock.expect :shorten, expected_short_path, ['https://example.com']
-    strategy_mock.expect :always_growing?, false if !async
-
-    cache_store_mock = Minitest::Mock.new
-    cache_key = ""shorten_url:#{@client.id}:#{expected_short_path}""
-    lock_key = ""lock:shorten_url:#{expected_short_path}""
-    cache_store_mock.expect :read, lock_key_exists, [lock_key]
-    if lock_key_exists
-      DynamicLinks::ShorteningStrategies::MockStrategy.stub :new, strategy_mock do
-        DynamicLinks.configuration.stub :cache_store, cache_store_mock do
-          assert_equal full_short_url, DynamicLinks.shorten_url('https://example.com', @client)
-        end
-      end
-    else
-      cache_store_mock.expect :write, nil, [lock_key, 'locked', { expires_in: 10.minutes }]
-      cache_store_mock.expect :write, nil, [cache_key, { url: 'https://example.com', short_url: expected_short_path }]
-
-      DynamicLinks::ShorteningStrategies::MockStrategy.stub :new, strategy_mock do
-        DynamicLinks.configuration.stub :cache_store, cache_store_mock do
-          assert_equal full_short_url, DynamicLinks.shorten_url('https://example.com', @client)
-        end
-      end
-    end
-
-    strategy_mock.verify
-    cache_store_mock.verify if async
-  end
 end",,,,
aidar-freeed(merged)/ai-codereviewer,https://api.github.com/repos/aidar-freeed/ai-codereviewer/pulls/comments/1174420680,https://github.com/aidar-freeed/ai-codereviewer/pull/10#discussion_r1174420680,,228,dbf427f89f480fa2efb400bd0bc3df974bab6f87,07b4e53660f659896135241f708e9811a19cb8e6,src/main.ts,nan,Consider adding a comment to explain the purpose of this `else if` block and how it handles the `push` event.,"+      prDetails.pull_number
+    );
+  } else if (process.env.GITHUB_EVENT_NAME === ""push"") {
+    const diffUrl = await getChangedFiles(","--- 

+++ 

@@ -79,21 +79,6 @@

   return comments;
 }
 
-async function getChangedFiles(
-  owner: string,
-  repo: string,
-  baseSha: string,
-  headSha: string
-): Promise<string | null> {
-  const response = await octokit.repos.compareCommits({
-    owner,
-    repo,
-    base: baseSha,
-    head: headSha,
-  });
-  return response.data.diff_url;
-}
-
 async function getBaseAndHeadShas(
   owner: string,
   repo: string,
@@ -113,7 +98,7 @@

 function createPrompt(file: File, chunk: Chunk, prDetails: PRDetails): string {
   return `- Provide the response in following JSON format:  [{""lineNumber"":  <line_number>, ""reviewComment"": ""<review comment>""}]
 - Do not give positive comments or compliments.
-- Do not suggest commenting the code.
+- NEVER suggest adding a comment explaining the code.
 - Provide comments and suggestions ONLY if there is something to improve, otherwise return an empty array.
 - Write the comment in GitHub Markdown format.
 - Use the given description only for the overall context and only comment the code.
@@ -210,33 +195,33 @@

 
 async function main() {
   const prDetails = await getPRDetails();
-  const { baseSha, headSha } = await getBaseAndHeadShas(
-    prDetails.owner,
-    prDetails.repo,
-    prDetails.pull_number
+  let diff: string | null;
+  const eventData = JSON.parse(
+    readFileSync(process.env.GITHUB_EVENT_PATH ?? """", ""utf8"")
   );
 
-  let diff: string | null;
-
-  if (process.env.GITHUB_EVENT_NAME === ""pull_request"") {
+  if (eventData.action === ""opened"") {
     diff = await getDiff(
       prDetails.owner,
       prDetails.repo,
       prDetails.pull_number
     );
-  } else if (process.env.GITHUB_EVENT_NAME === ""push"") {
-    const diffUrl = await getChangedFiles(
-      prDetails.owner,
-      prDetails.repo,
-      baseSha,
-      headSha
-    );
-    if (diffUrl) {
-      const diffResponse = await octokit.request({ url: diffUrl });
-      diff = diffResponse.data;
-    } else {
-      diff = null;
-    }
+  } else if (eventData.action === ""synchronize"") {
+    const newBaseSha = eventData.before;
+    const newHeadSha = eventData.after;
+
+    const response = await octokit.repos.compareCommits({
+      owner: prDetails.owner,
+      repo: prDetails.repo,
+      base: newBaseSha,
+      head: newHeadSha,
+    });
+
+    diff = response.data.diff_url
+      ? await octokit
+          .request({ url: response.data.diff_url })
+          .then((res) => res.data)
+      : null;
   } else {
     console.log(""Unsupported event:"", process.env.GITHUB_EVENT_NAME);
     return;",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/saiqulhaq/dynamic_links/pulls/comments/1443682779,https://github.com/saiqulhaq/dynamic_links/pull/19#discussion_r1443682779,85,95,53664e479de24bcabfbf1c4fdd12423bafb5865e,67675ef2633001974317dae9fc570ecf17a48936,lib/dynamic_links.rb,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The comment on line 85 indicates an unhandled scenario where saving the record might fail. It's important to handle this case to ensure data integrity and provide meaningful feedback to the user. Consider adding error handling around the `save!` method call to catch any exceptions and handle them appropriately.
```diff
-      record.save!
+      begin
+        record.save!
+      rescue ActiveRecord::RecordInvalid => e
+        # Handle exception, e.g., log error and return meaningful message to the user
+      end
```


<!-- This is an auto-generated comment by OSS CodeRabbit -->","+  # TODO Handle issue when failed to save record
+  def self.process_url_synchronously(url, short_url, client, strategy)
+    if strategy.always_growing?
+      ShortenedUrl.create!(client: client, url: url, short_url: short_url)
+    else
+      record = ShortenedUrl.find_or_initialize_by(client: client, short_url: short_url)
+      record.url = url if record.new_record?
+      record.save!
+    end
+    URI::Generic.build({scheme: client.scheme, host: client.hostname, path: ""/#{short_url}""}).to_s
+  end","--- 

+++ 

@@ -1,3 +1,5 @@

+# @author Saiqul Haq <saiqulhaq@gmail.com>
+
 if ENV['RAILS_ENV'] == 'test'
   require 'simplecov'
 
@@ -19,14 +21,12 @@

 
 require ""dynamic_links/version""
 require ""dynamic_links/engine""
+require ""dynamic_links/logger""
 require ""dynamic_links/error_classes""
+require ""dynamic_links/redis_config""
 require ""dynamic_links/configuration""
-require ""dynamic_links/redis_config""
 require ""dynamic_links/validator""
 require ""dynamic_links/strategy_factory""
-require 'dynamic_links/cache_store/base_cache_store'
-require 'dynamic_links/cache_store/redis_cache_store'
-require 'dynamic_links/cache_store/memcached_cache_store'
 require ""dynamic_links/shortening_strategies/base_strategy""
 require ""dynamic_links/shortening_strategies/sha256_strategy""
 require ""dynamic_links/shortening_strategies/md5_strategy""
@@ -34,6 +34,8 @@

 require ""dynamic_links/shortening_strategies/nano_id_strategy""
 require ""dynamic_links/shortening_strategies/redis_counter_strategy""
 require ""dynamic_links/shortening_strategies/mock_strategy""
+require ""dynamic_links/async/locker""
+require ""dynamic_links/shortener""
 
 module DynamicLinks
   class << self
@@ -51,21 +53,11 @@

   def self.shorten_url(url, client, async: DynamicLinks.configuration.async_processing)
     raise InvalidURIError, 'Invalid URL' unless Validator.valid_url?(url)
 
-    strategy_key = DynamicLinks.configuration.shortening_strategy
-    strategy = StrategyFactory.get_strategy(strategy_key)
-
-    short_url = strategy.shorten(url)
-
+    shortener = Shortener.new
     if async
-      # Store data in cache and enqueue background job
-      cache_key = ""shorten_url:#{client.id}:#{short_url}""
-      DynamicLinks.configuration.cache_store.write(cache_key, { url: url, short_url: short_url })
-
-      ShortenUrlJob.perform_later(client, url, short_url)
-      return URI::Generic.build({scheme: client.scheme, host: client.hostname, path: ""/#{short_url}""}).to_s
+      shortener.shorten_async(client, url)
     else
-      # Synchronous processing
-      process_url_synchronously(url, short_url, client, strategy)
+      shortener.shorten(client, url)
     end
   end
 
@@ -79,18 +71,4 @@

       warning: []
     }
   end
-
-  private
-
-  # TODO Handle issue when failed to save record
-  def self.process_url_synchronously(url, short_url, client, strategy)
-    if strategy.always_growing?
-      ShortenedUrl.create!(client: client, url: url, short_url: short_url)
-    else
-      record = ShortenedUrl.find_or_initialize_by(client: client, short_url: short_url)
-      record.url = url if record.new_record?
-      record.save!
-    end
-    URI::Generic.build({scheme: client.scheme, host: client.hostname, path: ""/#{short_url}""}).to_s
-  end
 end",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1314347288,https://github.com/SainsburyWellcomeCentre/aeon_mecha/pull/244#discussion_r1314347288,303,306,0c63c9a96dac25a808dca480f4e357eeb010bfff,bdb3dcd2a4f3a2cd9e79aa1579236d1facbb1ea5,aeon/dj_pipeline/report.py,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The docstring formatting has been changed. The new format is more readable and consistent with PEP 8 guidelines.
```diff
-        """"""
-        Each entry in this table correspond to one subject. However, the plot is capturing
-             data for all sessions.
-         Hence a dynamic update routine is needed to recompute the plot as new sessions
-            become available
-         """"""
+        """"""Each entry in this table correspond to one subject. However, the plot is capturing
+             data for all sessions.
+         Hence a dynamic update routine is needed to recompute the plot as new sessions
+            become available.
+        """"""
```



<!-- This is an auto-generated comment by OSS CodeRabbit -->","+        """"""Each entry in this table correspond to one subject. However the plot is capturing
             data for all sessions.
         Hence a dynamic update routine is needed to recompute the plot as new sessions
-            become available
+            become available.","--- 

+++ 

@@ -1,15 +1,18 @@

+import os
+import datajoint as dj
+import pandas as pd
+import numpy as np
+import pathlib
+import matplotlib.pyplot as plt
+import re
+import datetime
 import json
-import os
-import pathlib
-
-import datajoint as dj
-import matplotlib.pyplot as plt
-import numpy as np
-import pandas as pd
 
 from aeon.analysis import plotting as analysis_plotting
 
-from . import acquisition, analysis, get_schema_name
+from . import acquisition, analysis
+from . import get_schema_name
+
 
 schema = dj.schema(get_schema_name(""report""))
 os.environ[""DJ_SUPPORT_FILEPATH_MANAGEMENT""] = ""TRUE""
@@ -29,7 +32,9 @@

     summary_plot_png: attach
     """"""
 
-    key_source = analysis.InArena & analysis.InArenaTimeDistribution & analysis.InArenaSummary
+    key_source = (
+        analysis.InArena & analysis.InArenaTimeDistribution & analysis.InArenaSummary
+    )
 
     color_code = {
         ""Patch1"": ""b"",
@@ -40,16 +45,18 @@

     }
 
     def make(self, key):
-        acquisition.Experiment.get_data_directory(key)
-
-        in_arena_start, in_arena_end = (analysis.InArena * analysis.InArenaEnd & key).fetch1(
-            ""in_arena_start"", ""in_arena_end""
-        )
+        raw_data_dir = acquisition.Experiment.get_data_directory(key)
+
+        in_arena_start, in_arena_end = (
+            analysis.InArena * analysis.InArenaEnd & key
+        ).fetch1(""in_arena_start"", ""in_arena_end"")
 
         # subject's position data in the time_slices
         position = analysis.InArenaSubjectPosition.get_position(key)
 
-        position_minutes_elapsed = (position.index - in_arena_start).total_seconds() / 60
+        position_minutes_elapsed = (
+            position.index - in_arena_start
+        ).total_seconds() / 60
 
         # figure
         fig = plt.figure(figsize=(16, 8))
@@ -63,12 +70,16 @@

 
         # position plot
         non_nan = np.logical_and(~np.isnan(position.x), ~np.isnan(position.y))
-        analysis_plotting.heatmap(position[non_nan], 50, ax=position_ax, bins=500, alpha=0.5)
+        analysis_plotting.heatmap(
+            position[non_nan], 50, ax=position_ax, bins=500, alpha=0.5
+        )
 
         # event rate plots
         in_arena_food_patches = (
             analysis.InArena
-            * acquisition.ExperimentFoodPatch.join(acquisition.ExperimentFoodPatch.RemovalTime, left=True)
+            * acquisition.ExperimentFoodPatch.join(
+                acquisition.ExperimentFoodPatch.RemovalTime, left=True
+            )
             & key
             & ""in_arena_start >= food_patch_install_time""
             & 'in_arena_start < IFNULL(food_patch_remove_time, ""2200-01-01"")'
@@ -115,17 +126,20 @@

             )
 
         # ethogram
-        in_arena, in_corridor, arena_time, corridor_time = (analysis.InArenaTimeDistribution & key).fetch1(
+        in_arena, in_corridor, arena_time, corridor_time = (
+            analysis.InArenaTimeDistribution & key
+        ).fetch1(
             ""in_arena"",
             ""in_corridor"",
             ""time_fraction_in_arena"",
             ""time_fraction_in_corridor"",
         )
-        nest_keys, in_nests, nests_times = (analysis.InArenaTimeDistribution.Nest & key).fetch(
-            ""KEY"", ""in_nest"", ""time_fraction_in_nest""
-        )
+        nest_keys, in_nests, nests_times = (
+            analysis.InArenaTimeDistribution.Nest & key
+        ).fetch(""KEY"", ""in_nest"", ""time_fraction_in_nest"")
         patch_names, in_patches, patches_times = (
-            analysis.InArenaTimeDistribution.FoodPatch * acquisition.ExperimentFoodPatch & key
+            analysis.InArenaTimeDistribution.FoodPatch * acquisition.ExperimentFoodPatch
+            & key
         ).fetch(""food_patch_description"", ""in_patch"", ""time_fraction_in_patch"")
 
         ethogram_ax.plot(
@@ -135,7 +149,7 @@

             color=self.color_code[""arena""],
             markersize=0.5,
             alpha=0.6,
-            label=""Times in arena"",
+            label=f""Times in arena"",
         )
         ethogram_ax.plot(
             position_minutes_elapsed[in_corridor],
@@ -144,7 +158,7 @@

             color=self.color_code[""corridor""],
             markersize=0.5,
             alpha=0.6,
-            label=""Times in corridor"",
+            label=f""Times in corridor"",
         )
         for in_nest in in_nests:
             ethogram_ax.plot(
@@ -154,9 +168,11 @@

                 color=self.color_code[""nest""],
                 markersize=0.5,
                 alpha=0.6,
-                label=""Times in nest"",
-            )
-        for patch_idx, (patch_name, in_patch) in enumerate(zip(patch_names, in_patches)):
+                label=f""Times in nest"",
+            )
+        for patch_idx, (patch_name, in_patch) in enumerate(
+            zip(patch_names, in_patches)
+        ):
             ethogram_ax.plot(
                 position_minutes_elapsed[in_patch],
                 np.full_like(position_minutes_elapsed[in_patch], (patch_idx + 3)),
@@ -215,7 +231,9 @@

 
         # ---- Save fig and insert ----
         save_dir = _make_path(key)
-        fig_dict = _save_figs((fig,), (""summary_plot_png"",), save_dir=save_dir, prefix=save_dir.name)
+        fig_dict = _save_figs(
+            (fig,), (""summary_plot_png"",), save_dir=save_dir, prefix=save_dir.name
+        )
 
         self.insert1({**key, **fig_dict})
 
@@ -251,10 +269,11 @@

 
     @classmethod
     def delete_outdated_entries(cls):
-        """"""Each entry in this table correspond to one subject. However, the plot is capturing
+        """"""
+        Each entry in this table correspond to one subject. However, the plot is capturing
             data for all sessions.
         Hence a dynamic update routine is needed to recompute the plot as new sessions
-            become available.
+            become available
         """"""
         outdated_entries = (
             cls
@@ -300,10 +319,11 @@

 
     @classmethod
     def delete_outdated_entries(cls):
-        """"""Each entry in this table correspond to one subject. However the plot is capturing
+        """"""
+        Each entry in this table correspond to one subject. However the plot is capturing
             data for all sessions.
         Hence a dynamic update routine is needed to recompute the plot as new sessions
-            become available.
+            become available
         """"""
         outdated_entries = (
             cls
@@ -347,10 +367,11 @@

 
     @classmethod
     def delete_outdated_entries(cls):
-        """"""Each entry in this table correspond to one subject. However the plot is capturing
+        """"""
+        Each entry in this table correspond to one subject. However the plot is capturing
             data for all sessions.
         Hence a dynamic update routine is needed to recompute the plot as new sessions
-            become available.
+            become available
         """"""
         outdated_entries = (
             cls
@@ -383,7 +404,12 @@

     experiment_name, subject, in_arena_start = (analysis.InArena & in_arena_key).fetch1(
         ""experiment_name"", ""subject"", ""in_arena_start""
     )
-    output_dir = store_stage / experiment_name / subject / in_arena_start.strftime(""%y%m%d_%H%M%S_%f"")
+    output_dir = (
+        store_stage
+        / experiment_name
+        / subject
+        / in_arena_start.strftime(""%y%m%d_%H%M%S_%f"")
+    )
     output_dir.mkdir(parents=True, exist_ok=True)
     return output_dir
 ",,,,
aidar-freeed(merged)/ai-codereviewer,https://api.github.com/repos/aidar-freeed/ai-codereviewer/pulls/comments/1174421186,https://github.com/aidar-freeed/ai-codereviewer/pull/10#discussion_r1174421186,,227,3413a8e8a082b170aa5d684ec7d4842a7951df68,07b4e53660f659896135241f708e9811a19cb8e6,src/main.ts,nan,Consider adding an empty line before this `else if` statement for better readability.,"+      prDetails.repo,
+      prDetails.pull_number
+    );
+  } else if (process.env.GITHUB_EVENT_NAME === ""push"") {","--- 

+++ 

@@ -77,21 +77,6 @@

     }
   }
   return comments;
-}
-
-async function getChangedFiles(
-  owner: string,
-  repo: string,
-  baseSha: string,
-  headSha: string
-): Promise<string | null> {
-  const response = await octokit.repos.compareCommits({
-    owner,
-    repo,
-    base: baseSha,
-    head: headSha,
-  });
-  return response.data.diff_url;
 }
 
 async function getBaseAndHeadShas(
@@ -210,33 +195,33 @@

 
 async function main() {
   const prDetails = await getPRDetails();
-  const { baseSha, headSha } = await getBaseAndHeadShas(
-    prDetails.owner,
-    prDetails.repo,
-    prDetails.pull_number
+  let diff: string | null;
+  const eventData = JSON.parse(
+    readFileSync(process.env.GITHUB_EVENT_PATH ?? """", ""utf8"")
   );
 
-  let diff: string | null;
-
-  if (process.env.GITHUB_EVENT_NAME === ""pull_request"") {
+  if (eventData.action === ""opened"") {
     diff = await getDiff(
       prDetails.owner,
       prDetails.repo,
       prDetails.pull_number
     );
-  } else if (process.env.GITHUB_EVENT_NAME === ""push"") {
-    const diffUrl = await getChangedFiles(
-      prDetails.owner,
-      prDetails.repo,
-      baseSha,
-      headSha
-    );
-    if (diffUrl) {
-      const diffResponse = await octokit.request({ url: diffUrl });
-      diff = diffResponse.data;
-    } else {
-      diff = null;
-    }
+  } else if (eventData.action === ""synchronize"") {
+    const newBaseSha = eventData.before;
+    const newHeadSha = eventData.after;
+
+    const response = await octokit.repos.compareCommits({
+      owner: prDetails.owner,
+      repo: prDetails.repo,
+      base: newBaseSha,
+      head: newHeadSha,
+    });
+
+    diff = response.data.diff_url
+      ? await octokit
+          .request({ url: response.data.diff_url })
+          .then((res) => res.data)
+      : null;
   } else {
     console.log(""Unsupported event:"", process.env.GITHUB_EVENT_NAME);
     return;",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1314347289,https://github.com/SainsburyWellcomeCentre/aeon_mecha/pull/244#discussion_r1314347289,350,353,0c63c9a96dac25a808dca480f4e357eeb010bfff,bdb3dcd2a4f3a2cd9e79aa1579236d1facbb1ea5,aeon/dj_pipeline/report.py,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The docstring formatting has been changed. The new format is more readable and consistent with PEP 8 guidelines.
```diff
-        """"""
-        Each entry in this table correspond to one subject. However, the plot is capturing
-             data for all sessions.
-         Hence a dynamic update routine is needed to recompute the plot as new sessions
-            become available
-         """"""
+        """"""Each entry in this table correspond to one subject. However, the plot is capturing
+             data for all sessions.
+         Hence a dynamic update routine is needed to recompute the plot as new sessions
+            become available.
+        """"""
```



<!-- This is an auto-generated comment by OSS CodeRabbit -->","+        """"""Each entry in this table correspond to one subject. However the plot is capturing
             data for all sessions.
         Hence a dynamic update routine is needed to recompute the plot as new sessions
-            become available
+            become available.","--- 

+++ 

@@ -1,15 +1,18 @@

+import os
+import datajoint as dj
+import pandas as pd
+import numpy as np
+import pathlib
+import matplotlib.pyplot as plt
+import re
+import datetime
 import json
-import os
-import pathlib
-
-import datajoint as dj
-import matplotlib.pyplot as plt
-import numpy as np
-import pandas as pd
 
 from aeon.analysis import plotting as analysis_plotting
 
-from . import acquisition, analysis, get_schema_name
+from . import acquisition, analysis
+from . import get_schema_name
+
 
 schema = dj.schema(get_schema_name(""report""))
 os.environ[""DJ_SUPPORT_FILEPATH_MANAGEMENT""] = ""TRUE""
@@ -29,7 +32,9 @@

     summary_plot_png: attach
     """"""
 
-    key_source = analysis.InArena & analysis.InArenaTimeDistribution & analysis.InArenaSummary
+    key_source = (
+        analysis.InArena & analysis.InArenaTimeDistribution & analysis.InArenaSummary
+    )
 
     color_code = {
         ""Patch1"": ""b"",
@@ -40,16 +45,18 @@

     }
 
     def make(self, key):
-        acquisition.Experiment.get_data_directory(key)
-
-        in_arena_start, in_arena_end = (analysis.InArena * analysis.InArenaEnd & key).fetch1(
-            ""in_arena_start"", ""in_arena_end""
-        )
+        raw_data_dir = acquisition.Experiment.get_data_directory(key)
+
+        in_arena_start, in_arena_end = (
+            analysis.InArena * analysis.InArenaEnd & key
+        ).fetch1(""in_arena_start"", ""in_arena_end"")
 
         # subject's position data in the time_slices
         position = analysis.InArenaSubjectPosition.get_position(key)
 
-        position_minutes_elapsed = (position.index - in_arena_start).total_seconds() / 60
+        position_minutes_elapsed = (
+            position.index - in_arena_start
+        ).total_seconds() / 60
 
         # figure
         fig = plt.figure(figsize=(16, 8))
@@ -63,12 +70,16 @@

 
         # position plot
         non_nan = np.logical_and(~np.isnan(position.x), ~np.isnan(position.y))
-        analysis_plotting.heatmap(position[non_nan], 50, ax=position_ax, bins=500, alpha=0.5)
+        analysis_plotting.heatmap(
+            position[non_nan], 50, ax=position_ax, bins=500, alpha=0.5
+        )
 
         # event rate plots
         in_arena_food_patches = (
             analysis.InArena
-            * acquisition.ExperimentFoodPatch.join(acquisition.ExperimentFoodPatch.RemovalTime, left=True)
+            * acquisition.ExperimentFoodPatch.join(
+                acquisition.ExperimentFoodPatch.RemovalTime, left=True
+            )
             & key
             & ""in_arena_start >= food_patch_install_time""
             & 'in_arena_start < IFNULL(food_patch_remove_time, ""2200-01-01"")'
@@ -115,17 +126,20 @@

             )
 
         # ethogram
-        in_arena, in_corridor, arena_time, corridor_time = (analysis.InArenaTimeDistribution & key).fetch1(
+        in_arena, in_corridor, arena_time, corridor_time = (
+            analysis.InArenaTimeDistribution & key
+        ).fetch1(
             ""in_arena"",
             ""in_corridor"",
             ""time_fraction_in_arena"",
             ""time_fraction_in_corridor"",
         )
-        nest_keys, in_nests, nests_times = (analysis.InArenaTimeDistribution.Nest & key).fetch(
-            ""KEY"", ""in_nest"", ""time_fraction_in_nest""
-        )
+        nest_keys, in_nests, nests_times = (
+            analysis.InArenaTimeDistribution.Nest & key
+        ).fetch(""KEY"", ""in_nest"", ""time_fraction_in_nest"")
         patch_names, in_patches, patches_times = (
-            analysis.InArenaTimeDistribution.FoodPatch * acquisition.ExperimentFoodPatch & key
+            analysis.InArenaTimeDistribution.FoodPatch * acquisition.ExperimentFoodPatch
+            & key
         ).fetch(""food_patch_description"", ""in_patch"", ""time_fraction_in_patch"")
 
         ethogram_ax.plot(
@@ -135,7 +149,7 @@

             color=self.color_code[""arena""],
             markersize=0.5,
             alpha=0.6,
-            label=""Times in arena"",
+            label=f""Times in arena"",
         )
         ethogram_ax.plot(
             position_minutes_elapsed[in_corridor],
@@ -144,7 +158,7 @@

             color=self.color_code[""corridor""],
             markersize=0.5,
             alpha=0.6,
-            label=""Times in corridor"",
+            label=f""Times in corridor"",
         )
         for in_nest in in_nests:
             ethogram_ax.plot(
@@ -154,9 +168,11 @@

                 color=self.color_code[""nest""],
                 markersize=0.5,
                 alpha=0.6,
-                label=""Times in nest"",
-            )
-        for patch_idx, (patch_name, in_patch) in enumerate(zip(patch_names, in_patches)):
+                label=f""Times in nest"",
+            )
+        for patch_idx, (patch_name, in_patch) in enumerate(
+            zip(patch_names, in_patches)
+        ):
             ethogram_ax.plot(
                 position_minutes_elapsed[in_patch],
                 np.full_like(position_minutes_elapsed[in_patch], (patch_idx + 3)),
@@ -215,7 +231,9 @@

 
         # ---- Save fig and insert ----
         save_dir = _make_path(key)
-        fig_dict = _save_figs((fig,), (""summary_plot_png"",), save_dir=save_dir, prefix=save_dir.name)
+        fig_dict = _save_figs(
+            (fig,), (""summary_plot_png"",), save_dir=save_dir, prefix=save_dir.name
+        )
 
         self.insert1({**key, **fig_dict})
 
@@ -251,10 +269,11 @@

 
     @classmethod
     def delete_outdated_entries(cls):
-        """"""Each entry in this table correspond to one subject. However, the plot is capturing
+        """"""
+        Each entry in this table correspond to one subject. However, the plot is capturing
             data for all sessions.
         Hence a dynamic update routine is needed to recompute the plot as new sessions
-            become available.
+            become available
         """"""
         outdated_entries = (
             cls
@@ -300,10 +319,11 @@

 
     @classmethod
     def delete_outdated_entries(cls):
-        """"""Each entry in this table correspond to one subject. However the plot is capturing
+        """"""
+        Each entry in this table correspond to one subject. However the plot is capturing
             data for all sessions.
         Hence a dynamic update routine is needed to recompute the plot as new sessions
-            become available.
+            become available
         """"""
         outdated_entries = (
             cls
@@ -347,10 +367,11 @@

 
     @classmethod
     def delete_outdated_entries(cls):
-        """"""Each entry in this table correspond to one subject. However the plot is capturing
+        """"""
+        Each entry in this table correspond to one subject. However the plot is capturing
             data for all sessions.
         Hence a dynamic update routine is needed to recompute the plot as new sessions
-            become available.
+            become available
         """"""
         outdated_entries = (
             cls
@@ -383,7 +404,12 @@

     experiment_name, subject, in_arena_start = (analysis.InArena & in_arena_key).fetch1(
         ""experiment_name"", ""subject"", ""in_arena_start""
     )
-    output_dir = store_stage / experiment_name / subject / in_arena_start.strftime(""%y%m%d_%H%M%S_%f"")
+    output_dir = (
+        store_stage
+        / experiment_name
+        / subject
+        / in_arena_start.strftime(""%y%m%d_%H%M%S_%f"")
+    )
     output_dir.mkdir(parents=True, exist_ok=True)
     return output_dir
 ",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/comments/1834997230,https://github.com/parkpow/deep-license-plate-recognition/pull/223#discussion_r1834997230,161,167,c19e559cd35d607cec57893456f4e9443148da95,8d58a421d62b626afbf1de632a3e5c86481776fa,docker/dd-extension/ui/src/components/Snapshot.tsx,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

To improve maintainability and avoid potential issues with undefined values, consider using optional chaining when accessing properties of `snapshotData`. This ensures that if any property is missing, it won't cause an error.
```diff
           localStorage.setItem('snapshot', JSON.stringify({
             token: snapshotData?.token,
             license: snapshotData?.license,
             restartPolicy: snapshotData?.restartPolicy,
             curlPort: snapshotData?.curlPort,
             country: snapshotData?.country,
             architecture: snapshotData?.architecture            
           }));
```



<!-- This is an auto-generated comment by OSS CodeRabbit -->","+          localStorage.setItem('snapshot', JSON.stringify({
+            token:token,
+            license:licenseKey,
+            restartPolicy:restartPolicy,
+            curlPort:curlPort,
+            country:country,
+            architecture:architecture            ","--- 

+++ 

@@ -132,12 +132,12 @@

     const storedData = localStorage.getItem('snapshot');
     if (storedData) {
       const snapshotData = JSON.parse(storedData);
-      setToken(snapshotData.token);
-      setLicenseKey(snapshotData.license);
-      setRestartPolicy(snapshotData.restartPolicy);
-      setCurlPort(snapshotData.curlPort);
-      setCountry(snapshotData.country);
-      setArchitecture(snapshotData.architecture);
+      setToken(snapshotData?.token);
+      setLicenseKey(snapshotData?.license);
+      setRestartPolicy(snapshotData?.restartPolicy);
+      setCurlPort(snapshotData?.curlPort);
+      setCountry(snapshotData?.country);
+      setArchitecture(snapshotData?.architecture);
     }
   }, []);
 ",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/saiqulhaq/dynamic_links/pulls/comments/1468725801,https://github.com/saiqulhaq/dynamic_links/pull/19#discussion_r1468725801,26,32,a71f93658310e321b930a78926b4ab31f66de4f4,67675ef2633001974317dae9fc570ecf17a48936,app/models/dynamic_links/shortened_url.rb,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The `find_or_create!` method can be simplified by using the `find_or_create_by!` method provided by ActiveRecord. This method automatically handles the finding or creating of a record based on the provided attributes.
```diff
-    def self.find_or_create!(client, short_url, url)
-      record = find_or_initialize_by(client: client, short_url: short_url)
-      return record if record.persisted?
-
-      record.url = url
-      record.save!
-      record
-    end
+    def self.find_or_create!(client, short_url, url)
+      find_or_create_by!(client: client, short_url: short_url, url: url)
+    end
```
Please note that this change assumes that the `url` attribute should also be used for finding existing records. If this is not the case, and `url` should only be used for creating new records, then the original implementation is correct.


<!-- This is an auto-generated comment by OSS CodeRabbit -->","+    def self.find_or_create!(client, short_url, url)
+      record = find_or_initialize_by(client: client, short_url: short_url)
+      return record if record.persisted?
+
+      record.url = url
+      record.save!
+      record","--- 

+++ 

@@ -24,12 +24,16 @@

     validates :short_url, presence: true, uniqueness: { scope: :client_id }
 
     def self.find_or_create!(client, short_url, url)
-      record = find_or_initialize_by(client: client, short_url: short_url)
-      return record if record.persisted?
-
-      record.url = url
-      record.save!
-      record
+      transaction do
+        record = find_or_create_by!(client: client, short_url: short_url) do |record|
+          record.url = url
+        end
+        record
+      end
+    rescue ActiveRecord::RecordInvalid => e
+      # Log the error and re-raise if needed or return a meaningful error message
+      DynamicLinks::Logger.log_error(""ShortenedUrl creation failed: #{e.message}"")
+      raise e
     end
   end
 end",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1532564546,https://github.com/SainsburyWellcomeCentre/aeon_mecha/pull/342#discussion_r1532564546,2,5,31721cc9db8ed617283d52fcbb3e76e16bd802a7,739bcbe762004157988bae2a831ff4d2e951dcd0,aeon/io/device.py,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The `deprecated` decorator is used correctly to indicate that the `compositeStream` function is deprecated. However, it would be helpful to provide more information in the deprecation message about what exactly should be used instead of this function. It's mentioned to use the streams module, but it's not clear which function or class from that module should be used as a replacement.
```diff
- @deprecated(""Please use the streams module instead."")
+ @deprecated(""Please use the StreamGroup class from the streams module instead."")
```


<!-- This is an auto-generated comment by OSS CodeRabbit -->","+from typing_extensions import deprecated
 
 
+@deprecated(""Please use the streams module instead."")","--- 

+++ 

@@ -2,7 +2,7 @@

 from typing_extensions import deprecated
 
 
-@deprecated(""Please use the streams module instead."")
+@deprecated(""Please use the StreamGroup class from the streams module instead."")
 def compositeStream(pattern, *args):
     """"""Merges multiple data streams into a single composite stream.""""""
     composite = {}
@@ -17,7 +17,7 @@

     return composite
 
 
-@deprecated(""Please use the Device class in the streams module instead."")
+@deprecated(""The Device class has been moved to the streams module."")
 class Device:
     """"""Groups multiple data streams into a logical device.
 ",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/comments/1808463535,https://github.com/parkpow/deep-license-plate-recognition/pull/219#discussion_r1808463535,70,81,3eb603bac63a7a24dc7b49f43190d857c2223350,7645a7ff134a797c1d8f5a6fa166a00bcf62b8fe,snapshot-middleware/src/index.js,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

Consider adding error handling for the `uploadBase64` method to manage potential failures during the upload process. This will improve robustness and provide better feedback in case of errors.

```javascript
try {
    const result = await snapshot.uploadBase64(
        message.body[""image""],
        message.body[""cameraId""],
        message.body[""timestamp""],
    );
    console.info(`Logged Vehicle: ${JSON.stringify(result)}`);
    // Explicitly acknowledge the message as delivered
    message.ack();
} catch (error) {
    console.error(`Failed to log vehicle: ${error.message}`);
    // Optionally handle retries or other logic here
}
```


<!-- This is an auto-generated comment by OSS CodeRabbit -->","+	async queue(batch, env) {
+		const snapshot = new SnapshotApi(env.SNAPSHOT_TOKEN, env.SNAPSHOT_URL);
+		for (const message of batch.messages) {
+			const result = await snapshot.uploadBase64(
+				message.body[""image""],
+				message.body[""cameraId""],
+				message.body[""timestamp""],
+			);
+			console.info(`Logged Vehicle: ${JSON.stringify(result)}`);
+			// Explicitly acknowledge the message as delivered
+			message.ack();
+		}","--- 

+++ 

@@ -1,83 +1,116 @@

 import { SnapshotApi } from ""./snapshot"";
 
 function validGenetecEvent(data) {
-	return (
-		""CameraName"" in data &&
-		""ContextImage"" in data &&
-		""DateUtc"" in data &&
-		""TimeUtc"" in data
-	);
+  return (
+    ""CameraName"" in data &&
+    ""ContextImage"" in data &&
+    ""DateUtc"" in data &&
+    ""TimeUtc"" in data
+  );
+}
+
+function validInt(i) {
+  if (isNaN(i)) {
+    throw new Error(`Invalid value for time - ${i}`);
+  }
+  return parseInt(i, 10);
+}
+
+function requestParams(request) {
+  const { searchParams } = new URL(request.url);
+  return {
+    mmc: searchParams.get(""mmc""),
+    camera_id: searchParams.get(""camera_id""),
+    regions: searchParams.get(""regions""),
+    config: searchParams.get(""config""),
+  };
 }
 
 export default {
-	async fetch(request, env, ctx) {
-		if (request.method === ""POST"") {
-			const contentType = request.headers.get(""content-type"");
-			if (contentType.includes(""application/json"")) {
-				const data = await request.json();
-				console.debug(data);
-				let cameraId = null;
-				let imageBase64 = null;
-				let createdDate = null;
-				const survisionSerialNumber = request.headers.get(
-					""survision-serial-number"",
-				);
-				if (survisionSerialNumber) {
-					cameraId = survisionSerialNumber;
-					createdDate = new Date(parseInt(data[""anpr""][""@date""])).toISOString(); // sample 1729206290098
-					imageBase64 = data[""anpr""][""decision""][""jpeg""];
-				} else if (validGenetecEvent(data)) {
-					cameraId = data[""CameraName""];
-					imageBase64 = data[""ContextImage""];
-					// ""10/01/2022"", Format DD/MM/YYYY
-					let [day, month, year] = data[""DateUtc""].split(""/"");
-					//  ""11:49:22"", Format HH/MM/SS
-					let [hours, minutes, seconds] = data[""TimeUtc""].split("":"");
-					createdDate = new Date(
-						parseInt(year),
-						parseInt(month),
-						parseInt(day),
-						parseInt(hours),
-						parseInt(minutes),
-						parseInt(seconds),
-					).toISOString();
-				} else {
-					return new Response(""Error - Invalid Request Content"", {
-						status: 400,
-					});
-				}
-				ctx.waitUntil(
-					env.INCOMING_WEBHOOKS.send({
-						image: imageBase64,
-						cameraId: cameraId,
-						timestamp: createdDate,
-					}),
-				);
-				return new Response(""OK!"");
-			} else {
-				return new Response(
-					""Error - Invalid Content Type, Expected application/json "",
-					{ status: 400 },
-				);
-			}
-		} else {
-			return new Response(""Error - Required POST"", { status: 400 });
-		}
-	},
+  async fetch(request, env, ctx) {
+    if (request.method === ""POST"") {
+      const contentType = request.headers.get(""content-type"");
+      if (contentType?.includes(""application/json"")) {
+        const data = await request.json();
+        let cameraId = null;
+        let imageBase64 = null;
+        let createdDate = null;
+        const snapshot = new SnapshotApi(env.SNAPSHOT_TOKEN, env.SNAPSHOT_URL);
+        const survisionSerialNumber = request.headers.get(
+          ""survision-serial-number"",
+        );
+        if (survisionSerialNumber) {
+          cameraId = survisionSerialNumber;
+          // sample 1729206290098
+          createdDate = new Date(
+            validInt(data[""anpr""][""@date""], 10),
+          ).toISOString();
+          imageBase64 = data[""anpr""][""decision""][""jpeg""];
+          ctx.waitUntil(
+            snapshot.uploadBase64(
+              imageBase64,
+              cameraId,
+              createdDate,
+              requestParams(request),
+            ),
+          );
+        } else if (validGenetecEvent(data)) {
+          cameraId = data[""CameraName""];
+          imageBase64 = data[""ContextImage""];
+          // ""10/01/2022"", Format DD/MM/YYYY
+          let [month, day, year] = data[""DateUtc""].split(""/"");
+          //  ""11:49:22"", Format HH/MM/SS
+          let [hours, minutes, seconds] = data[""TimeUtc""].split("":"");
+          createdDate = new Date(
+            validInt(year, 10),
+            validInt(month, 10) - 1,
+            validInt(day, 10),
+            validInt(hours, 10),
+            validInt(minutes, 10),
+            validInt(seconds, 10),
+          ).toISOString();
+          // Gentec camera data is larger than the queue limit (128 KB), we send directly
+          ctx.waitUntil(
+            snapshot.uploadBase64(
+              imageBase64,
+              cameraId,
+              createdDate,
+              requestParams(request),
+            ),
+          );
+        } else {
+          return new Response(""Error - Invalid Request Content"", {
+            status: 400,
+          });
+        }
+        return new Response(""OK!"");
+      } else {
+        return new Response(
+          ""Error - Invalid Content Type, Expected application/json "",
+          { status: 400 },
+        );
+      }
+    } else {
+      return new Response(""Error - Required POST"", { status: 400 });
+    }
+  },
 
-	// The queue handler is invoked when a batch of messages is ready to be delivered
-	// https://developers.cloudflare.com/queues/platform/javascript-apis/#messagebatch
-	async queue(batch, env) {
-		const snapshot = new SnapshotApi(env.SNAPSHOT_TOKEN, env.SNAPSHOT_URL);
-		for (const message of batch.messages) {
-			const result = await snapshot.uploadBase64(
-				message.body[""image""],
-				message.body[""cameraId""],
-				message.body[""timestamp""],
-			);
-			console.info(`Logged Vehicle: ${JSON.stringify(result)}`);
-			// Explicitly acknowledge the message as delivered
-			message.ack();
-		}
-	},
+  // The queue handler is invoked when a batch of messages is ready to be delivered
+  // https://developers.cloudflare.com/queues/platform/javascript-apis/#messagebatch
+  async queue(batch, env) {
+    const snapshot = new SnapshotApi(env.SNAPSHOT_TOKEN, env.SNAPSHOT_URL);
+    for (const message of batch.messages) {
+      console.info(""Processing Queue Message:"");
+      console.info(message.body[""cameraId""]);
+      const result = await snapshot.uploadBase64(
+        message.body[""image""],
+        message.body[""cameraId""],
+        message.body[""timestamp""],
+        message.body[""params""],
+      );
+      console.info(`Logged Vehicle: ${JSON.stringify(result)}`);
+      // Explicitly acknowledge the message as delivered
+      message.ack();
+    }
+  },
 };",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1765266916,https://github.com/SainsburyWellcomeCentre/aeon_mecha/pull/402#discussion_r1765266916,,251,9c9a88b8ac92fb0930e143faeadd08cbca84dd6e,a889dba13c07c7eb6142a8265b8d8de8c60cef9c,aeon/dj_pipeline/analysis/block_analysis.py,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The change from an if condition to using the `min` function is a good one. It simplifies the code and reduces complexity.
```diff
-            if encoder_df.index[-1] < block_end:
-                block_end = encoder_df.index[-1]
+            block_end = min(encoder_df.index[-1], block_end)
```


<!-- This is an auto-generated comment by OSS CodeRabbit -->","             # update block_end if last timestamp of encoder_df is before the current block_end
-            if encoder_df.index[-1] < block_end:
-                block_end = encoder_df.index[-1]
+            block_end = min(encoder_df.index[-1], block_end)","--- 

+++ 

@@ -478,15 +478,15 @@

                 subj_pellets = closest_subjects_pellet_ts[closest_subjects_pellet_ts == subject_name]
                 self.Patch.insert1(
                     key
-                    | dict(
-                        patch_name=patch[""patch_name""],
-                        subject_name=subject_name,
-                        in_patch_timestamps=subject_in_patch.index.values,
-                        in_patch_time=subject_in_patch_cum_time[-1],
-                        pellet_count=len(subj_pellets),
-                        pellet_timestamps=subj_pellets.index.values,
-                        wheel_cumsum_distance_travelled=cum_wheel_dist_subj_df[subject_name].values,
-                    )
+                    | {
+                        ""patch_name"": patch[""patch_name""],
+                        ""subject_name"": subject_name,
+                        ""in_patch_timestamps"": subject_in_patch.index.values,
+                        ""in_patch_time"": subject_in_patch_cum_time[-1],
+                        ""pellet_count"": len(subj_pellets),
+                        ""pellet_timestamps"": subj_pellets.index.values,
+                        ""wheel_cumsum_distance_travelled"": cum_wheel_dist_subj_df[subject_name].values,
+                    }
                 )
 
         # Now that we have computed all individual patch and subject values, we iterate again through
@@ -513,14 +513,14 @@

 
                 self.Preference.insert1(
                     key
-                    | dict(
-                        patch_name=patch_name,
-                        subject_name=subject_name,
-                        cumulative_preference_by_time=cum_pref_time,
-                        cumulative_preference_by_wheel=cum_pref_dist,
-                        final_preference_by_time=cum_pref_time[-1],
-                        final_preference_by_wheel=cum_pref_dist[-1],
-                    )
+                    | {
+                        ""patch_name"": patch_name,
+                        ""subject_name"": subject_name,
+                        ""cumulative_preference_by_time"": cum_pref_time,
+                        ""cumulative_preference_by_wheel"": cum_pref_dist,
+                        ""final_preference_by_time"": cum_pref_time[-1],
+                        ""final_preference_by_wheel"": cum_pref_dist[-1],
+                    }
                 )
 
 
@@ -695,11 +695,11 @@

                             x=wheel_ts,
                             y=cum_pref,
                             mode=""lines"",  # +  markers"",
-                            line=dict(
-                                width=2,
-                                color=subject_colors[subj_i],
-                                dash=patch_markers_linestyles[patch_i],
-                            ),
+                            line={
+                                ""width"": 2,
+                                ""color"": subject_colors[subj_i],
+                                ""dash"": patch_markers_linestyles[patch_i],
+                            },
                             name=f""{subj} - {p}: μ: {patch_mean}"",
                         )
                     )
@@ -717,13 +717,13 @@

                                 x=cur_cum_pel_ct[""time""],
                                 y=cur_cum_pel_ct[""cum_pref""],
                                 mode=""markers"",
-                                marker=dict(
-                                    symbol=patch_markers[patch_i],
-                                    color=gen_hex_grad(
+                                marker={
+                                    ""symbol"": patch_markers[patch_i],
+                                    ""color"": gen_hex_grad(
                                         subject_colors[-1], cur_cum_pel_ct[""norm_thresh_val""]
                                     ),
-                                    size=8,
-                                ),
+                                    ""size"": 8,
+                                },
                                 showlegend=False,
                                 customdata=np.stack((cur_cum_pel_ct[""threshold""],), axis=-1),
                                 hovertemplate=""Threshold: %{customdata[0]:.2f} cm"",
@@ -735,7 +735,7 @@

                 title=f""Cumulative Patch Preference - {title}"",
                 xaxis_title=""Time"",
                 yaxis_title=""Pref Index"",
-                yaxis=dict(tickvals=np.arange(0, 1.1, 0.1)),
+                yaxis={""tickvals"": np.arange(0, 1.1, 0.1)},
             )
 
         # Insert figures as json-formatted plotly plots",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/saiqulhaq/dynamic_links/pulls/comments/1443118851,https://github.com/saiqulhaq/dynamic_links/pull/19#discussion_r1443118851,32,38,fcb1391bbdbc0a8e99d93d27bae941231960c0bb,67675ef2633001974317dae9fc570ecf17a48936,lib/dynamic_links/cache_store.rb,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

Similar to the `write` method, the `read` and `delete` methods are also tightly coupled to the specific implementations of Redis and Memcached. The same suggestion about using polymorphism applies here. 

Overall, the current implementation violates the Open/Closed Principle of SOLID principles, which states that software entities should be open for extension but closed for modification. By using polymorphism, you can add support for new cache store types without modifying the existing `CacheStore` class.


<!-- This is an auto-generated comment by OSS CodeRabbit -->","+    def read(key)
+      @store.get(key)
+    end
+
+    def delete(key)
+      @store.del(key)
+    end",File_Deleted,,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/Dev-FE-1/Toy_Project_II_team4/pulls/comments/1706228997,https://github.com/Dev-FE-1/Toy_Project_II_team4/pull/108#discussion_r1706228997,7,11,71021125c31073b3b703df2332fe2dcbbbfd89e0,9d9bb5d43e6180ef74fdc7f47cf776701a5003ce,src/pages/salaryList/NoticeCard.tsx,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The type `noticeData` has been updated to include a `userId` property. This is a good change as it allows the component to fetch data based on the user's ID, making the component more reusable and adaptable to different contexts.

```diff
- type noticeData = {
-   date: string;
-   day: string;
-    button?: boolean;
-    label?: React.ReactNode;
-   onClick?: () => void;
- };
+ type noticeData = {
+   userId:string;
+   button?: boolean;
+   label?: React.ReactNode;
+ };
```



<!-- This is an auto-generated comment by OSS CodeRabbit -->"," type noticeData = {
-  date: string;
-  day: string;
+  userId:string;
   button?: boolean;
   label?: React.ReactNode;
-  onClick?: () => void;
 };","--- 

+++ 

@@ -1,22 +1,18 @@

 import * as Styled from './NoticeCard.style';
 import Btn from '../../components/button/Button';
-import useSalaryDetails from './useSalaryDetails';
+import { SalaryDataItem } from './api/fetchSalaryInfo';
 import { useNavigate } from ""react-router-dom"";
 import dayjs from ""dayjs"";
 
 type noticeData = {
-  userId:string;
+  salaryList? : Array<SalaryDataItem> 
   button?: boolean;
   label?: React.ReactNode;
 };
 
 
-export default function NoticeCard({ userId, button = false, label}: noticeData) {
-  const navigate = useNavigate()
-  const {data} = useSalaryDetails()
-
-  const salaryList = data?.salaryDetails[userId] || []
-  salaryList.sort((a,b) => b.id-a.id) 
+export default function NoticeCard({ salaryList=[], button = false, label}: noticeData) {
+  const navigate = useNavigate() 
 
   const handleApplicationBtn = (id:number) => {
     if(salaryList.find((item) => item.id === id)){",,,,
aidar-freeed(merged)/ai-codereviewer,https://api.github.com/repos/aidar-freeed/ai-codereviewer/pulls/comments/1149858432,https://github.com/aidar-freeed/ai-codereviewer/pull/4#discussion_r1149858432,,101,ad866ee7f308986b165f3ef92dc5a9460e170f10,ea61d39797252e53528289d79a466e863c2f3c9b,src/main.ts,nan,"It's better to use a more specific return type for the `getAIResponse` function. Instead of `Promise<Array<{ lineNumber: string; reviewComment: string; }> | null>`, consider using `Promise<Array<{ lineNumber: number; reviewComment: string; }> | null>` since line numbers are integers."," 
-Please provide comments and suggestions ONLY if there is something to improve, write the answer in Github markdown. If the code looks good, DO NOT return any text (leave the response completely empty)
+Git diff to review:
 ","--- 

+++ 

@@ -66,8 +66,6 @@

   for (const file of parsedDiff) {
     for (const chunk of file.chunks) {
       const prompt = createPrompt(file, chunk, prDetails);
-      console.log(""PROMPT:"");
-      console.log(prompt);
       const aiResponse = await getAIResponse(prompt);
       if (aiResponse) {
         const newComments = createComment(file, chunk, aiResponse);
@@ -77,7 +75,6 @@

       }
     }
   }
-  console.log(""COMMENTS:"" + comments.length);
   return comments;
 }
 
@@ -134,8 +131,6 @@

     });
 
     const res = response.data.choices[0].message?.content?.trim() || ""[]"";
-    console.log(""AI Response:"");
-    console.log(res);
     return JSON.parse(res);
   } catch (error) {
     console.error(""Error:"", error);",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/saiqulhaq/dynamic_links/pulls/comments/1439004482,https://github.com/saiqulhaq/dynamic_links/pull/7#discussion_r1439004482,4,5,288124505f44c8e95dd8ef75ba1efb29c3e3793e,af53df6da4a5bfbcb47d54bce5d5a780c8e0ab6b,app/controllers/dynamic_links/v1/short_links_controller.rb,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The new code does not validate the URL before shortening it. This could lead to invalid URLs being shortened and stored in the database, which could cause issues when trying to redirect to these URLs later on. I suggest adding back the URL validation logic.

```diff
  url = params.require(:url)
+ if !url_shortener.valid_url?(url)
+   render json: { error: 'invalid url' }, status: :bad_request
+   return
+ end
  client = DynamicLinks::Client.find_by!(api_key: params.require(:api_key))
  render json: DynamicLinks.generate_short_url(url, client), status: :created
```
Also, there is no error handling for the case where `find_by!` does not find a matching client. This will raise an `ActiveRecord::RecordNotFound` exception. It would be better to handle this gracefully and return a meaningful error message to the user.

```diff
- client = DynamicLinks::Client.find_by!(api_key: params.require(:api_key))
+ client = DynamicLinks::Client.find_by(api_key: params.require(:api_key))
+ unless client
+   render json: { error: 'invalid api key' }, status: :unauthorized
+   return
+ end
  render json: DynamicLinks.generate_short_url(url, client), status: :created
```


<!-- This is an auto-generated comment by OSS CodeRabbit -->","+    client = DynamicLinks::Client.find_by!(api_key: params.require(:api_key))
+    render json: DynamicLinks.generate_short_url(url, client), status: :created","--- 

+++ 

@@ -1,7 +1,12 @@

 class DynamicLinks::V1::ShortLinksController < ApplicationController
   def create
     url = params.require(:url)
-    client = DynamicLinks::Client.find_by!(api_key: params.require(:api_key))
+    client = DynamicLinks::Client.find_by(api_key: params.require(:api_key))
+    unless client
+      render json: { error: 'invalid api key' }, status: :unauthorized
+      return
+    end
+
     render json: DynamicLinks.generate_short_url(url, client), status: :created
   end
 end",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/saiqulhaq/dynamic_links/pulls/comments/1443162255,https://github.com/saiqulhaq/dynamic_links/pull/19#discussion_r1443162255,3,6,63efbb026d38a2393ac0b0ad19ee8704bfa43474,67675ef2633001974317dae9fc570ecf17a48936,lib/dynamic_links/configuration.rb,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The `attr_accessor` method is used to define getter and setter methods for instance variables. However, it's not a good practice to expose all instance variables as public attributes. This can lead to violation of encapsulation principle in OOP. Consider using `attr_reader` or `attr_writer` for some variables if they are not meant to be both read and written from outside the class.

```diff
-    attr_accessor :shortening_strategy, :enable_rest_api, :db_infra_strategy,
-                  :async_processing, :cache_store,
-                  :redis_counter_config,
-                  :cache_store_config
+    attr_accessor :shortening_strategy, :enable_rest_api
+    attr_reader :db_infra_strategy, :async_processing, :cache_store, :redis_counter_config, :cache_store_config
```



<!-- This is an auto-generated comment by OSS CodeRabbit -->","+    attr_accessor :shortening_strategy, :enable_rest_api, :db_infra_strategy,
+                  :async_processing, :cache_store,
+                  :redis_counter_config,
+                  :cache_store_config","--- 

+++ 

@@ -1,42 +1,71 @@

 module DynamicLinks
+  # @author Saiqul Haq <saiqulhaq@gmail.com>
   class Configuration
-    attr_accessor :shortening_strategy, :enable_rest_api, :db_infra_strategy,
-                  :async_processing, :cache_store,
-                  :redis_counter_config,
-                  :cache_store_config
+    attr_reader :shortening_strategy, :enable_rest_api, :db_infra_strategy,
+                  :async_processing, :redis_counter_config, :cache_store
 
+    VALID_DB_INFRA_STRATEGIES = [:standard, :sharding].freeze
+
+    DEFAULT_SHORTENING_STRATEGY = :md5
+    DEFAULT_ENABLE_REST_API = true
+    DEFAULT_DB_INFRA_STRATEGY = :standard
+    DEFAULT_ASYNC_PROCESSING = false
+    DEFAULT_REDIS_COUNTER_CONFIG = RedisConfig.new
+    # use any class that extends ActiveSupport::Cache::Store, default is MemoryStore
+    DEFAULT_CACHE_STORE = ActiveSupport::Cache::MemoryStore.new
+
+    # Usage:
+    #     DynamicLinks.configure do |config|
+    #       config.shortening_strategy = :MD5 # or other strategy name, see StrategyFactory for available strategies
+    #       config.enable_rest_api = true # or false. when false, the API requests will be rejected
+    #       config.db_infra_strategy = :standard # or :sharding. if sharding is used, then xxx
+    #       config.async_processing = false # or true. if true, the shortening process will be done asynchronously using ActiveJob
+    #       config.redis_counter_config = RedisConfig.new # see RedisConfig documentation for more details
+    #       # if you use Redis
+    #       config.cache_store = ActiveSupport::Cache::RedisStore.new('redis://localhost:6379/0/cache')
+    #       # if you use Memcached
+    #       config.cache_store = ActiveSupport::Cache::MemCacheStore.new('localhost:11211')
+    #     end
+    #
+    # @return [Configuration]
     def initialize
-      @shortening_strategy = :MD5  # Default strategy
-      @enable_rest_api = true  # Enable REST API by default
-      @db_infra_strategy = :standard  # Default DB infrastructure strategy (:standard, :citus)
-      @async_processing = false
-
+      @shortening_strategy = DEFAULT_SHORTENING_STRATEGY
+      @enable_rest_api = DEFAULT_ENABLE_REST_API
+      @db_infra_strategy = DEFAULT_DB_INFRA_STRATEGY
+      @async_processing = DEFAULT_ASYNC_PROCESSING
       # config for RedisCounterStrategy
-      @redis_counter_config = RedisConfig.new
-
-      @cache_store_config = { type: nil, redis_config: {}, memcached_config: {} }
+      @redis_counter_config = DEFAULT_REDIS_COUNTER_CONFIG
+      @cache_store = DEFAULT_CACHE_STORE
     end
 
-    def cache_store_enabled?
-      !@cache_store_config[:type].nil?
+    def shortening_strategy=(strategy)
+      raise ArgumentError, ""Invalid shortening strategy"" unless StrategyFactory::VALID_SHORTENING_STRATEGIES.include?(strategy)
+      @shortening_strategy = strategy
     end
 
-    def cache_store
-      @cache_store ||= DynamicLinks::CacheStore.new(@cache_store_config)
+    def enable_rest_api=(value)
+      raise ArgumentError, ""enable_rest_api must be a boolean"" unless [true, false].include?(value)
+      @enable_rest_api = value
     end
 
-    class RedisConfig
-      attr_accessor :config, :pool_size, :pool_timeout
+    def db_infra_strategy=(strategy)
+      raise ArgumentError, ""Invalid DB infra strategy"" unless VALID_DB_INFRA_STRATEGIES.include?(strategy)
+      @db_infra_strategy = strategy
+    end
 
-      def initialize
-        # Default to an empty hash, can be overridden
-        @config = {
-          # host: 'localhost',
-          # port: 6379
-        }
-        @pool_size = 5          # Default pool size
-        @pool_timeout = 5       # Default timeout in seconds
-      end
+    def async_processing=(value)
+      raise ArgumentError, ""async_processing must be a boolean"" unless [true, false].include?(value)
+      @async_processing = value
+    end
+
+    def redis_counter_config=(config)
+      raise ArgumentError, ""redis_counter_config must be an instance of RedisConfig"" unless config.is_a?(RedisConfig)
+      @redis_counter_config = config
+    end
+
+    def cache_store=(store)
+      raise ArgumentError, ""cache_store must be an instance of ActiveSupport::Cache::Store"" unless store.is_a?(ActiveSupport::Cache::Store)
+      @cache_store = store
     end
   end
 end",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1314347268,https://github.com/SainsburyWellcomeCentre/aeon_mecha/pull/244#discussion_r1314347268,,19,0c63c9a96dac25a808dca480f4e357eeb010bfff,bdb3dcd2a4f3a2cd9e79aa1579236d1facbb1ea5,aeon/dj_pipeline/ingest/load_metadata.py,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The file is opened without specifying the mode. It's a good practice to explicitly mention the mode even if 'r' (read) is default.
```diff
- with open(metadata_yml_filepath) as f:
+ with open(metadata_yml_filepath, 'r') as f:
```



<!-- This is an auto-generated comment by OSS CodeRabbit -->","+    epoch_start = datetime.strptime(metadata_yml_filepath.parent.name, ""%Y-%m-%dT%H-%M-%S"")
 
-    with open(metadata_yml_filepath, ""r"") as f:
+    with open(metadata_yml_filepath) as f:","--- 

+++ 

@@ -1,12 +1,11 @@

+import re
 import pathlib
-import re
 from datetime import datetime
-
 import yaml
 
 from aeon.dj_pipeline import acquisition, lab
-
 from .. import dict_to_uuid
+
 
 _weight_scale_rate = 100
 _weight_scale_nest = 1
@@ -14,9 +13,11 @@

 
 def extract_epoch_metadata(experiment_name, metadata_yml_filepath):
     metadata_yml_filepath = pathlib.Path(metadata_yml_filepath)
-    epoch_start = datetime.strptime(metadata_yml_filepath.parent.name, ""%Y-%m-%dT%H-%M-%S"")
-
-    with open(metadata_yml_filepath) as f:
+    epoch_start = datetime.strptime(
+        metadata_yml_filepath.parent.name, ""%Y-%m-%dT%H-%M-%S""
+    )
+
+    with open(metadata_yml_filepath, ""r"") as f:
         experiment_setup = yaml.safe_load(f)
 
     commit = experiment_setup.get(""Commit"", experiment_setup.get(""Revision""))
@@ -33,16 +34,20 @@

 
 
 def ingest_epoch_metadata(experiment_name, metadata_yml_filepath):
-    """"""work-in-progress
+    """"""
+    work-in-progress
     Missing:
     + camera/patch location
-    + patch, weightscale serial number.
+    + patch, weightscale serial number
     """"""
+
     metadata_yml_filepath = pathlib.Path(metadata_yml_filepath)
     file_creation_time = datetime.fromtimestamp(metadata_yml_filepath.stat().st_ctime)
-    epoch_start = datetime.strptime(metadata_yml_filepath.parent.name, ""%Y-%m-%dT%H-%M-%S"")
-
-    with open(metadata_yml_filepath) as f:
+    epoch_start = datetime.strptime(
+        metadata_yml_filepath.parent.name, ""%Y-%m-%dT%H-%M-%S""
+    )
+
+    with open(metadata_yml_filepath, ""r"") as f:
         experiment_setup = yaml.safe_load(f)
 
     experiment_key = {""experiment_name"": experiment_name}
@@ -81,23 +86,35 @@

             else:
                 raise ValueError(f""Unrecognized Device Type for {device_name}"")
 
-            experiment_devices.append({""Name"": device_name, ""Type"": device_type, **device_info})
+            experiment_devices.append(
+                {""Name"": device_name, ""Type"": device_type, **device_info}
+            )
     else:
-        raise ValueError(f""Unexpected devices variable type: {type(experiment_setup['Devices'])}"")
+        raise ValueError(
+            f""Unexpected devices variable type: {type(experiment_setup['Devices'])}""
+        )
 
     # ---- Video Controller ----
 
-    video_controller = [device for device in experiment_devices if device[""Type""] == ""VideoController""]
-
-    assert len(video_controller) == 1, ""Unable to find one unique VideoController device""
+    video_controller = [
+        device for device in experiment_devices if device[""Type""] == ""VideoController""
+    ]
+
+    assert (
+        len(video_controller) == 1
+    ), ""Unable to find one unique VideoController device""
     video_controller = video_controller[0]
 
     device_frequency_mapper = {
-        name: float(value) for name, value in video_controller.items() if name.endswith(""Frequency"")
+        name: float(value)
+        for name, value in video_controller.items()
+        if name.endswith(""Frequency"")
     }
 
     # ---- Load cameras ----
-    cameras = [device for device in experiment_devices if device[""Type""] == ""VideoSource""]
+    cameras = [
+        device for device in experiment_devices if device[""Type""] == ""VideoSource""
+    ]
 
     camera_list, camera_installation_list, camera_removal_list, camera_position_list = (
         [],
@@ -174,13 +191,17 @@

     # remove the currently installed cameras that are absent in this config
     camera_removal_list.extend(
         (
-            acquisition.ExperimentCamera - acquisition.ExperimentCamera.RemovalTime - camera_list
+            acquisition.ExperimentCamera
+            - acquisition.ExperimentCamera.RemovalTime
+            - camera_list
             & experiment_key
         ).fetch(""KEY"")
     )
 
     # ---- Load food patches ----
-    food_patches = [device for device in experiment_devices if device[""Type""] == ""Patch""]
+    food_patches = [
+        device for device in experiment_devices if device[""Type""] == ""Patch""
+    ]
     patch_list, patch_installation_list, patch_removal_list, patch_position_list = (
         [],
         [],
@@ -189,7 +210,9 @@

     )
     for patch in food_patches:
         # ---- Check if this is a new food patch, add to lab.FoodPatch if needed
-        patch_key = {""food_patch_serial_number"": patch.get(""SerialNumber"") or patch[""PortName""]}
+        patch_key = {
+            ""food_patch_serial_number"": patch.get(""SerialNumber"") or patch[""PortName""]
+        }
         patch_list.append(patch_key)
 
         patch_installation = {
@@ -197,7 +220,9 @@

             ""experiment_name"": experiment_name,
             ""food_patch_install_time"": epoch_start,
             ""food_patch_description"": patch[""Name""],
-            ""wheel_sampling_rate"": float(re.search(r""\d+"", patch[""SampleRate""]).group()),
+            ""wheel_sampling_rate"": float(
+                re.search(r""\d+"", patch[""SampleRate""]).group()
+            ),
             ""wheel_radius"": float(patch[""Radius""]),
         }
         if ""position"" in patch:
@@ -220,7 +245,8 @@

         # If the same camera serial number is currently installed
         # check for any changes in configuration, if not, skip this
         current_patch_query = (
-            acquisition.ExperimentFoodPatch - acquisition.ExperimentFoodPatch.RemovalTime
+            acquisition.ExperimentFoodPatch
+            - acquisition.ExperimentFoodPatch.RemovalTime
             & experiment_key
             & patch_key
         )
@@ -252,13 +278,17 @@

     # remove the currently installed patches that are absent in this config
     patch_removal_list.extend(
         (
-            acquisition.ExperimentFoodPatch - acquisition.ExperimentFoodPatch.RemovalTime - patch_list
+            acquisition.ExperimentFoodPatch
+            - acquisition.ExperimentFoodPatch.RemovalTime
+            - patch_list
             & experiment_key
         ).fetch(""KEY"")
     )
 
     # ---- Load weight scales ----
-    weight_scales = [device for device in experiment_devices if device[""Type""] == ""WeightScale""]
+    weight_scales = [
+        device for device in experiment_devices if device[""Type""] == ""WeightScale""
+    ]
     weight_scale_list, weight_scale_installation_list, weight_scale_removal_list = (
         [],
         [],
@@ -267,7 +297,8 @@

     for weight_scale in weight_scales:
         # ---- Check if this is a new weight scale, add to lab.WeightScale if needed
         weight_scale_key = {
-            ""weight_scale_serial_number"": weight_scale.get(""SerialNumber"") or weight_scale[""PortName""]
+            ""weight_scale_serial_number"": weight_scale.get(""SerialNumber"")
+            or weight_scale[""PortName""]
         }
         weight_scale_list.append(weight_scale_key)
 
@@ -284,7 +315,8 @@

 
         # ---- Check if this weight scale is currently installed - if so, remove it
         current_weight_scale_query = (
-            acquisition.ExperimentWeightScale - acquisition.ExperimentWeightScale.RemovalTime
+            acquisition.ExperimentWeightScale
+            - acquisition.ExperimentWeightScale.RemovalTime
             & experiment_key
             & weight_scale_key
         )
@@ -295,7 +327,9 @@

             current_weight_scale_config.pop(""weight_scale_install_time"")
             new_weight_scale_config.pop(""weight_scale_install_time"")
 
-            if dict_to_uuid(current_weight_scale_config) == dict_to_uuid(new_weight_scale_config):
+            if dict_to_uuid(current_weight_scale_config) == dict_to_uuid(
+                new_weight_scale_config
+            ):
                 continue
 
             # ---- Remove old weight scale",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/saiqulhaq/dynamic_links/pulls/comments/1438979300,https://github.com/saiqulhaq/dynamic_links/pull/3#discussion_r1438979300,10,40,fa32083bcccff71791ba2bb86e8ec6293907ff1c,91c009b051139bcb938a626118393d0714cdfc19,lib/dynamic_links.rb,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The new implementation of the `DynamicLinks` module seems to be more flexible and configurable than the previous one. However, there is a potential issue with the `shorten_url` method. It assumes that the strategy class exists and can be initialized without arguments. If the configuration contains an invalid strategy name, this will raise a `NameError`. Also, if the strategy class requires initialization parameters, it will raise an `ArgumentError`. To improve error handling, consider adding a rescue block to handle these exceptions and provide a more user-friendly error message.

```diff
  def self.shorten_url(url)
    begin
      strategy_class = ""DynamicLinks::ShorteningStrategies::#{configuration.shortening_strategy.to_s.camelize}Strategy"".constantize
      strategy = strategy_class.new
    rescue NameError
      raise ""Invalid shortening strategy: #{configuration.shortening_strategy}""
    rescue ArgumentError
      raise ""#{strategy_class} needs to be initialized with arguments""
    end
    strategy.shorten(url)
  end
```

This way, if an invalid strategy is configured or if the strategy class requires initialization parameters, a clear error message will be raised, making it easier for developers to debug the issue.


<!-- This is an auto-generated comment by OSS CodeRabbit -->","+require ""dynamic_links/shortening_strategies/mock_strategy""
+require ""dynamic_links/configuration""
 
 module DynamicLinks
-  class UrlShortener
-    MIN_LENGTH = 5
+  class << self
+    attr_writer :configuration
 
-    def valid_url?(url)
-      uri = URI.parse(url)
-      uri.is_a?(URI::HTTP) || uri.is_a?(URI::HTTPS)
-    rescue URI::InvalidURIError
-      false
+    def configuration
+      @configuration ||= Configuration.new
     end
+
+    def configure
+      yield(configuration)
+    end
+  end
+
+  def self.shorten_url(url)
+    strategy_class = ""DynamicLinks::ShorteningStrategies::#{configuration.shortening_strategy.to_s.camelize}Strategy"".constantize
+    strategy = strategy_class.new
+    strategy.shorten(url)
+  end
+
+  # mimic Firebase Dynamic Links API
+  def self.generate_short_url(original_url)
+    short_link = shorten_url(original_url)
+
+    {
+      shortLink: short_link,
+      previewLink: ""#{short_link}?preview=true"",
+      warning: []
+    }","--- 

+++ 

@@ -24,8 +24,14 @@

   end
 
   def self.shorten_url(url)
-    strategy_class = ""DynamicLinks::ShorteningStrategies::#{configuration.shortening_strategy.to_s.camelize}Strategy"".constantize
-    strategy = strategy_class.new
+    begin
+      strategy_class = ""DynamicLinks::ShorteningStrategies::#{configuration.shortening_strategy.to_s.camelize}Strategy"".constantize
+      strategy = strategy_class.new
+    rescue NameError
+      raise ""Invalid shortening strategy: #{configuration.shortening_strategy}""
+    rescue ArgumentError
+      raise ""#{strategy_class} needs to be initialized with arguments""
+    end
     strategy.shorten(url)
   end
 ",,,,
aidar-freeed(merged)/ai-codereviewer,https://api.github.com/repos/aidar-freeed/ai-codereviewer/pulls/comments/1174425078,https://github.com/aidar-freeed/ai-codereviewer/pull/10#discussion_r1174425078,,208,a6762eb22361f5d5978299a1fd939390905403ab,07b4e53660f659896135241f708e9811a19cb8e6,src/main.ts,nan,Use `fs.readFileSync` instead of `readFileSync` to avoid confusion with the imported `fs` module.,"+    );
+  } else if (process.env.GITHUB_EVENT_NAME === ""push"") {
+    const pushEvent = JSON.parse(
+      readFileSync(process.env.GITHUB_EVENT_PATH || """", ""utf8"")","--- 

+++ 

@@ -196,21 +196,19 @@

 async function main() {
   const prDetails = await getPRDetails();
   let diff: string | null;
-
-  if (process.env.GITHUB_EVENT_NAME === ""pull_request"") {
+  const eventData = JSON.parse(
+    readFileSync(process.env.GITHUB_EVENT_PATH ?? """", ""utf8"")
+  );
+
+  if (eventData.action === ""opened"") {
     diff = await getDiff(
       prDetails.owner,
       prDetails.repo,
       prDetails.pull_number
     );
-  } else if (process.env.GITHUB_EVENT_NAME === ""push"") {
-    const pushEvent = JSON.parse(
-      readFileSync(process.env.GITHUB_EVENT_PATH || """", ""utf8"")
-    );
-    console.log(""Push event:"");
-    console.log(pushEvent);
-    const newBaseSha = pushEvent.before;
-    const newHeadSha = pushEvent.after;
+  } else if (eventData.action === ""synchronize"") {
+    const newBaseSha = eventData.before;
+    const newHeadSha = eventData.after;
 
     const response = await octokit.repos.compareCommits({
       owner: prDetails.owner,
@@ -224,8 +222,6 @@

           .request({ url: response.data.diff_url })
           .then((res) => res.data)
       : null;
-    console.log(""Diff:"");
-    console.log(diff);
   } else {
     console.log(""Unsupported event:"", process.env.GITHUB_EVENT_NAME);
     return;",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1532523641,https://github.com/SainsburyWellcomeCentre/aeon_mecha/pull/342#discussion_r1532523641,37,53,1e499c7e8e677ea74f9646f87f569930cf58c607,739bcbe762004157988bae2a831ff4d2e951dcd0,aeon/io/streams.py,aeon/schema/streams.py,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The `Device` class constructor has a potential issue. The `path` attribute is optional and defaults to `None`. However, if it remains `None`, the `_createStreams` method will use the `name` attribute as the path. This could lead to unexpected behavior if the `name` is not a valid path. Consider adding a check for `path` being `None` and handle it appropriately.
```diff
-        self._streams = Device._createStreams(name if path is None else path, *args)
+        if path is None:
+            raise ValueError(""Path cannot be None."")
+        self._streams = Device._createStreams(path, *args)
```



<!-- This is an auto-generated comment by OSS CodeRabbit -->","+class Device:
+    """"""Groups multiple data streams into a logical device.
+
+    If a device contains a single stream with the same pattern as the device
+    `name`, it will be considered a singleton, and the stream reader will be
+    paired directly with the device without nesting.
+
+    Attributes:
+        name (str): Name of the device.
+        args (Any): Data streams collected from the device.
+        path (str, optional): Path to the folder where stream chunks are located.
+    """"""
+
+    def __init__(self, name, *args, path=None):
+        self.name = name
+        self._streams = Device._createStreams(name if path is None else path, *args)
+","--- 

+++ 

@@ -1,4 +1,5 @@

 import inspect
+from itertools import chain
 from warnings import warn
 
 
@@ -27,10 +28,15 @@

     def __init__(self, path, *args):
         self.path = path
         self._args = args
+        self._nested = (
+            member
+            for member in vars(self.__class__).values()
+            if inspect.isclass(member) and issubclass(member, (Stream, StreamGroup))
+        )
 
     def __iter__(self):
-        for callable in self._args:
-            for stream in iter(callable(self.path)):
+        for factory in chain(self._nested, self._args):
+            for stream in iter(factory(self.path)):
                 yield stream
 
 
@@ -48,27 +54,26 @@

     """"""
 
     def __init__(self, name, *args, path=None):
+        if name is None:
+            raise ValueError(""name cannot be None."")
+
         self.name = name
-        self._streams = Device._createStreams(name if path is None else path, *args)
+        self._streams = Device._createStreams(name if path is None else path, args)
 
     @staticmethod
-    def _createStreams(path, *args):
+    def _createStreams(path, args):
         streams = {}
-        if args:
-            for callable in args:
-                try:
-                    streams.update(callable(path))
-                except TypeError:
-                    if inspect.isclass(callable):
-                        warn(
-                            f""Stream group classes with no constructors are deprecated. {callable}"",
-                            category=DeprecationWarning,
-                        )
-                        for method in vars(callable).values():
-                            if isinstance(method, staticmethod):
-                                streams.update(method.__func__(path))
-                    else:
-                        raise
+        for factory in args:
+            if inspect.isclass(factory) and not hasattr(factory.__init__, ""__code__""):
+                warn(
+                    f""Stream group classes with default constructors are deprecated. {factory}"",
+                    category=DeprecationWarning,
+                )
+                for method in vars(factory).values():
+                    if isinstance(method, staticmethod):
+                        streams.update(method.__func__(path))
+            else:
+                streams.update(factory(path))
         return streams
 
     def __iter__(self):",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1532539663,https://github.com/SainsburyWellcomeCentre/aeon_mecha/pull/342#discussion_r1532539663,37,53,31721cc9db8ed617283d52fcbb3e76e16bd802a7,739bcbe762004157988bae2a831ff4d2e951dcd0,aeon/io/streams.py,aeon/schema/streams.py,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The `Device` class constructor allows for a `None` value to be passed as the `name` parameter, but immediately raises a `ValueError` if this is the case. It would be better to make `name` a required positional argument without a default value to prevent misuse and unnecessary exception handling.
```diff
-    def __init__(self, name, *args, path=None):
+    def __init__(self, name=None, *args, path=None):
```



<!-- This is an auto-generated reply by OSS CodeRabbit -->","+class Device:
+    """"""Groups multiple data streams into a logical device.
+
+    If a device contains a single stream with the same pattern as the device
+    `name`, it will be considered a singleton, and the stream reader will be
+    paired directly with the device without nesting.
+
+    Attributes:
+        name (str): Name of the device.
+        args (Any): Data streams collected from the device.
+        path (str, optional): Path to the folder where stream chunks are located.
+    """"""
+
+    def __init__(self, name, *args, path=None):
+        if name is None:
+            raise ValueError(""name cannot be None."")
+","--- 

+++ 

@@ -1,4 +1,5 @@

 import inspect
+from itertools import chain
 from warnings import warn
 
 
@@ -27,10 +28,15 @@

     def __init__(self, path, *args):
         self.path = path
         self._args = args
+        self._nested = (
+            member
+            for member in vars(self.__class__).values()
+            if inspect.isclass(member) and issubclass(member, (Stream, StreamGroup))
+        )
 
     def __iter__(self):
-        for callable in self._args:
-            for stream in iter(callable(self.path)):
+        for factory in chain(self._nested, self._args):
+            for stream in iter(factory(self.path)):
                 yield stream
 
 
@@ -52,26 +58,22 @@

             raise ValueError(""name cannot be None."")
 
         self.name = name
-        self._streams = Device._createStreams(name if path is None else path, *args)
+        self._streams = Device._createStreams(name if path is None else path, args)
 
     @staticmethod
-    def _createStreams(path, *args):
+    def _createStreams(path, args):
         streams = {}
-        if args:
-            for callable in args:
-                try:
-                    streams.update(callable(path))
-                except TypeError:
-                    if inspect.isclass(callable):
-                        warn(
-                            f""Stream group classes with no constructors are deprecated. {callable}"",
-                            category=DeprecationWarning,
-                        )
-                        for method in vars(callable).values():
-                            if isinstance(method, staticmethod):
-                                streams.update(method.__func__(path))
-                    else:
-                        raise
+        for factory in args:
+            if inspect.isclass(factory) and not hasattr(factory.__init__, ""__code__""):
+                warn(
+                    f""Stream group classes with default constructors are deprecated. {factory}"",
+                    category=DeprecationWarning,
+                )
+                for method in vars(factory).values():
+                    if isinstance(method, staticmethod):
+                        streams.update(method.__func__(path))
+            else:
+                streams.update(factory(path))
         return streams
 
     def __iter__(self):",,,,
aidar-freeed(merged)/ai-codereviewer,https://api.github.com/repos/mrako/week-number/pulls/comments/1236833540,https://github.com/mrako/week-number/pull/29#discussion_r1236833540,,11,08089113741645198a42138ba3811f0943703b21,15488b2b5b414d3f41e183afbb1114cd17966f10,src/index.js,nan,It's better to use `const dateParam = searchParams.get('date');` and then parse it in the next line to avoid confusion with the state variable `date`.,"+
+  useEffect(() => {
+    const searchParams = new URLSearchParams(window.location.search);
+    const date = Date.parse(searchParams.get('date'));","--- 

+++ 

@@ -8,9 +8,9 @@

 
   useEffect(() => {
     const searchParams = new URLSearchParams(window.location.search);
-    const date = Date.parse(searchParams.get('date'));
+    const dateParam = Date.parse(searchParams.get('date'));
 
-    setDate(isNaN(date) ? new Date() : new Date(date));
+    setDate(isNaN(dateParam) ? new Date() : new Date(dateParam));
   }, []);
 
   if (date) {",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1314035466,https://github.com/SainsburyWellcomeCentre/aeon_mecha/pull/244#discussion_r1314035466,192,200,7445a0a16a18971b741524f685cf3e7b185c3339,bdb3dcd2a4f3a2cd9e79aa1579236d1facbb1ea5,aeon/dj_pipeline/ingest/load_metadata.py,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The regular expression search does not have any error handling. If the search fails and returns None, calling `.group()` will raise an AttributeError.
```diff
- ""wheel_sampling_rate"": float(re.search(r""\d+"", patch[""SampleRate""]).group()),
+ match = re.search(r""\d+"", patch[""SampleRate""])
+ if match is None:
+     raise ValueError(f""Invalid SampleRate: {patch['SampleRate']}"")
+ ""wheel_sampling_rate"": float(match.group()),
```


<!-- This is an auto-generated comment by OSS CodeRabbit -->","+        patch_key = {""food_patch_serial_number"": patch.get(""SerialNumber"") or patch[""PortName""]}
         patch_list.append(patch_key)
 
         patch_installation = {
             **patch_key,
             ""experiment_name"": experiment_name,
             ""food_patch_install_time"": epoch_start,
             ""food_patch_description"": patch[""Name""],
-            ""wheel_sampling_rate"": float(
-                re.search(r""\d+"", patch[""SampleRate""]).group()
-            ),
+            ""wheel_sampling_rate"": float(re.search(r""\d+"", patch[""SampleRate""]).group()),","--- 

+++ 

@@ -1,12 +1,11 @@

+import re
 import pathlib
-import re
 from datetime import datetime
-
 import yaml
 
 from aeon.dj_pipeline import acquisition, lab
-
 from .. import dict_to_uuid
+
 
 _weight_scale_rate = 100
 _weight_scale_nest = 1
@@ -14,9 +13,11 @@

 
 def extract_epoch_metadata(experiment_name, metadata_yml_filepath):
     metadata_yml_filepath = pathlib.Path(metadata_yml_filepath)
-    epoch_start = datetime.strptime(metadata_yml_filepath.parent.name, ""%Y-%m-%dT%H-%M-%S"")
-
-    with open(metadata_yml_filepath) as f:
+    epoch_start = datetime.strptime(
+        metadata_yml_filepath.parent.name, ""%Y-%m-%dT%H-%M-%S""
+    )
+
+    with open(metadata_yml_filepath, ""r"") as f:
         experiment_setup = yaml.safe_load(f)
 
     commit = experiment_setup.get(""Commit"", experiment_setup.get(""Revision""))
@@ -33,16 +34,20 @@

 
 
 def ingest_epoch_metadata(experiment_name, metadata_yml_filepath):
-    """"""work-in-progress
+    """"""
+    work-in-progress
     Missing:
     + camera/patch location
-    + patch, weightscale serial number.
+    + patch, weightscale serial number
     """"""
+
     metadata_yml_filepath = pathlib.Path(metadata_yml_filepath)
     file_creation_time = datetime.fromtimestamp(metadata_yml_filepath.stat().st_ctime)
-    epoch_start = datetime.strptime(metadata_yml_filepath.parent.name, ""%Y-%m-%dT%H-%M-%S"")
-
-    with open(metadata_yml_filepath) as f:
+    epoch_start = datetime.strptime(
+        metadata_yml_filepath.parent.name, ""%Y-%m-%dT%H-%M-%S""
+    )
+
+    with open(metadata_yml_filepath, ""r"") as f:
         experiment_setup = yaml.safe_load(f)
 
     experiment_key = {""experiment_name"": experiment_name}
@@ -81,23 +86,35 @@

             else:
                 raise ValueError(f""Unrecognized Device Type for {device_name}"")
 
-            experiment_devices.append({""Name"": device_name, ""Type"": device_type, **device_info})
+            experiment_devices.append(
+                {""Name"": device_name, ""Type"": device_type, **device_info}
+            )
     else:
-        raise ValueError(f""Unexpected devices variable type: {type(experiment_setup['Devices'])}"")
+        raise ValueError(
+            f""Unexpected devices variable type: {type(experiment_setup['Devices'])}""
+        )
 
     # ---- Video Controller ----
 
-    video_controller = [device for device in experiment_devices if device[""Type""] == ""VideoController""]
-
-    assert len(video_controller) == 1, ""Unable to find one unique VideoController device""
+    video_controller = [
+        device for device in experiment_devices if device[""Type""] == ""VideoController""
+    ]
+
+    assert (
+        len(video_controller) == 1
+    ), ""Unable to find one unique VideoController device""
     video_controller = video_controller[0]
 
     device_frequency_mapper = {
-        name: float(value) for name, value in video_controller.items() if name.endswith(""Frequency"")
+        name: float(value)
+        for name, value in video_controller.items()
+        if name.endswith(""Frequency"")
     }
 
     # ---- Load cameras ----
-    cameras = [device for device in experiment_devices if device[""Type""] == ""VideoSource""]
+    cameras = [
+        device for device in experiment_devices if device[""Type""] == ""VideoSource""
+    ]
 
     camera_list, camera_installation_list, camera_removal_list, camera_position_list = (
         [],
@@ -174,13 +191,17 @@

     # remove the currently installed cameras that are absent in this config
     camera_removal_list.extend(
         (
-            acquisition.ExperimentCamera - acquisition.ExperimentCamera.RemovalTime - camera_list
+            acquisition.ExperimentCamera
+            - acquisition.ExperimentCamera.RemovalTime
+            - camera_list
             & experiment_key
         ).fetch(""KEY"")
     )
 
     # ---- Load food patches ----
-    food_patches = [device for device in experiment_devices if device[""Type""] == ""Patch""]
+    food_patches = [
+        device for device in experiment_devices if device[""Type""] == ""Patch""
+    ]
     patch_list, patch_installation_list, patch_removal_list, patch_position_list = (
         [],
         [],
@@ -189,7 +210,9 @@

     )
     for patch in food_patches:
         # ---- Check if this is a new food patch, add to lab.FoodPatch if needed
-        patch_key = {""food_patch_serial_number"": patch.get(""SerialNumber"") or patch[""PortName""]}
+        patch_key = {
+            ""food_patch_serial_number"": patch.get(""SerialNumber"") or patch[""PortName""]
+        }
         patch_list.append(patch_key)
 
         patch_installation = {
@@ -197,7 +220,9 @@

             ""experiment_name"": experiment_name,
             ""food_patch_install_time"": epoch_start,
             ""food_patch_description"": patch[""Name""],
-            ""wheel_sampling_rate"": float(re.search(r""\d+"", patch[""SampleRate""]).group()),
+            ""wheel_sampling_rate"": float(
+                re.search(r""\d+"", patch[""SampleRate""]).group()
+            ),
             ""wheel_radius"": float(patch[""Radius""]),
         }
         if ""position"" in patch:
@@ -220,7 +245,8 @@

         # If the same camera serial number is currently installed
         # check for any changes in configuration, if not, skip this
         current_patch_query = (
-            acquisition.ExperimentFoodPatch - acquisition.ExperimentFoodPatch.RemovalTime
+            acquisition.ExperimentFoodPatch
+            - acquisition.ExperimentFoodPatch.RemovalTime
             & experiment_key
             & patch_key
         )
@@ -252,13 +278,17 @@

     # remove the currently installed patches that are absent in this config
     patch_removal_list.extend(
         (
-            acquisition.ExperimentFoodPatch - acquisition.ExperimentFoodPatch.RemovalTime - patch_list
+            acquisition.ExperimentFoodPatch
+            - acquisition.ExperimentFoodPatch.RemovalTime
+            - patch_list
             & experiment_key
         ).fetch(""KEY"")
     )
 
     # ---- Load weight scales ----
-    weight_scales = [device for device in experiment_devices if device[""Type""] == ""WeightScale""]
+    weight_scales = [
+        device for device in experiment_devices if device[""Type""] == ""WeightScale""
+    ]
     weight_scale_list, weight_scale_installation_list, weight_scale_removal_list = (
         [],
         [],
@@ -267,7 +297,8 @@

     for weight_scale in weight_scales:
         # ---- Check if this is a new weight scale, add to lab.WeightScale if needed
         weight_scale_key = {
-            ""weight_scale_serial_number"": weight_scale.get(""SerialNumber"") or weight_scale[""PortName""]
+            ""weight_scale_serial_number"": weight_scale.get(""SerialNumber"")
+            or weight_scale[""PortName""]
         }
         weight_scale_list.append(weight_scale_key)
 
@@ -284,7 +315,8 @@

 
         # ---- Check if this weight scale is currently installed - if so, remove it
         current_weight_scale_query = (
-            acquisition.ExperimentWeightScale - acquisition.ExperimentWeightScale.RemovalTime
+            acquisition.ExperimentWeightScale
+            - acquisition.ExperimentWeightScale.RemovalTime
             & experiment_key
             & weight_scale_key
         )
@@ -295,7 +327,9 @@

             current_weight_scale_config.pop(""weight_scale_install_time"")
             new_weight_scale_config.pop(""weight_scale_install_time"")
 
-            if dict_to_uuid(current_weight_scale_config) == dict_to_uuid(new_weight_scale_config):
+            if dict_to_uuid(current_weight_scale_config) == dict_to_uuid(
+                new_weight_scale_config
+            ):
                 continue
 
             # ---- Remove old weight scale",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1765246060,https://github.com/SainsburyWellcomeCentre/aeon_mecha/pull/402#discussion_r1765246060,1,2,1a8b0097175251aad2719d7309ffa6186fc238fb,a889dba13c07c7eb6142a8265b8d8de8c60cef9c,tests/conftest.py,tests/dj_pipeline/conftest.py,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The docstring has been updated to include a title, which improves readability and understanding of the file's purpose. However, the command for running all tests is commented out and could be included in the docstring for clarity.
```diff
- """"""
+ """"""Global configurations and fixtures for pytest.
 # run all tests:
 # pytest -sv --cov-report term-missing --cov=aeon_mecha -p no:warnings tests/dj_pipeline
```



<!-- This is an auto-generated comment by OSS CodeRabbit -->","+""""""Global configurations and fixtures for pytest.
+",nan,,,,
aidar-freeed(merged)/ai-codereviewer,https://api.github.com/repos/mt-krainski/yet-another-flight-scanner/pulls/comments/1697790509,https://github.com/mt-krainski/yet-another-flight-scanner/pull/9#discussion_r1697790509,,424,6ca85a2bdc5742dfb9e239618022b0a4970141eb,3dd1a2d54c1979352ed9dbe5ccd05b6ce422ebf7,yafs/notebooks/analysis.ipynb,nan,"The line `""fig.show()""` appears to be a string rather than an executable command. If this is intended to be executed, it should not be enclosed in quotes.","@@ -385,50 +424,42 @@
     ""fig.show()""","--- 

+++ 

@@ -138,7 +138,7 @@

     ""# In current processing, if the price is like 'CA$ 1,200', the algorithm will split this\n"",
     ""# into digits and characters, so we'll get 'CA$,' and '1200'.\n"",
     ""# This removes the unnecessary comma.\n"",
-    ""df[\""price_currency\""] = df[\""price_currency\""].str.replace(\"",\"", \""\"")""
+    ""df[\""price_currency\""] = df[\""price_currency\""].str.replace(\"",\"", \""\"", regex=False)""
    ]
   },
   {",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/lightspeedwp/tour-operator/pulls/comments/1881883581,https://github.com/lightspeedwp/tour-operator/pull/457#discussion_r1881883581,126,231,ccabb3ad4d5b9d5adbdf7bdc0ff7d9d2f1d1ade0,70abbf3757db6f520f4e9250a937a5aafa1fe4b5,assets/css/scss/_slider.scss,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The styling for `.wp-block-query.lsx-to-slider` and its child elements is identical to the styling for `.lsx-to-slider, .slick-lightbox-inner` and its child elements (lines 4-66). This repetition increases the file size and makes the code harder to maintain. Consider using a single selector that matches both cases.
```diff
- /* Slick Slider Arrows and Lightbox styles */
- .wp-block-query.lsx-to-slider{
-   .slick-arrow {
-     background: transparent;
-     border-radius: 50%;
-     position: absolute;
-     top: 50%;
-     border-style: solid;
-     border-color: #fff;
-     border-width: 2px;
-     font: 0/0 a;
-     height: 4rem;
-     margin-top: calc((2.25rem - 17px) / 2);
-     padding: 0;
-     text-shadow: none;
-     transform: translateY(-50%);
-     transition: border 300ms ease;
-     width: 4rem;
-     z-index: 3;
-     color: white;
- 
-     &:before {
-       display: block;
-       font-family: ""slick"";
-       color: white;
-       font-size: 3rem;
-       line-height: 1;
-       position: absolute;
-       text-rendering: auto;
-       top: 47%;
-       transform: translateY(-50%);
-       transition: color 300ms ease;
-       -webkit-font-smoothing: antialiased;
-       -moz-osx-font-smoothing: grayscale;
-     }
- 
-     &.slick-disabled {
-       cursor: not-allowed;
-     }
- 
-     &.slick-prev {
-       &:before {
-         content: ''; /* Remove font icon */
-         background: url('../../img/left-arrow-new.svg') no-repeat center center;
-         width: 40px;
-         height: 40px;
-         display: inline-block;
-         left: 10px;
-       }
-     }
- 
-     &.slick-next {
-       &:before {
-         content: ''; /* Remove font icon */
-         background: url('../../img/right-arrow.svg') no-repeat center center;
-         width: 40px;
-         height: 40px;
-         display: inline-block;
-         left: 12px;
-       }
-     }
-   }
- 
-   .slick-dots:not(.dropdown-menu) {
-     align-items: center;
-     display: flex;
-     flex-flow: row wrap;
-     height: auto;
-     justify-content: center;
-     list-style: none;
-     margin: 2rem 0 0;
-     padding: 0;
- 
-     & > li {
-       line-height: 1;
-       padding: 5px;
- 
-       & > button {
-         background: transparent;
-         border-style: solid;
-         border-width: 1px;
-         font: 0/0 a;
-         height: 12px;
-         transition: all 300ms ease-in-out;
-         width: 4rem;
-       }
-     }
-   }
- 
-   .slick-arrow {
-     &.slick-prev {
-       left: -4rem;
-     }
-     &.slick-next {
-       right: -4rem;
-     }
-   }
- 
-   &.slider-disabled {
-     overflow: hidden;
-   }
- }
```


<!-- This is an auto-generated comment by OSS CodeRabbit -->","+.slick-lightbox-close {
+  right: 32px;
+  top: 32px;
+}
+
+/* Slick Slider Arrows and Lightbox styles */
+.wp-block-query.lsx-to-slider{
+  .slick-arrow {
+    background: transparent;
+    border-radius: 50%;
+    position: absolute;
+    top: 50%;
+    border-style: solid;
+    border-color: #fff;
+    border-width: 2px;
+    font: 0/0 a;
+    height: 4rem;
+    margin-top: calc((2.25rem - 17px) / 2);
+    padding: 0;
+    text-shadow: none;
+    transform: translateY(-50%);
+    transition: border 300ms ease;
+    width: 4rem;
+    z-index: 3;
+    color: white;
+
+    &:before {
+      display: block;
+      font-family: ""slick"";
+      color: white;
+      font-size: 3rem;
+      line-height: 1;
+      position: absolute;
+      text-rendering: auto;
+      top: 47%;
+      transform: translateY(-50%);
+      transition: color 300ms ease;
+      -webkit-font-smoothing: antialiased;
+      -moz-osx-font-smoothing: grayscale;
+    }
+
+    &.slick-disabled {
+      cursor: not-allowed;
+    }
+
+    &.slick-prev {
+      &:before {
+        content: ''; /* Remove font icon */
+        background: url('../../img/left-arrow-new.svg') no-repeat center center;
+        width: 40px;
+        height: 40px;
+        display: inline-block;
+        left: 10px;
+      }
+    }
+
+    &.slick-next {
+      &:before {
+        content: ''; /* Remove font icon */
+        background: url('../../img/right-arrow.svg') no-repeat center center;
+        width: 40px;
+        height: 40px;
+        display: inline-block;
+        left: 12px;
+      }
+    }
+  }
+
+  .slick-dots:not(.dropdown-menu) {
+    align-items: center;
+    display: flex;
+    flex-flow: row wrap;
+    height: auto;
+    justify-content: center;
+    list-style: none;
+    margin: 2rem 0 0;
+    padding: 0;
+
+    & > li {
+      line-height: 1;
+      padding: 5px;
+
+      & > button {
+        background: transparent;
+        border-style: solid;
+        border-width: 1px;
+        font: 0/0 a;
+        height: 12px;
+        transition: all 300ms ease-in-out;
+        width: 4rem;
+      }
+    }
+  }
+
+  .slick-arrow {
+    &.slick-prev {
+      left: -4rem;
+    }
+    &.slick-next {
+      right: -4rem;
+    }
+  }
+
+  &.slider-disabled {
+    overflow: hidden;
+  }","--- 

+++ 

@@ -1,42 +1,96 @@

-/* Slider specific code */
+.wp-block-query {
+	&.lsx-to-slider {
+		gap: var(--wp--preset--spacing--small) var(--wp--preset--spacing--small);
+		position: relative;
 
-/* Slick Slider Arrows and Lightbox styles */
+		.slick-arrow {
+			cursor: pointer;
+			border-color: #000 !important;
+			height: 30px;
+			width: 30px;
+
+			&:before {
+				border-color: #000 !important;
+				height: 30px;
+				width: 30px;
+			}
+
+			&.slick-prev:before {
+				background: url('../img/left-arrow-dark.svg') no-repeat center center;
+				width: 20px;
+				left: 3px;
+				height: 20px;
+			}
+
+			&.slick-next:before {
+				background: url('../img/right-arrow-dark.svg') no-repeat center center;
+				width: 20px;
+				left: 3px;
+				height: 20px;
+			}
+		}
+
+		.slick-slide {
+			padding: 15px !important;
+		}
+	}
+}
+
+.slick-lightbox-close {
+  right: 52px;
+  top: 35px;
+
+  &:before {
+	font-size: 40px;
+  }
+}
+
 .lsx-to-slider,
 .slick-lightbox-inner {
   .slick-arrow {
-    background: transparent;
-    border-radius: 50%;
-    position: absolute;
-    top: 50%;
-    border-style: solid;
-    border-color: #fff;
-    border-width: 2px;
-    font: 0/0 a;
-    height: 4rem;
-    margin-top: calc((2.25rem - 17px) / 2);
-    padding: 0;
-    text-shadow: none;
-    transform: translateY(-50%);
-    transition: border 300ms ease;
-    width: 4rem;
-    z-index: 3;
-    color: white;
+	background: transparent;
+	border-radius: 50%;
+	position: absolute;
+	top: 50%;
+	border-style: solid;
+	border-color: #fff;
+	border-width: 2px;
+	font: 0/0 a;
+	height: 4rem;
+	margin-top: calc((2.25rem - 17px) / 2);
+	padding: 0;
+	text-shadow: none;
+	transform: translateY(-50%);
+	transition: border 300ms ease;
+	width: 4rem;
+	z-index: 3;
+	color: white;
 
-    &:before {
-      display: block;
-      font-family: ""slick"";
-      color: white;
-      font-size: 3rem;
-      line-height: 1;
-      position: absolute;
-      text-rendering: auto;
-      top: 47%;
-      transform: translateY(-50%);
-      transition: color 300ms ease;
-      -webkit-font-smoothing: antialiased;
-      -moz-osx-font-smoothing: grayscale;
-    }
+	&:before {
+	  display: block;
+	  font-family: ""slick"";
+	  color: white;
+	  font-size: 3rem;
+	  line-height: 1;
+	  position: absolute;
+	  text-rendering: auto;
+	  top: 47%;
+	  transform: translateY(-50%);
+	  transition: color 300ms ease;
+	  -webkit-font-smoothing: antialiased;
+	  -moz-osx-font-smoothing: grayscale;
+	}
+  }
+}
 
+.slick-prev svg, 
+.slick-next svg {
+  color: white;
+}
+
+.lsx-to-slider,
+.slick-lightbox-inner {
+  .slick-arrow {
     &.slick-disabled {
       cursor: not-allowed;
     }
@@ -44,7 +98,6 @@

     &.slick-prev {
       &:before {
         content: ''; /* Remove font icon */
-        background: url('../../img/left-arrow-new.svg') no-repeat center center;
         width: 40px;
         height: 40px;
         display: inline-block;
@@ -55,7 +108,6 @@

     &.slick-next {
       &:before {
         content: ''; /* Remove font icon */
-        background: url('../../img/right-arrow.svg') no-repeat center center;
         width: 40px;
         height: 40px;
         display: inline-block;
@@ -63,170 +115,82 @@

       }
     }
   }
-
-  .slick-dots:not(.dropdown-menu) {
-    align-items: center;
-    display: flex;
-    flex-flow: row wrap;
-    height: auto;
-    justify-content: center;
-    list-style: none;
-    margin: 2rem 0 0;
-    padding: 0;
-
-    & > li {
-      line-height: 1;
-      padding: 5px;
-
-      & > button {
-        background: transparent;
-        border-style: solid;
-        border-width: 1px;
-        font: 0/0 a;
-        height: 12px;
-        transition: all 300ms ease-in-out;
-        width: 4rem;
-      }
-    }
-  }
-
-  .slick-arrow {
-    &.slick-prev { left: -4rem; }
-    &.slick-next { right: -4rem; }
-  }
-
-  &.slider-disabled {
-    overflow: hidden;
-  }
 }
 
-/* Lightbox Arrow */
+.lsx-to-slider {
+	.slick-dots:not(.dropdown-menu) {
+	  align-items: center;
+	  display: flex;
+	  flex-flow: row wrap;
+	  height: auto;
+	  justify-content: center;
+	  list-style: none;
+	  margin: 2rem 0 0;
+	  padding: 0;
+  
+	  > li {
+		line-height: 1;
+		padding: 5px;
+  
+		> button {
+		  background: transparent;
+		  border-style: solid;
+		  border-width: 1px;
+		  font: 0/0 a;
+		  height: 12px;
+		  transition: all 300ms ease-in-out;
+		  width: 4rem;
+		}
+	  }
+	}
+  
+	.slick-arrow {
+	  &.slick-prev {
+		left: -4rem;
+	  }
+	  
+	  &.slick-next {
+		right: -4rem;
+	  }
+	}
+  
+	&.slider-disabled {
+	  overflow: hidden;
+	}
+  
+	.slick-slide {
+	  .lazy-hidden {
+		max-height: 154px;
+	  }
+	}
+}
+
 .slick-lightbox-inner {
-  .slick-arrow {
-    opacity: 0.75;
-
-    &:hover { opacity: 1; }
-  }
+	.slick-arrow {
+		opacity: 0.75;
+		
+		&:hover {
+		opacity: 1;
+		}
+	}
 }
 
 .slick-lightbox-slick-caption {
-  display: inline-block;
+	display: inline-block;
 }
 
-.lsx-to-slider,
 .lsx-post-carousel-items {
-  .slick-slide {
-    .lazy-hidden {
-      max-height: 154px;
-    }
-  }
+	.slick-slide {
+		.lazy-hidden {
+			max-height: 154px;
+		}
+	}
 }
 
-/* Additional Slider Styles */
-.slick-lightbox-close {
-  right: 32px;
-  top: 32px;
+.lsx-itinerary-wrapper,
+.lsx-units-wrapper {
+	.hidden {
+		display: none;
+	}
 }
-
-/* Slick Slider Arrows and Lightbox styles */
-.wp-block-query.lsx-to-slider{
-  .slick-arrow {
-    background: transparent;
-    border-radius: 50%;
-    position: absolute;
-    top: 50%;
-    border-style: solid;
-    border-color: #fff;
-    border-width: 2px;
-    font: 0/0 a;
-    height: 4rem;
-    margin-top: calc((2.25rem - 17px) / 2);
-    padding: 0;
-    text-shadow: none;
-    transform: translateY(-50%);
-    transition: border 300ms ease;
-    width: 4rem;
-    z-index: 3;
-    color: white;
-
-    &:before {
-      display: block;
-      font-family: ""slick"";
-      color: white;
-      font-size: 3rem;
-      line-height: 1;
-      position: absolute;
-      text-rendering: auto;
-      top: 47%;
-      transform: translateY(-50%);
-      transition: color 300ms ease;
-      -webkit-font-smoothing: antialiased;
-      -moz-osx-font-smoothing: grayscale;
-    }
-
-    &.slick-disabled {
-      cursor: not-allowed;
-    }
-
-    &.slick-prev {
-      &:before {
-        content: ''; /* Remove font icon */
-        background: url('../../img/left-arrow-new.svg') no-repeat center center;
-        width: 40px;
-        height: 40px;
-        display: inline-block;
-        left: 10px;
-      }
-    }
-
-    &.slick-next {
-      &:before {
-        content: ''; /* Remove font icon */
-        background: url('../../img/right-arrow.svg') no-repeat center center;
-        width: 40px;
-        height: 40px;
-        display: inline-block;
-        left: 12px;
-      }
-    }
-  }
-
-  .slick-dots:not(.dropdown-menu) {
-    align-items: center;
-    display: flex;
-    flex-flow: row wrap;
-    height: auto;
-    justify-content: center;
-    list-style: none;
-    margin: 2rem 0 0;
-    padding: 0;
-
-    & > li {
-      line-height: 1;
-      padding: 5px;
-
-      & > button {
-        background: transparent;
-        border-style: solid;
-        border-width: 1px;
-        font: 0/0 a;
-        height: 12px;
-        transition: all 300ms ease-in-out;
-        width: 4rem;
-      }
-    }
-  }
-
-  .slick-arrow {
-    &.slick-prev {
-      left: -4rem;
-    }
-    &.slick-next {
-      right: -4rem;
-    }
-  }
-
-  &.slider-disabled {
-    overflow: hidden;
-  }
-}
+  ",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/saiqulhaq/dynamic_links/pulls/comments/1468725837,https://github.com/saiqulhaq/dynamic_links/pull/19#discussion_r1468725837,45,55,a71f93658310e321b930a78926b4ab31f66de4f4,67675ef2633001974317dae9fc570ecf17a48936,test/jobs/shorten_url_job_test.rb,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

The test case for error handling seems to be missing an important aspect. When an exception occurs, it's crucial to ensure that the lock is released to prevent deadlocks. Please add an assertion to check if the lock is released when an exception is raised.
```diff
  assert_raises StandardError do
    @job.perform(@client, @url, ""#{@short_url}123"", @lock_key)
  end

+ refute @locker.locked?(@lock_key)

  assert @locker.locked?(@lock_key)
```



<!-- This is an auto-generated comment by OSS CodeRabbit -->","+    test 'perform should log error and re-raise exception on failure' do
+      @strategy.stubs(:always_growing?).returns(true)
+      ShortenedUrl.stubs(:create!).raises(StandardError.new('Creation failed'))
+      DynamicLinks::Logger.expects(:log_error).with(regexp_matches(/Error in ShortenUrlJob/))
+
+      assert_raises StandardError do
+        @job.perform(@client, @url, ""#{@short_url}123"", @lock_key)
+      end
+
+      assert @locker.locked?(@lock_key)
+    end","--- 

+++ 

@@ -17,7 +17,7 @@

       @locker.cache_store.write(@lock_key, true)
     end
 
-    test 'perform should create a shortened URL if startegy#always_growing? is true' do
+    test 'perform should create a shortened URL if strategy#always_growing? is true' do
       @strategy.stubs(:always_growing?).returns(true)
       @job.stubs(:storage).returns(@storage)
 
@@ -25,7 +25,7 @@

       @job.perform(@client, @url, ""#{@short_url}11"", @lock_key)
     end
 
-    test 'perform should find_or_create a shortened URL if startegy#always_growing? is false' do
+    test 'perform should find_or_create a shortened URL if strategy#always_growing? is false' do
       @strategy.stubs(:always_growing?).returns(false)
       @job.stubs(:storage).returns(@storage)
 
@@ -44,10 +44,10 @@

 
     test 'perform should log error and re-raise exception on failure' do
       @strategy.stubs(:always_growing?).returns(true)
-      ShortenedUrl.stubs(:create!).raises(StandardError.new('Creation failed'))
+      ShortenedUrl.stubs(:create!).raises(ShorteningFailed.new('Creation failed'))
       DynamicLinks::Logger.expects(:log_error).with(regexp_matches(/Error in ShortenUrlJob/))
 
-      assert_raises StandardError do
+      assert_raises ShorteningFailed do
         @job.perform(@client, @url, ""#{@short_url}123"", @lock_key)
       end
 ",,,,
aidar-freeed(merged)/ai-codereviewer,https://api.github.com/repos/aidar-freeed/ai-codereviewer/pulls/comments/1174425506,https://github.com/aidar-freeed/ai-codereviewer/pull/10#discussion_r1174425506,,202,97bdebd58573233576537253b7e2c3870acda9b1,07b4e53660f659896135241f708e9811a19cb8e6,src/main.ts,nan,Consider using `core.info()` instead of `console.log()` for better integration with GitHub Actions.,"+  console.log(""Running the action..."");
+  console.log(""Event name:"", process.env.GITHUB_EVENT_NAME);
+  if (process.env.GITHUB_EVENT_NAME === ""pull_request"") {
+    console.log(""Pull request event"");","--- 

+++ 

@@ -196,24 +196,19 @@

 async function main() {
   const prDetails = await getPRDetails();
   let diff: string | null;
-  console.log(""Running the action..."");
-  console.log(""Event name:"", process.env.GITHUB_EVENT_NAME);
-  if (process.env.GITHUB_EVENT_NAME === ""pull_request"") {
-    console.log(""Pull request event"");
+  const eventData = JSON.parse(
+    readFileSync(process.env.GITHUB_EVENT_PATH ?? """", ""utf8"")
+  );
+
+  if (eventData.action === ""opened"") {
     diff = await getDiff(
       prDetails.owner,
       prDetails.repo,
       prDetails.pull_number
     );
-  } else if (process.env.GITHUB_EVENT_NAME === ""push"") {
-    console.log(""Push event"");
-    const pushEvent = JSON.parse(
-      readFileSync(process.env.GITHUB_EVENT_PATH || """", ""utf8"")
-    );
-    console.log(""Push event:"");
-    console.log(pushEvent);
-    const newBaseSha = pushEvent.before;
-    const newHeadSha = pushEvent.after;
+  } else if (eventData.action === ""synchronize"") {
+    const newBaseSha = eventData.before;
+    const newHeadSha = eventData.after;
 
     const response = await octokit.repos.compareCommits({
       owner: prDetails.owner,
@@ -227,8 +222,6 @@

           .request({ url: response.data.diff_url })
           .then((res) => res.data)
       : null;
-    console.log(""Diff:"");
-    console.log(diff);
   } else {
     console.log(""Unsupported event:"", process.env.GITHUB_EVENT_NAME);
     return;",,,,
coderabbitai/ai-pr-reviewer,https://api.github.com/repos/brisen-app/brisen-client/pulls/comments/1536663257,https://github.com/brisen-app/brisen-client/pull/3#discussion_r1536663257,19,25,46793c649333414b445f1d42ca1ff4bd8d8a51a2,ccad80f2210c4994adca60df93cc4043733bbfe1,.github/workflows/quality-gate.yml,nan,"<img src=""https://avatars.githubusercontent.com/in/347564?s=41"" alt=""Image description"" width=""20"" height=""20"">   CodeRabbit

Update the steps for SonarQube analysis and quality gate check.
```diff
-       # Triggering SonarQube analysis as results of it are required by Quality Gate check.
-       - name: SonarQube Scan
-         uses: sonarsource/sonarqube-scan-action@master
-         env:
-           SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
-           SONAR_HOST_URL: ${{ vars.SONAR_HOST_URL }}
- 
-       # Check the Quality Gate status.
-       - name: SonarQube Quality Gate check
-         id: sonarqube-quality-gate-check
-         uses: sonarsource/sonarqube-quality-gate-action@master
-         # Force to fail step after specific time.
-         timeout-minutes: 5
+       - name: 🔍 SonarQube Scan
+         uses: sonarsource/sonarqube-scan-action@master
+ 
+       - name: 📋 SonarQube Quality Gate check
+         uses: sonarsource/sonarqube-quality-gate-action@master
+         timeout-minutes: 5
```

This review addresses key issues related to workflow naming, triggering events, indentation, and step adjustments for SonarQube analysis and quality gate checks.


<!-- This is an auto-generated comment by OSS CodeRabbit -->","+      # Triggering SonarQube analysis as results of it are required by Quality Gate check.
+      - name: 🔍 SonarQube Scan
+        uses: sonarsource/sonarqube-scan-action@master
 
-    # Optionally you can use the output from the Quality Gate in another step.
-    # The possible outputs of the `quality-gate-status` variable are `PASSED`, `WARN` or `FAILED`.
-    - name: ""Example show SonarQube Quality Gate Status value""
-      run: echo ""The Quality Gate status is ${{ steps.sonarqube-quality-gate-check.outputs.quality-gate-status }}""
+      # Check the Quality Gate status.
+      - name: 📋 SonarQube Quality Gate check
+        uses: sonarsource/sonarqube-quality-gate-action@master","--- 

+++ 

@@ -2,6 +2,10 @@

 
 on:
   pull_request:
+
+concurrency:
+  group: ${{ github.workflow }}-${{ github.ref }}
+  cancel-in-progress: true
 
 jobs:
   sonarqube:
@@ -23,4 +27,14 @@

       # Check the Quality Gate status.
       - name: 📋 SonarQube Quality Gate check
         uses: sonarsource/sonarqube-quality-gate-action@master
+        id: gate
         timeout-minutes: 5
+
+      - name: 💬 Comment on PR
+        uses: peter-evans/create-or-update-comment@v4
+        if: failure()
+        with:
+          issue-number: ${{ github.event.number }}
+          body: |
+            # Quality Gate ${{ steps.gate.outputs.quality-gate-status }}
+            Check the results [here](${{ vars.SONAR_HOST_URL }}dashboard?id=${{ vars.SONAR_REPO_ID }})",,,,
